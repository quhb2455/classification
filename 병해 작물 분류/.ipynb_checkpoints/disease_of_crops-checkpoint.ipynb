{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmFkU-CAjyAa",
    "outputId": "e66c60a3-e0c1-45f3-fee4-1e2301cb2315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Mh2yZjDj9z5",
    "outputId": "37f405c5-bcf1-4f07-d827-da9d08593ae6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/병해작물/235842_작물 병해 분류 AI 경진대회_data.zip\n",
      "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu111)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!unzip \"/content/drive/MyDrive/병해작물/235842_작물 병해 분류 AI 경진대회_data.zip\"\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xQzzqkXOy5kc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "J01dWsWEzK4x",
    "outputId": "ffd9c003-9bc0-4db0-b658-5ee01133161f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>img_path</th>\n",
       "      <th>disease</th>\n",
       "      <th>disease_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>train_imgs/10000.jpg</td>\n",
       "      <td>시설포도노균병</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>train_imgs/10001.jpg</td>\n",
       "      <td>시설포도노균병</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>train_imgs/10002.jpg</td>\n",
       "      <td>시설포도노균병반응</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>train_imgs/10003.jpg</td>\n",
       "      <td>축과병</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>train_imgs/10004.jpg</td>\n",
       "      <td>시설포도노균병</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid              img_path    disease  disease_code\n",
       "0  10000  train_imgs/10000.jpg    시설포도노균병             1\n",
       "1  10001  train_imgs/10001.jpg    시설포도노균병             1\n",
       "2  10002  train_imgs/10002.jpg  시설포도노균병반응             2\n",
       "3  10003  train_imgs/10003.jpg        축과병             4\n",
       "4  10004  train_imgs/10004.jpg    시설포도노균병             1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# train_total = pd.DataFrame(train_total)\n",
    "# test = pd.DataFrame(test)\n",
    "\n",
    "train_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨별 데이터 개수를 이용하여 weight를 줄 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106\n",
       "1     46\n",
       "2     30\n",
       "3     29\n",
       "4     17\n",
       "5     12\n",
       "6     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total = pd.read_csv('./data/train.csv')\n",
    "pd.value_counts(train_total['disease_code'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_list, label_list, transforms=None):\n",
    "        self.img_list = img_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.img_list[idx], cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms :\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        img = torch.tensor(img, dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.img_list) == len(self.label_list)\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParser() :\n",
    "    def __init__(self, data_path, random_seed, resize):\n",
    "        self.img_list, self.label_list = self.get_data(data_path)\n",
    "        self.random_seed = random_seed\n",
    "        self.resize = resize\n",
    "\n",
    "\n",
    "    def get_data(self, data_path):\n",
    "        \n",
    "        data = pd.read_csv(data_path)\n",
    "\n",
    "        upper_path = data_path.split('/')[-1]\n",
    "\n",
    "        img_list = []\n",
    "        label_list = []\n",
    "        for i in range(len(data['img_path'])) :\n",
    "            img_list.append(data_path.replace(upper_path, data['img_path'][i]))\n",
    "            label_list.append(data['disease_code'][i])\n",
    "    \n",
    "        return img_list, label_list\n",
    "\n",
    "    \n",
    "    def get_fold_data(self, fold_datalist):\n",
    "        imgs = [self.img_list[i] for i in fold_datalist]\n",
    "        labels = [self.label_list[i] for i in fold_datalist]\n",
    "\n",
    "        return imgs, labels\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_transforms(self, train=True):\n",
    "        if train :\n",
    "            transforms = A.Compose([\n",
    "                A.Resize(self.resize + 20,self.resize + 20),\n",
    "                A.RandomCrop(self.resize, self.resize),\n",
    "                A.Rotate(),\n",
    "                A.HorizontalFlip(),\n",
    "#                 A.ColorJitter(),\n",
    "                A.Normalize()\n",
    "            ])\n",
    "        else :\n",
    "            transforms = A.Compose([\n",
    "                A.Resize(224, 224),\n",
    "                A.Normalize()\n",
    "            ])\n",
    "\n",
    "        return transforms\n",
    "    \n",
    "    \n",
    "    def DatasetParsing(self, fold_train=None, fold_valid=None):\n",
    "        if fold_train is None :\n",
    "            train_imgs, valid_imgs, train_labels, valid_labels = train_test_split(self.img_list,\n",
    "                                                                                  self.label_list,\n",
    "                                                                                  train_size=0.9,\n",
    "                                                                                  shuffle=True,\n",
    "                                                                                  random_state=self.random_seed,\n",
    "                                                                                  stratify=self.label_list)\n",
    "        else :\n",
    "            train_imgs, train_labels = self.get_fold_data(fold_train)\n",
    "            valid_imgs, valid_labels = self.get_fold_data(fold_valid)\n",
    "\n",
    "        train_transforms = self.get_transforms()\n",
    "        valid_transforms = self.get_transforms(train=False)\n",
    "\n",
    "        train_dataset = TrainDataset(img_list=train_imgs, label_list=train_labels, transforms=train_transforms)\n",
    "        valid_dataset = TrainDataset(img_list=valid_imgs, label_list=valid_labels, transforms=valid_transforms)\n",
    "\n",
    "        return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutmix 사용을 위한 Random bbox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2bdf934fa07b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "from easydict import EasyDict\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train():\n",
    "    def __init__(self, args):\n",
    "        self.model_name = args.model_name\n",
    "        self.export = args.export\n",
    "\n",
    "        self.epoch = args.epoch\n",
    "        self.batch_size = args.batch_size\n",
    "        self.lr = args.learning_rate\n",
    "\n",
    "        self.k_fold_n = args.k_fold_n\n",
    "        self.early_stop = args.early_stop\n",
    "        self.resize = args.resize\n",
    "\n",
    "        self.cosine_lr_Tmax = args.cosine_lr_Tmax\n",
    "        self.cosine_lr_eta_min = args.cosine_lr_eta_min\n",
    "        \n",
    "        self.train_path = args.train_path\n",
    "        self.test_path = args.test_path\n",
    "        self.num_classes = args.num_classes\n",
    "\n",
    "        self.random_seed = args.random_seed\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.weights = self.cal_weights(self.train_path, self.num_classes) if args.weights else None\n",
    "\n",
    "        self.args = args\n",
    "        # self.CUDA_NUMPY_SETTING(random_seed=args.random_seed)\n",
    "\n",
    "    def create_model(self, model_name, num_classes):\n",
    "        model = timm.create_model(model_name,pretrained=True, num_classes=num_classes).to(device=self.device)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def CUDA_NUMPY_SETTING(self, random_seed=11):\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.manual_seed_all(random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "\n",
    "        print(\"==\" * 30)\n",
    "        print(\"USING CUDA is \",torch.cuda.is_available())\n",
    "        print(\"DETECTED GPU NUMNER : \", torch.cuda.current_device())\n",
    "        print(\"Using \", torch.cuda.device_count(),\" GPUs\")\n",
    "        for i in range(torch.cuda.device_count()) :\n",
    "            print(\"GPU name is \", torch.cuda.get_device_name(i))\n",
    "        print(\"==\" * 30)\n",
    "\n",
    "        \n",
    "    def cal_ACC(self, pred, label):\n",
    "        preds = pred.argmax(dim=-1)\n",
    "        comp_list = (preds==label).cpu().tolist()\n",
    "\n",
    "        cnt = 0\n",
    "        for i in comp_list :\n",
    "            if i == True : cnt += 1\n",
    "\n",
    "        return cnt / len(preds)\n",
    "\n",
    "    \n",
    "    def cal_weights(self, data_path, num_classes) :\n",
    "        train_total = pd.read_csv(data_path)\n",
    "        num_label = np.array([pd.value_counts(train_total['disease_code'].values)[i] for i in range(num_classes)])\n",
    "        return torch.tensor(np.max(num_label)/num_label).to(self.device, dtype=torch.float)\n",
    "        \n",
    "\n",
    "    def model(self,datasetWeights=None):\n",
    "        model = self.create_model(self.model_name, num_classes=self.num_classes)\n",
    "        criterion = nn.CrossEntropyLoss(weight=(datasetWeights).to(device=self.device, dtype=torch.float)\n",
    "                                        if datasetWeights is not None\n",
    "                                        else None)\n",
    "        optimizer = AdamW(params=model.parameters(), lr=self.lr)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.cosine_lr_Tmax, eta_min=self.cosine_lr_eta_min)\n",
    "\n",
    "        return model, criterion, optimizer, scheduler\n",
    "\n",
    "\n",
    "    def run(self, train_loader, valid_loader, weights):\n",
    "        \n",
    "        results = {\n",
    "            'train_acc': [],\n",
    "            'train_loss': [],\n",
    "            'valid_loss': [],\n",
    "            'valid_acc': [],\n",
    "            'valid_f1': []\n",
    "        }\n",
    "\n",
    "        best_snapshot = {\n",
    "            'best_epoch': 0,\n",
    "            'best_f1': 0,\n",
    "            'best_model': None\n",
    "        }\n",
    "\n",
    "        early_stop_cout = 0\n",
    "\n",
    "        model, criterion, optimizer, scheduler = self.model(weights)\n",
    "\n",
    "        wandb.init(project='vit', entity='quhb2455',  config=self.args)\n",
    "#         wandb.watch(model, criterion, log=\"all\", log_freq=1)\n",
    "        \n",
    "        for E in range(1, self.epoch + 1):\n",
    "            model.train()\n",
    "\n",
    "            iter_results = {\n",
    "                'train_acc': [],\n",
    "                'train_loss': [],\n",
    "                'valid_loss': [],\n",
    "                'valid_acc': [],\n",
    "                'valid_f1': []\n",
    "            }\n",
    "            start_t = time()\n",
    "            # iter\n",
    "            for iter, (batch_img, batch_label) in enumerate(train_loader, start=1):\n",
    "                imgs = batch_img.to(device=self.device, dtype=torch.float)\n",
    "                labels = batch_label.to(device=self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                lam = np.random.beta(1.0, 1.0)\n",
    "                rand_index = torch.randperm(imgs.size()[0])\n",
    "                target_a = labels\n",
    "                target_b = labels[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(imgs.size(), lam)\n",
    "                imgs[:, :, bbx1:bbx2, bby1:bby2] = imgs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                \n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (imgs.size()[-1] * imgs.size()[-2]))\n",
    "                      \n",
    "                \n",
    "\n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, target_a) * lam + criterion(pred, target_b) * (1. - lam)\n",
    "#                 loss = criterion(pred, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                iter_results['train_acc'].append(self.cal_ACC(pred, labels))\n",
    "                iter_results['train_loss'].append(loss.cpu().item())\n",
    "\n",
    "                print(f\"Epoch [{E} / {self.epoch}]      Iter [{iter} / {len(train_loader)}]\", end=\"\\r\")\n",
    "\n",
    "                \n",
    "                \n",
    "            # eval\n",
    "            with torch.no_grad():\n",
    "                for iter, (batch_img, batch_label) in enumerate(valid_loader, start=1):\n",
    "                    model.eval()\n",
    "\n",
    "                    imgs = batch_img.to(device=self.device, dtype=torch.float)\n",
    "                    labels = batch_label.to(device=self.device)\n",
    "\n",
    "                    val_pred = model(imgs)\n",
    "                    val_pred_argmax = val_pred.argmax(dim=-1)\n",
    "                    val_loss = criterion(val_pred, labels)\n",
    "\n",
    "                    iter_results['valid_acc'].append(self.cal_ACC(val_pred, labels))\n",
    "                    iter_results['valid_loss'].append(val_loss.cpu().item())\n",
    "                    iter_results['valid_f1'].append(f1_score(y_true=labels.cpu().numpy(),\n",
    "                                                             y_pred=val_pred_argmax.cpu().numpy(),\n",
    "                                                             average=\"macro\"))\n",
    "\n",
    "                    print(f\"Epoch [{E} / {self.epoch}]      valid_Iter [{iter} / {len(valid_loader)}]\", end=\"\\r\")\n",
    "\n",
    "            # print(iter_results['valid_acc'])\n",
    "            # print(type(iter_results['valid_acc']))\n",
    "            results['train_acc'].append(np.mean(iter_results['train_acc']))\n",
    "            results['train_loss'].append(np.mean(iter_results['train_loss']))\n",
    "            results['valid_acc'].append(np.mean(iter_results['valid_acc']))\n",
    "            results['valid_loss'].append(np.mean(iter_results['valid_loss']))\n",
    "            results['valid_f1'].append(np.mean(iter_results['valid_f1']))\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            wandb.log({\n",
    "                'Epochs' : E,\n",
    "                'train_acc' : results['train_acc'][-1].item(),\n",
    "                'train_loss' : results['train_loss'][-1].item(),\n",
    "                'valid_acc' : results['valid_acc'][-1].item(),\n",
    "                'valid_loss' : results['valid_loss'][-1].item(),\n",
    "                'valid_f1' : results['valid_f1'][-1].item()                \n",
    "            })\n",
    "            end_t = time() - start_t\n",
    "            print(\n",
    "                f\"[Epoch {E} / {self.epoch}] \"\n",
    "                f\"Time : {end_t:.4f} s | \"\n",
    "                f\"train_acc : {results['train_acc'][-1]:.4f} | \"\n",
    "                f\"train_loss : {results['train_loss'][-1]:.4f} | \"\n",
    "                f\"valid_acc : {results['valid_acc'][-1]:.4f} | \"\n",
    "                f\"valid_loss : {results['valid_loss'][-1]:.4f} | \"\n",
    "                f\"valid_f1 : {results['valid_f1'][-1]:.4f}\"\n",
    "            )\n",
    "\n",
    "            if results['valid_f1'][-1] > best_snapshot['best_f1']:\n",
    "                best_snapshot['best_f1'] = results['valid_f1'][-1]\n",
    "                best_snapshot['best_model'] = model\n",
    "                best_snapshot['best_epoch'] = E\n",
    "                early_stop_cout = 0\n",
    "\n",
    "            else:\n",
    "                early_stop_cout += 1\n",
    "                print(f\"early_stop_couter : {early_stop_cout} / {self.early_stop}\")\n",
    "\n",
    "            if early_stop_cout >= self.early_stop:\n",
    "                print()\n",
    "                print(\"*\" * 20)\n",
    "                print(\"!! EARLY STOP !!\")\n",
    "                print(\"*\" * 20)\n",
    "                print()\n",
    "                break\n",
    "\n",
    "        return results, best_snapshot\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        Datasets = DataParser(self.train_path, self.random_seed, self.resize)\n",
    "        \n",
    "        if self.k_fold_n == False :\n",
    "\n",
    "            train_dataset, valid_dataset = Datasets.DatasetParsing()\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            \n",
    "            results, best_snapshot = self.run(train_loader, valid_loader, self.weights)\n",
    "\n",
    "            return results, best_snapshot\n",
    "\n",
    "        else :\n",
    "            print(f\"Training Start [ {self.k_fold_n} ] times\")\n",
    "\n",
    "            # StratifiedKFold가 class 간의  balance를 맞춰주기 때문에 weights는 필요 없음\n",
    "            kfold = StratifiedKFold(n_splits=self.k_fold_n, random_state=self.random_seed, shuffle=True)\n",
    "\n",
    "            # kfold_result = {\"results\": [], \"best_snapshot\":[]}\n",
    "            kfold_result = []\n",
    "            for k, (fold_train, fold_valid) in enumerate(kfold.split(Datasets.img_list, Datasets.label_list), 1) :\n",
    "\n",
    "                fold_train_dataset, fold_valid_dataset = Datasets.DatasetParsing(fold_train, fold_valid)\n",
    "\n",
    "                fold_train_loader = DataLoader(fold_train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "                fold_valid_loader = DataLoader(fold_valid_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "                results, best_snapshot = self.run(fold_train_loader, fold_valid_loader, None)\n",
    "\n",
    "                # kfold_result['results'].append(results) # >> ?? 굳이 저장을 해야하나?\n",
    "                kfold_result.append(best_snapshot)\n",
    "\n",
    "                print(f\"\\n==== Fold [{k} / {self.k_fold_n}]  Best-F1 [{kfold_result[k-1]['best_f1']}] ====\\n\")\n",
    "\n",
    "            return kfold_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_dir(path) : \n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_large_patch4_window7_224_config={\n",
    "    'model_name' : 'swin_large_patch4_window7_224', # 사용하려는 timm 모델 #  vit_base_patch16_224\n",
    "    'export' : './data/model', # 학습 후 모델이 저장될 장소\n",
    "    'batch_size' : 2, \n",
    "    'epoch' : 20,\n",
    "    'k_fold_n': 2, # False 로하면 Epoch만큼 학습, 숫자를 넣으면 해당 횟수로 데이터셋 fold 후 학습\n",
    "                        # Fold 별로 모델 저장도 진행함.\n",
    "    'resize' : 224,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'cosine_lr_Tmax' : 15,\n",
    "    'cosine_lr_eta_min' : 1e-5,\n",
    "    \n",
    "    'early_stop' : 4,\n",
    "    'random_seed' : 11, # dataset 셔플용\n",
    "    'train_path' : './data/train.csv',\n",
    "    'test_path' : './data/test.csv', # 안씀\n",
    "    'num_classes' : 7, \n",
    "    'weights' : True # dataset 불균형 때문에 넣어봄, loss 계산 시 label 갯수를 기반으로 가중치 추가됨.\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "\n",
    "swin_base_patch4_window7_224_in22k_config={\n",
    "    'model_name' : 'swin_base_patch4_window7_224_in22k', # 사용하려는 timm 모델 #  vit_base_patch16_224\n",
    "    'export' : './data/model', # 학습 후 모델이 저장될 장소\n",
    "    'batch_size' : 8, \n",
    "    'epoch' : 20,\n",
    "    'k_fold_n': 4, # False 로하면 Epoch만큼 학습, 숫자를 넣으면 해당 횟수로 데이터셋 fold 후 학습\n",
    "                        # Fold 별로 모델 저장도 진행함.\n",
    "    'resize' : 224,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'cosine_lr_Tmax' : 15,\n",
    "    'cosine_lr_eta_min' : 1e-5,\n",
    "    \n",
    "    'early_stop' : 4,\n",
    "    'random_seed' : 11, # dataset 셔플용\n",
    "    'train_path' : './data/train.csv',\n",
    "    'test_path' : './data/test.csv', # 안씀\n",
    "    'num_classes' : 7, \n",
    "    'weights' : True # dataset 불균형 때문에 넣어봄, loss 계산 시 label 갯수를 기반으로 가중치 추가됨.\n",
    "}\n",
    "\n",
    "# =============================================\n",
    "\n",
    "nfnet_l0_config={\n",
    "    'model_name' : 'nfnet_l0', # 사용하려는 timm 모델 #  vit_base_patch16_224\n",
    "    'export' : './data/model', # 학습 후 모델이 저장될 장소\n",
    "    'batch_size' : 16, \n",
    "    'epoch' : 20,\n",
    "    'k_fold_n': 4, # False 로하면 Epoch만큼 학습, 숫자를 넣으면 해당 횟수로 데이터셋 fold 후 학습\n",
    "                        # Fold 별로 모델 저장도 진행함.\n",
    "    'resize' : 288,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'cosine_lr_Tmax' : 15,\n",
    "    'cosine_lr_eta_min' : 1e-5,\n",
    "    \n",
    "    'early_stop' : 4,\n",
    "    'random_seed' : 11, # dataset 셔플용\n",
    "    'train_path' : './data/train.csv',\n",
    "    'test_path' : './data/test.csv', # 안씀\n",
    "    'num_classes' : 7, \n",
    "    'weights' : True # dataset 불균형 때문에 넣어봄, loss 계산 시 label 갯수를 기반으로 가중치 추가됨.\n",
    "}\n",
    "\n",
    "# ========================================\n",
    "\n",
    "vit_config={\n",
    "    'model_name' : 'vit_base_patch16_224', # 사용하려는 timm 모델 #  vit_base_patch16_224\n",
    "    'export' : './data/model', # 학습 후 모델이 저장될 장소\n",
    "    'batch_size' : 16, \n",
    "    'epoch' : 20,\n",
    "    'k_fold_n': 3, # False 로하면 Epoch만큼 학습, 숫자를 넣으면 해당 횟수로 데이터셋 fold 후 학습\n",
    "                        # Fold 별로 모델 저장도 진행함.\n",
    "    'resize' : 224,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'cosine_lr_Tmax' : 15,\n",
    "    'cosine_lr_eta_min' : 1e-5,\n",
    "    \n",
    "    'early_stop' : 4,\n",
    "    'random_seed' : 11, # dataset 셔플용\n",
    "    'train_path' : './data/train.csv',\n",
    "    'test_path' : './data/test.csv', # 안씀\n",
    "    'num_classes' : 7, \n",
    "    'weights' : True # dataset 불균형 때문에 넣어봄, loss 계산 시 label 갯수를 기반으로 가중치 추가됨.\n",
    "}\n",
    "\n",
    "# args = EasyDict(config)\n",
    "args = EasyDict(swin_large_patch4_window7_224_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "{'model_name': 'swin_large_patch4_window7_224', 'export': './data/model', 'batch_size': 2, 'epoch': 20, 'k_fold_n': 2, 'resize': 224, 'learning_rate': 0.0001, 'cosine_lr_Tmax': 15, 'cosine_lr_eta_min': 1e-05, 'early_stop': 4, 'random_seed': 11, 'train_path': './data/train.csv', 'test_path': './data/test.csv', 'num_classes': 7, 'weights': True}\n",
      "====================\n",
      "Training Start [ 2 ] times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquhb2455\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/quhb2455/vit/runs/2rr7xabk\" target=\"_blank\">distinctive-frog-39</a></strong> to <a href=\"https://wandb.ai/quhb2455/vit\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 20] Time : 31.2412 s | train_acc : 0.5238 | train_loss : 1.4425 | valid_acc : 0.8810 | valid_loss : 0.6067 | valid_f1 : 0.8466\n",
      "[Epoch 2 / 20] Time : 30.5946 s | train_acc : 0.8492 | train_loss : 0.5649 | valid_acc : 0.9603 | valid_loss : 0.1522 | valid_f1 : 0.9524\n",
      "[Epoch 3 / 20] Time : 30.4067 s | train_acc : 0.8968 | train_loss : 0.4591 | valid_acc : 0.9524 | valid_loss : 0.2022 | valid_f1 : 0.9365\n",
      "early_stop_couter : 1 / 4\n",
      "[Epoch 4 / 20] Time : 30.7195 s | train_acc : 0.8730 | train_loss : 0.4728 | valid_acc : 0.9127 | valid_loss : 0.2623 | valid_f1 : 0.8836\n",
      "early_stop_couter : 2 / 4\n",
      "[Epoch 5 / 20] Time : 31.0008 s | train_acc : 0.8095 | train_loss : 0.5657 | valid_acc : 0.9683 | valid_loss : 0.1455 | valid_f1 : 0.9577\n",
      "[Epoch 6 / 20] Time : 30.9422 s | train_acc : 0.8810 | train_loss : 0.3776 | valid_acc : 0.9762 | valid_loss : 0.1018 | valid_f1 : 0.9683\n",
      "[Epoch 7 / 20] Time : 31.3076 s | train_acc : 0.9286 | train_loss : 0.3445 | valid_acc : 0.9841 | valid_loss : 0.1177 | valid_f1 : 0.9788\n",
      "[Epoch 8 / 20] Time : 30.8690 s | train_acc : 0.9048 | train_loss : 0.3656 | valid_acc : 0.9683 | valid_loss : 0.1243 | valid_f1 : 0.9577\n",
      "early_stop_couter : 1 / 4\n",
      "[Epoch 9 / 20] Time : 31.5734 s | train_acc : 0.8810 | train_loss : 0.3256 | valid_acc : 0.9762 | valid_loss : 0.1084 | valid_f1 : 0.9683\n",
      "early_stop_couter : 2 / 4\n",
      "[Epoch 10 / 20] Time : 33.5950 s | train_acc : 0.9524 | train_loss : 0.2731 | valid_acc : 0.9841 | valid_loss : 0.0984 | valid_f1 : 0.9788\n",
      "early_stop_couter : 3 / 4\n",
      "[Epoch 11 / 20] Time : 31.8215 s | train_acc : 0.9127 | train_loss : 0.2515 | valid_acc : 0.9841 | valid_loss : 0.0938 | valid_f1 : 0.9788\n",
      "early_stop_couter : 4 / 4\n",
      "\n",
      "********************\n",
      "!! EARLY STOP !!\n",
      "********************\n",
      "\n",
      "\n",
      "==== Fold [1 / 2]  Best-F1 [0.978835978835979] ====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2rr7xabk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 120192... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▆▇█▇▇█▇</td></tr><tr><td>train_loss</td><td>█▃▂▂▃▂▂▂▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▆▆▃▇▇█▇▇██</td></tr><tr><td>valid_f1</td><td>▁▇▆▃▇▇█▇▇██</td></tr><tr><td>valid_loss</td><td>█▂▂▃▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>11</td></tr><tr><td>train_acc</td><td>0.9127</td></tr><tr><td>train_loss</td><td>0.25155</td></tr><tr><td>valid_acc</td><td>0.98413</td></tr><tr><td>valid_f1</td><td>0.97884</td></tr><tr><td>valid_loss</td><td>0.0938</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">distinctive-frog-39</strong>: <a href=\"https://wandb.ai/quhb2455/vit/runs/2rr7xabk\" target=\"_blank\">https://wandb.ai/quhb2455/vit/runs/2rr7xabk</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211022_122436-2rr7xabk\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2rr7xabk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/quhb2455/vit/runs/2vjsgqki\" target=\"_blank\">eager-morning-40</a></strong> to <a href=\"https://wandb.ai/quhb2455/vit\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 20] Time : 31.3300 s | train_acc : 0.5476 | train_loss : 1.4848 | valid_acc : 0.7937 | valid_loss : 0.7664 | valid_f1 : 0.7354\n",
      "[Epoch 2 / 20] Time : 31.2770 s | train_acc : 0.7698 | train_loss : 0.7869 | valid_acc : 0.8095 | valid_loss : 0.6062 | valid_f1 : 0.7513\n",
      "[Epoch 3 / 20] Time : 31.2911 s | train_acc : 0.7857 | train_loss : 0.6425 | valid_acc : 0.9206 | valid_loss : 0.2700 | valid_f1 : 0.8942\n",
      "[Epoch 4 / 20] Time : 31.7616 s | train_acc : 0.8889 | train_loss : 0.4413 | valid_acc : 0.9365 | valid_loss : 0.1971 | valid_f1 : 0.9153\n",
      "[Epoch 5 / 20] Time : 31.3185 s | train_acc : 0.9127 | train_loss : 0.4029 | valid_acc : 0.9444 | valid_loss : 0.3044 | valid_f1 : 0.9259\n",
      "[Epoch 6 / 20] Time : 32.0415 s | train_acc : 0.8889 | train_loss : 0.4483 | valid_acc : 0.9127 | valid_loss : 0.3703 | valid_f1 : 0.8889\n",
      "early_stop_couter : 1 / 4\n",
      "[Epoch 7 / 20] Time : 32.3084 s | train_acc : 0.9524 | train_loss : 0.2581 | valid_acc : 0.9365 | valid_loss : 0.2001 | valid_f1 : 0.9153\n",
      "early_stop_couter : 2 / 4\n",
      "[Epoch 8 / 20] Time : 32.4157 s | train_acc : 0.8651 | train_loss : 0.3910 | valid_acc : 0.9603 | valid_loss : 0.1494 | valid_f1 : 0.9471\n",
      "[Epoch 9 / 20] Time : 31.3788 s | train_acc : 0.8810 | train_loss : 0.3081 | valid_acc : 0.9206 | valid_loss : 0.2760 | valid_f1 : 0.9048\n",
      "early_stop_couter : 1 / 4\n",
      "[Epoch 10 / 20] Time : 32.2275 s | train_acc : 0.9286 | train_loss : 0.2529 | valid_acc : 0.9444 | valid_loss : 0.1943 | valid_f1 : 0.9259\n",
      "early_stop_couter : 2 / 4\n",
      "[Epoch 11 / 20] Time : 31.7190 s | train_acc : 0.9048 | train_loss : 0.3134 | valid_acc : 0.9841 | valid_loss : 0.1253 | valid_f1 : 0.9788\n",
      "[Epoch 12 / 20] Time : 31.7546 s | train_acc : 0.8730 | train_loss : 0.3061 | valid_acc : 0.9762 | valid_loss : 0.1022 | valid_f1 : 0.9683\n",
      "early_stop_couter : 1 / 4\n",
      "[Epoch 13 / 20] Time : 33.8506 s | train_acc : 0.9206 | train_loss : 0.2385 | valid_acc : 0.9603 | valid_loss : 0.1078 | valid_f1 : 0.9471\n",
      "early_stop_couter : 2 / 4\n",
      "[Epoch 14 / 20] Time : 32.2663 s | train_acc : 0.9206 | train_loss : 0.2788 | valid_acc : 0.9524 | valid_loss : 0.1019 | valid_f1 : 0.9418\n",
      "early_stop_couter : 3 / 4\n",
      "[Epoch 15 / 20] Time : 32.0055 s | train_acc : 0.8651 | train_loss : 0.2767 | valid_acc : 0.9683 | valid_loss : 0.1050 | valid_f1 : 0.9577\n",
      "early_stop_couter : 4 / 4\n",
      "\n",
      "********************\n",
      "!! EARLY STOP !!\n",
      "********************\n",
      "\n",
      "\n",
      "==== Fold [2 / 2]  Best-F1 [0.9788359788359788] ====\n",
      "\n",
      "Training DONE\n",
      "SUCCESS to saving the model\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*20)\n",
    "print(args)\n",
    "print(\"=\" * 20)\n",
    "\n",
    "make_new_dir(args.export)\n",
    "\n",
    "training = Train(args)\n",
    "\n",
    "\n",
    "\n",
    "if args.k_fold_n == False :\n",
    "    results, best_snapshot = training.train()\n",
    "    \n",
    "    print(\"Training DONE\")\n",
    "    \n",
    "    torch.save(best_snapshot['best_model'],\n",
    "               args.export + '/' + str(best_snapshot['best_f1']) + '_' + str(best_snapshot['best_epoch']) + 'E_best_model.pt')\n",
    "\n",
    "else :\n",
    "    kfold_best_snapshot = training.train()\n",
    "    \n",
    "    print(\"Training DONE\")\n",
    "    \n",
    "    for idx, bs in enumerate(kfold_best_snapshot) :\n",
    "        torch.save(bs['best_model'],\n",
    "               args.export + '/Kfold_' + str(idx) +'_'+ str(bs['best_f1']) + '_' + str(bs['best_epoch']) + 'E_best_model.pt')\n",
    "\n",
    "\n",
    "print(\"SUCCESS to saving the model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset) :\n",
    "    def __init__(self, img_list, transforms=None):\n",
    "        self.img_list = img_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.img_list[idx], cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms :\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        img = img.transpose(2, 0, 1)\n",
    "\n",
    "        img = torch.tensor(img, dtype=torch.float)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(model_list) :\n",
    "    return [torch.load(model).eval() for model in model_list]\n",
    "\n",
    "def softvoting(models, img, n_classes=7) :\n",
    "\n",
    "    predicts = torch.zeros(img.size(0), n_classes)\n",
    "    for model in models :\n",
    "        output = model(img)\n",
    "        output = F.softmax(output.cpu(), dim=1)\n",
    "        predicts += output\n",
    "\n",
    "    # 둘다 값은 똑같이 나옴.\n",
    "    # pred_avg = predicts / len(models)\n",
    "    # answer = pred_avg.argmax(dim=-1)\n",
    "    # _, answer2 = torch.max(pred_avg, 1)\n",
    "\n",
    "    return predicts.detach().cpu() / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "path ='./data/test.csv'\n",
    "\n",
    "test = pd.read_csv(path)\n",
    "upper_path = path.split('/')[-1]\n",
    "\n",
    "test_path = [path.replace(upper_path, test['img_path'][i]) for i in range(len(test))]\n",
    "\n",
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize()\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(test_path, transforms=transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./data/model/nfnet_vit_swin_Large'\n",
    "models = get_models(glob(model_path+'/*.pt'))\n",
    "n_classes = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./data/model/1.0_4E_best_model.pt'\n",
    "model = torch.load(model_path).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4750/4750 [20:47<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 0, 0, 2, 0, 2, 0, 0, 0, 3, 0, 4, 1, 0, 0, 3, 3, 5, 3, 0, 0, 6, 3, 5, 3, 2, 3, 1, 4, 2, 1, 0, 1, 0, 2, 0, 1, 0, 3, 2, 2, 1, 4, 2, 0, 4, 0, 0, 0, 1, 3, 3, 6, 0, 0, 0, 2, 0, 5, 4, 5, 0, 0, 3, 0, 0, 0, 0, 3, 0, 1, 3, 4, 1, 0, 3, 2, 0, 6, 1, 4, 0, 2, 1, 0, 2, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 1, 1, 0, 0, 4, 4, 5, 2, 2, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 4, 1, 5, 0, 0, 0, 2, 4, 2, 1, 3, 0, 0, 2, 0, 3, 0, 0, 1, 2, 4, 2, 4, 6, 6, 4, 5, 0, 2, 1, 1, 0, 3, 5, 0, 2, 5, 0, 1, 1, 0, 1, 0, 0, 0, 5, 5, 0, 3, 2, 4, 0, 2, 0, 5, 3, 0, 3, 0, 2, 0, 1, 3, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 3, 3, 0, 0, 0, 0, 3, 1, 0, 0, 5, 1, 6, 1, 0, 0, 3, 3, 1, 0, 0, 0, 4, 6, 0, 6, 3, 2, 6, 3, 6, 1, 2, 0, 1, 1, 2, 0, 0, 2, 4, 0, 1, 3, 0, 1, 3, 0, 1, 2, 3, 2, 3, 3, 4, 5, 3, 0, 0, 0, 5, 1, 2, 0, 1, 2, 0, 4, 2, 1, 0, 0, 1, 0, 0, 3, 1, 1, 0, 0, 1, 2, 0, 0, 0, 3, 5, 4, 0, 1, 0, 0, 2, 0, 0, 0, 1, 4, 3, 2, 1, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 3, 1, 4, 0, 1, 0, 4, 0, 0, 0, 3, 2, 5, 0, 4, 0, 0, 5, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 4, 1, 0, 3, 0, 0, 0, 4, 4, 2, 0, 4, 1, 4, 0, 0, 0, 4, 3, 0, 4, 2, 3, 4, 3, 2, 5, 0, 2, 3, 0, 0, 0, 1, 0, 3, 0, 4, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 6, 0, 0, 3, 0, 3, 0, 1, 1, 3, 0, 5, 1, 4, 0, 0, 0, 4, 2, 0, 3, 4, 0, 2, 3, 1, 3, 5, 5, 2, 1, 1, 5, 1, 3, 2, 3, 3, 0, 1, 0, 0, 3, 2, 4, 0, 6, 0, 1, 1, 6, 2, 0, 3, 3, 1, 6, 1, 6, 0, 1, 2, 3, 3, 0, 0, 4, 2, 0, 2, 0, 0, 0, 4, 0, 4, 1, 3, 0, 2, 0, 2, 0, 0, 0, 5, 1, 4, 2, 2, 4, 3, 1, 0, 2, 0, 0, 0, 0, 6, 0, 0, 0, 3, 1, 3, 6, 2, 0, 0, 3, 6, 5, 2, 0, 4, 1, 0, 6, 1, 4, 2, 3, 1, 0, 1, 0, 3, 3, 0, 2, 2, 0, 0, 3, 6, 2, 2, 0, 3, 1, 2, 3, 4, 0, 0, 2, 0, 4, 0, 5, 0, 1, 0, 5, 0, 1, 4, 0, 1, 2, 2, 6, 1, 0, 0, 4, 3, 3, 4, 6, 0, 4, 3, 2, 0, 0, 3, 5, 0, 2, 0, 1, 2, 0, 0, 2, 3, 3, 0, 0, 4, 1, 3, 4, 0, 0, 4, 1, 0, 0, 0, 1, 0, 5, 0, 0, 2, 5, 0, 0, 3, 0, 0, 0, 0, 4, 5, 2, 1, 0, 0, 0, 3, 6, 3, 0, 6, 0, 0, 0, 1, 5, 0, 1, 2, 0, 5, 0, 0, 1, 3, 5, 3, 2, 0, 1, 0, 3, 5, 0, 2, 0, 3, 5, 1, 6, 3, 2, 2, 4, 2, 4, 3, 2, 3, 2, 3, 6, 0, 2, 2, 2, 1, 0, 0, 0, 3, 2, 1, 3, 0, 0, 5, 0, 1, 0, 2, 0, 2, 2, 2, 6, 1, 2, 2, 3, 3, 2, 0, 0, 2, 2, 1, 0, 2, 0, 2, 3, 0, 3, 2, 0, 4, 0, 1, 2, 5, 3, 0, 0, 0, 0, 0, 1, 4, 1, 1, 1, 3, 0, 0, 0, 2, 0, 5, 3, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0, 2, 1, 1, 0, 3, 1, 2, 1, 5, 2, 0, 0, 3, 0, 4, 0, 6, 0, 1, 5, 0, 0, 0, 4, 3, 4, 0, 0, 0, 0, 1, 0, 0, 2, 0, 3, 0, 0, 6, 2, 0, 0, 0, 0, 2, 0, 0, 0, 4, 2, 0, 0, 4, 5, 1, 0, 0, 0, 0, 0, 3, 4, 0, 0, 1, 1, 2, 2, 4, 5, 0, 1, 6, 5, 3, 0, 0, 2, 0, 3, 1, 0, 4, 0, 0, 4, 0, 4, 6, 1, 0, 0, 0, 0, 4, 5, 1, 4, 2, 5, 0, 3, 0, 0, 6, 0, 5, 0, 4, 6, 0, 1, 3, 4, 0, 1, 3, 5, 1, 0, 0, 1, 0, 3, 0, 0, 4, 0, 4, 1, 0, 0, 0, 3, 0, 0, 2, 0, 3, 0, 3, 2, 3, 1, 2, 0, 1, 0, 2, 4, 3, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 3, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 3, 2, 6, 1, 2, 1, 4, 3, 3, 0, 6, 3, 0, 0, 0, 2, 5, 0, 4, 0, 0, 0, 3, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 1, 4, 1, 4, 3, 0, 0, 2, 0, 3, 0, 6, 0, 1, 2, 1, 0, 5, 2, 1, 0, 1, 2, 2, 4, 3, 0, 0, 2, 2, 3, 2, 2, 1, 3, 1, 3, 0, 2, 0, 1, 0, 1, 2, 1, 0, 0, 0, 3, 1, 1, 0, 6, 3, 1, 3, 4, 0, 4, 3, 4, 1, 0, 0, 0, 0, 3, 4, 3, 0, 6, 3, 4, 0, 0, 0, 1, 0, 3, 1, 0, 1, 0, 0, 0, 0, 4, 0, 3, 0, 1, 2, 0, 0, 2, 2, 0, 3, 2, 2, 3, 1, 0, 0, 4, 2, 0, 0, 1, 0, 1, 2, 3, 5, 5, 1, 0, 2, 0, 0, 1, 3, 0, 6, 0, 3, 0, 3, 1, 5, 0, 3, 2, 0, 3, 0, 0, 0, 6, 0, 1, 0, 0, 0, 4, 0, 0, 4, 2, 2, 0, 4, 3, 3, 1, 2, 6, 1, 4, 0, 0, 0, 2, 0, 2, 0, 5, 0, 3, 5, 4, 0, 0, 0, 0, 4, 4, 0, 2, 4, 3, 1, 0, 0, 2, 0, 3, 5, 0, 1, 3, 2, 1, 4, 3, 0, 0, 3, 4, 1, 2, 0, 0, 3, 3, 0, 4, 5, 0, 4, 3, 1, 0, 6, 0, 0, 2, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 2, 3, 2, 6, 5, 1, 1, 0, 3, 0, 6, 0, 0, 4, 3, 0, 2, 0, 0, 2, 6, 0, 0, 4, 0, 0, 0, 0, 6, 1, 0, 0, 2, 0, 4, 0, 3, 6, 2, 0, 4, 0, 1, 0, 2, 2, 5, 3, 2, 3, 0, 5, 0, 2, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 1, 2, 2, 4, 0, 0, 1, 0, 3, 3, 3, 6, 2, 0, 0, 5, 3, 0, 5, 4, 2, 0, 1, 1, 2, 0, 4, 6, 4, 3, 5, 2, 3, 2, 4, 0, 0, 4, 1, 4, 2, 5, 1, 0, 3, 0, 0, 2, 1, 0, 0, 5, 1, 2, 1, 1, 3, 0, 0, 4, 1, 0, 0, 5, 0, 6, 0, 0, 0, 1, 1, 2, 4, 0, 0, 0, 4, 0, 2, 0, 4, 2, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0, 3, 0, 2, 2, 3, 3, 3, 3, 1, 1, 0, 3, 0, 1, 1, 0, 2, 0, 2, 0, 3, 5, 3, 3, 0, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 1, 5, 2, 0, 0, 2, 6, 0, 3, 6, 3, 0, 6, 1, 6, 2, 4, 3, 5, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 5, 2, 0, 0, 3, 0, 0, 6, 1, 0, 0, 2, 0, 0, 4, 0, 2, 0, 4, 4, 0, 0, 4, 5, 2, 2, 2, 0, 3, 0, 3, 0, 3, 0, 0, 6, 3, 0, 3, 0, 6, 2, 1, 5, 2, 0, 2, 4, 0, 0, 0, 1, 0, 3, 0, 4, 0, 5, 1, 3, 4, 0, 0, 1, 0, 0, 2, 2, 1, 1, 2, 0, 1, 4, 0, 4, 4, 0, 1, 0, 1, 6, 0, 1, 2, 2, 5, 0, 0, 1, 1, 5, 0, 1, 0, 4, 0, 1, 1, 3, 3, 2, 3, 2, 2, 0, 0, 3, 0, 0, 1, 4, 2, 4, 0, 4, 0, 3, 3, 3, 3, 5, 3, 0, 2, 0, 2, 0, 0, 1, 0, 3, 1, 0, 1, 6, 0, 4, 0, 1, 4, 4, 2, 1, 1, 0, 2, 0, 4, 0, 1, 0, 3, 0, 3, 0, 6, 0, 1, 4, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 5, 0, 1, 1, 1, 5, 2, 5, 2, 0, 4, 2, 2, 3, 1, 2, 0, 0, 6, 5, 3, 2, 2, 0, 0, 3, 5, 0, 4, 0, 0, 2, 3, 2, 2, 6, 0, 2, 0, 1, 1, 1, 2, 6, 3, 1, 0, 1, 0, 0, 3, 0, 2, 3, 2, 1, 1, 5, 0, 1, 4, 4, 1, 6, 0, 0, 0, 3, 2, 2, 0, 4, 2, 2, 0, 0, 0, 6, 0, 0, 4, 0, 3, 0, 1, 0, 0, 0, 4, 0, 2, 0, 0, 2, 0, 1, 4, 1, 3, 1, 1, 1, 5, 0, 2, 0, 0, 4, 2, 6, 3, 0, 2, 0, 1, 0, 1, 5, 0, 0, 0, 2, 2, 2, 0, 1, 0, 6, 3, 3, 2, 1, 4, 0, 0, 1, 2, 4, 0, 0, 3, 4, 0, 1, 5, 0, 0, 2, 1, 1, 4, 2, 3, 3, 0, 1, 2, 0, 0, 0, 3, 1, 1, 1, 2, 1, 2, 0, 2, 6, 0, 1, 0, 0, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 1, 2, 1, 5, 1, 4, 0, 4, 1, 0, 3, 1, 0, 3, 0, 1, 4, 1, 0, 4, 0, 6, 0, 3, 0, 0, 0, 0, 6, 4, 3, 5, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 3, 3, 0, 0, 0, 3, 0, 2, 0, 4, 2, 1, 3, 3, 1, 0, 1, 1, 1, 0, 5, 5, 6, 0, 0, 0, 0, 6, 3, 3, 1, 0, 2, 0, 1, 0, 0, 4, 2, 0, 0, 3, 1, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 4, 0, 3, 0, 2, 0, 0, 3, 1, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 3, 4, 2, 1, 0, 1, 0, 0, 5, 5, 2, 3, 0, 3, 0, 0, 0, 0, 3, 2, 1, 2, 0, 2, 0, 3, 3, 1, 0, 0, 2, 6, 6, 0, 2, 4, 5, 1, 3, 2, 3, 4, 1, 0, 1, 0, 4, 1, 0, 4, 0, 3, 0, 3, 0, 4, 4, 0, 5, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 1, 5, 0, 2, 1, 2, 4, 1, 0, 0, 1, 3, 1, 1, 2, 2, 1, 2, 0, 1, 5, 1, 1, 0, 3, 2, 1, 6, 0, 3, 0, 1, 0, 6, 3, 0, 0, 0, 0, 0, 0, 1, 0, 2, 6, 0, 0, 4, 1, 0, 2, 1, 2, 0, 0, 1, 3, 6, 5, 3, 4, 0, 3, 4, 3, 0, 3, 2, 3, 2, 1, 3, 1, 3, 4, 4, 3, 0, 2, 1, 2, 0, 0, 0, 0, 1, 4, 1, 1, 3, 0, 2, 0, 0, 1, 0, 4, 6, 0, 0, 3, 1, 1, 3, 2, 0, 5, 0, 5, 6, 2, 0, 5, 0, 1, 4, 5, 0, 5, 0, 0, 0, 2, 0, 2, 5, 2, 0, 1, 0, 3, 0, 4, 6, 0, 1, 1, 5, 0, 2, 2, 1, 0, 4, 5, 2, 1, 0, 0, 3, 0, 0, 5, 0, 0, 3, 2, 4, 0, 0, 0, 3, 5, 3, 1, 0, 1, 3, 0, 0, 3, 3, 2, 0, 3, 0, 5, 0, 5, 1, 0, 0, 4, 0, 0, 6, 5, 4, 0, 3, 2, 1, 0, 4, 2, 5, 2, 3, 0, 0, 2, 5, 2, 2, 0, 6, 0, 0, 4, 1, 3, 2, 0, 2, 0, 2, 3, 3, 1, 0, 1, 3, 1, 0, 0, 0, 4, 5, 2, 5, 6, 0, 1, 3, 0, 1, 4, 4, 1, 5, 0, 0, 1, 3, 0, 1, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 3, 1, 1, 5, 2, 1, 0, 0, 1, 0, 0, 0, 3, 5, 0, 4, 5, 4, 5, 0, 2, 0, 0, 4, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 4, 0, 0, 0, 0, 4, 3, 0, 5, 4, 2, 4, 0, 0, 1, 0, 3, 6, 0, 0, 4, 0, 2, 0, 3, 1, 0, 0, 0, 1, 2, 0, 0, 0, 3, 2, 4, 3, 0, 3, 6, 3, 0, 1, 1, 0, 0, 1, 3, 0, 1, 0, 0, 5, 4, 0, 5, 2, 4, 0, 0, 0, 2, 1, 3, 0, 0, 6, 1, 2, 0, 0, 2, 1, 2, 0, 0, 6, 0, 0, 5, 6, 0, 1, 0, 5, 5, 4, 5, 6, 1, 1, 3, 0, 3, 2, 0, 0, 5, 3, 0, 0, 1, 1, 2, 5, 2, 2, 2, 3, 0, 2, 0, 0, 6, 0, 3, 1, 0, 4, 5, 4, 4, 2, 3, 1, 1, 0, 0, 2, 4, 0, 5, 4, 0, 2, 0, 4, 3, 1, 6, 1, 2, 5, 0, 3, 4, 4, 2, 2, 1, 1, 0, 6, 4, 4, 0, 0, 0, 2, 0, 0, 5, 4, 0, 0, 4, 6, 1, 2, 5, 0, 0, 3, 1, 0, 1, 4, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 4, 0, 1, 0, 5, 1, 0, 2, 0, 0, 3, 0, 0, 2, 2, 6, 1, 2, 0, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0, 4, 5, 2, 0, 3, 2, 5, 3, 1, 3, 0, 3, 0, 0, 0, 0, 1, 1, 0, 6, 6, 0, 0, 0, 6, 2, 0, 0, 3, 0, 0, 0, 0, 2, 4, 4, 2, 2, 6, 6, 2, 0, 0, 5, 6, 2, 5, 0, 2, 0, 0, 5, 2, 4, 3, 3, 0, 0, 0, 3, 3, 5, 5, 5, 0, 2, 0, 0, 2, 0, 0, 1, 3, 5, 1, 1, 4, 0, 0, 0, 0, 1, 0, 5, 1, 0, 0, 0, 2, 2, 0, 1, 0, 1, 2, 4, 2, 0, 0, 0, 4, 5, 2, 1, 0, 0, 6, 1, 0, 1, 5, 5, 3, 0, 0, 2, 3, 0, 3, 0, 0, 2, 0, 5, 2, 6, 3, 1, 6, 6, 4, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 6, 0, 6, 1, 2, 0, 0, 6, 1, 1, 0, 3, 2, 0, 0, 0, 0, 0, 6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 4, 6, 1, 2, 2, 0, 4, 1, 5, 4, 6, 0, 0, 0, 0, 2, 5, 3, 5, 0, 3, 5, 5, 1, 5, 0, 5, 0, 3, 1, 3, 2, 0, 6, 0, 3, 3, 0, 0, 1, 0, 2, 1, 4, 4, 3, 3, 0, 1, 2, 1, 0, 0, 1, 3, 2, 2, 3, 1, 2, 0, 4, 1, 0, 3, 2, 1, 2, 0, 3, 0, 5, 0, 3, 0, 1, 0, 3, 0, 0, 1, 2, 4, 6, 3, 1, 0, 0, 3, 0, 1, 3, 0, 0, 3, 1, 0, 0, 3, 1, 0, 0, 3, 0, 4, 4, 1, 1, 1, 3, 0, 1, 3, 1, 4, 3, 3, 5, 5, 0, 0, 3, 1, 1, 4, 1, 3, 1, 0, 3, 0, 1, 3, 3, 0, 3, 0, 0, 2, 0, 1, 4, 1, 4, 4, 2, 0, 0, 5, 2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 4, 0, 0, 0, 1, 5, 0, 6, 0, 0, 6, 0, 1, 6, 0, 3, 2, 0, 3, 0, 1, 0, 3, 0, 4, 2, 1, 0, 1, 1, 0, 0, 0, 3, 0, 1, 2, 6, 5, 1, 0, 1, 0, 3, 0, 0, 0, 1, 0, 0, 2, 5, 0, 6, 5, 0, 1, 0, 0, 3, 0, 5, 0, 4, 1, 0, 4, 0, 2, 0, 3, 0, 0, 0, 5, 3, 0, 2, 1, 1, 2, 2, 0, 1, 0, 0, 2, 3, 2, 1, 3, 1, 6, 2, 0, 0, 0, 4, 0, 0, 0, 5, 1, 0, 2, 0, 1, 1, 0, 4, 4, 4, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 0, 1, 2, 4, 1, 0, 1, 0, 1, 0, 2, 1, 2, 0, 0, 3, 0, 2, 2, 5, 0, 3, 1, 1, 3, 0, 1, 0, 4, 5, 5, 0, 4, 0, 6, 2, 1, 2, 0, 0, 0, 0, 3, 0, 2, 0, 2, 1, 1, 4, 1, 3, 2, 1, 1, 2, 0, 6, 3, 3, 0, 0, 2, 3, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 3, 0, 5, 3, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 6, 5, 5, 1, 0, 0, 1, 0, 1, 0, 0, 5, 3, 0, 0, 1, 1, 0, 1, 4, 2, 4, 1, 0, 0, 3, 2, 3, 0, 1, 0, 0, 1, 6, 2, 3, 5, 6, 0, 0, 0, 0, 0, 5, 3, 1, 6, 0, 4, 2, 1, 0, 0, 0, 3, 0, 0, 0, 0, 4, 4, 1, 3, 0, 3, 2, 0, 2, 0, 0, 0, 3, 1, 1, 3, 1, 2, 1, 0, 2, 0, 3, 1, 4, 5, 2, 0, 0, 0, 3, 6, 2, 0, 1, 6, 0, 0, 0, 0, 3, 0, 0, 5, 0, 3, 3, 3, 0, 0, 4, 2, 0, 0, 0, 1, 0, 1, 2, 6, 3, 6, 0, 0, 4, 0, 1, 4, 0, 3, 0, 5, 2, 5, 3, 0, 6, 2, 0, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1, 6, 5, 3, 3, 3, 5, 0, 3, 0, 1, 6, 3, 0, 2, 2, 0, 3, 2, 5, 0, 1, 1, 2, 1, 6, 0, 0, 4, 2, 3, 0, 3, 0, 0, 0, 4, 0, 0, 3, 0, 0, 1, 2, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 3, 1, 3, 1, 3, 6, 0, 6, 4, 3, 0, 0, 2, 0, 5, 0, 1, 4, 0, 2, 3, 0, 2, 0, 1, 0, 4, 3, 2, 5, 0, 0, 4, 0, 1, 0, 1, 1, 1, 6, 0, 2, 0, 1, 0, 0, 1, 0, 4, 3, 0, 3, 2, 5, 6, 0, 3, 0, 6, 1, 0, 3, 3, 1, 2, 3, 5, 6, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 5, 2, 1, 0, 0, 3, 4, 0, 0, 0, 0, 2, 4, 2, 0, 3, 0, 0, 6, 6, 3, 0, 1, 3, 6, 5, 0, 0, 3, 1, 1, 3, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 5, 2, 1, 1, 3, 1, 0, 2, 0, 0, 4, 1, 3, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 6, 3, 0, 0, 0, 3, 3, 1, 6, 0, 0, 2, 0, 0, 2, 0, 2, 0, 1, 0, 2, 4, 3, 2, 4, 0, 2, 0, 0, 3, 4, 1, 4, 3, 0, 0, 2, 3, 2, 3, 0, 0, 0, 5, 3, 5, 6, 0, 1, 3, 4, 0, 2, 0, 0, 3, 0, 3, 1, 0, 0, 0, 5, 3, 1, 5, 4, 3, 0, 1, 3, 6, 0, 1, 1, 0, 1, 0, 0, 0, 1, 3, 0, 6, 0, 0, 1, 1, 6, 3, 0, 0, 4, 3, 0, 4, 3, 3, 2, 0, 3, 2, 3, 4, 1, 1, 0, 0, 4, 2, 6, 1, 0, 3, 2, 2, 0, 4, 0, 0, 2, 0, 5, 5, 0, 0, 0, 3, 2, 0, 2, 0, 3, 4, 0, 3, 0, 1, 0, 5, 6, 1, 3, 1, 4, 0, 0, 2, 0, 0, 0, 0, 5, 0, 3, 0, 2, 1, 2, 2, 1, 2, 5, 0, 0, 3, 0, 4, 2, 0, 3, 5, 5, 3, 4, 3, 2, 0, 1, 0, 1, 1, 4, 0, 1, 2, 3, 3, 0, 5, 4, 1, 1, 4, 0, 0, 0, 2, 3, 2, 3, 4, 2, 1, 2, 0, 4, 3, 1, 0, 1, 3, 0, 1, 0, 4, 1, 4, 1, 3, 2, 2, 0, 0, 2, 6, 0, 0, 3, 2, 1, 3, 2, 0, 6, 2, 0, 1, 5, 4, 0, 0, 0, 1, 2, 1, 2, 3, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 5, 1, 1, 2, 2, 2, 3, 0, 0, 6, 4, 3, 0, 3, 6, 3, 5, 3, 0, 3, 0, 0, 1, 2, 2, 5, 0, 4, 6, 0, 3, 1, 1, 0, 4, 1, 6, 1, 0, 0, 3, 1, 2, 2, 1, 3, 0, 3, 5, 1, 0, 0, 4, 4, 0, 5, 0, 0, 1, 0, 0, 1, 0, 2, 1, 3, 2, 2, 0, 2, 3, 1, 0, 2, 0, 3, 3, 3, 1, 0, 2, 2, 0, 3, 5, 2, 0, 6, 1, 2, 1, 0, 0, 0, 3, 0, 4, 0, 0, 4, 3, 2, 1, 1, 0, 0, 0, 4, 0, 0, 0, 0, 4, 5, 2, 5, 0, 0, 0, 0, 3, 1, 6, 0, 0, 1, 0, 0, 2, 5, 1, 5, 6, 0, 3, 2, 1, 3, 1, 2, 2, 2, 4, 0, 3, 3, 6, 0, 2, 0, 0, 2, 4, 3, 2, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 5, 0, 0, 0, 0, 4, 2, 0, 0, 3, 1, 2, 0, 2, 0, 6, 1, 1, 4, 0, 5, 1, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 5, 1, 1, 4, 0, 0, 5, 0, 0, 0, 3, 3, 1, 3, 4, 0, 1, 0, 2, 2, 0, 0, 0, 2, 1, 4, 0, 0, 2, 0, 0, 0, 5, 5, 0, 5, 1, 0, 0, 2, 0, 3, 6, 1, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 1, 3, 0, 0, 1, 3, 1, 0, 3, 1, 0, 0, 0, 3, 3, 6, 3, 2, 0, 0, 4, 2, 0, 0, 0, 0, 2, 2, 0, 6, 3, 5, 1, 1, 1, 0, 0, 0, 0, 1, 2, 5, 3, 0, 2, 2, 2, 3, 0, 3, 3, 5, 1, 2, 4, 0, 0, 4, 4, 0, 0, 0, 0, 6, 6, 3, 3, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 4, 0, 6, 0, 1, 3, 0, 2, 5, 2, 1, 0, 5, 4, 0, 0, 0, 0, 0, 2, 0, 4, 3, 0, 2, 5, 1, 2, 0, 0, 0, 0, 3, 0, 1, 0, 3, 1, 4, 1, 2, 0, 0, 2, 3, 2, 1, 2, 2, 3, 2, 5, 0, 1, 0, 0, 2, 2, 2, 3, 0, 0, 1, 4, 4, 1, 1, 1, 0, 0, 3, 0, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 2, 5, 5, 1, 0, 2, 0, 1, 6, 1, 5, 5, 2, 6, 3, 0, 0, 0, 0, 0, 3, 3, 1, 5, 0, 0, 1, 3, 0, 4, 4, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 3, 4, 0, 2, 5, 1, 3, 0, 3, 0, 2, 0, 0, 3, 1, 0, 5, 0, 0, 3, 2, 0, 3, 3, 1, 1, 1, 3, 1, 2, 2, 1, 0, 3, 3, 1, 0, 1, 2, 0, 0, 1, 5, 1, 4, 5, 0, 4, 0, 3, 2, 0, 3, 4, 4, 3, 2, 5, 2, 1, 2, 0, 0, 0, 0, 3, 5, 0, 1, 2, 0, 0, 1, 2, 0, 1, 0, 0, 3, 6, 5, 0, 5, 0, 3, 3, 5, 4, 1, 2, 0, 1, 5, 4, 0, 3, 0, 0, 3, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 6, 2, 3, 1, 3, 0, 0, 0, 3, 5, 0, 4, 1, 2, 3, 0, 0, 5, 0, 1, 0, 2, 0, 0, 0, 1, 1, 0, 0, 2, 0, 2, 5, 2, 3, 0, 2, 0, 2, 0, 0, 3, 1, 1, 0, 0, 6, 3, 0, 2, 0, 1, 5, 1, 0, 2, 0, 5, 0, 2, 1, 2, 1, 5, 0, 1, 0, 3, 5, 3, 1, 1, 3, 2, 3, 5, 5, 6, 3, 1, 1, 1, 3, 0, 5, 1, 0, 0, 0, 0, 0, 0, 3, 1, 4, 3, 0, 0, 2, 4, 3, 1, 3, 0, 4, 0, 2, 0, 6, 0, 5, 0, 3, 2, 3, 2, 0, 0, 0, 4, 1, 0, 3, 6, 1, 0, 5, 4, 6, 3, 1, 2, 1, 2, 6, 0, 2, 1, 0, 0, 4, 3, 3, 0, 2, 3, 0, 3, 5, 0, 4, 1, 2, 0, 2, 2, 2, 0, 0, 2, 5, 4, 2, 0, 0, 1, 5, 0, 6, 0, 1, 6, 2, 1, 1, 5, 4, 0, 0, 2, 0, 0, 4, 4, 3, 1, 0, 1, 0, 0, 0, 0, 0, 2, 5, 1, 4, 1, 2, 2, 0, 1, 2, 4, 2, 6, 3, 4, 5, 1, 0, 5, 4, 1, 1, 0, 3, 4, 3, 1, 0, 4, 4, 6, 3, 0, 0, 0, 0, 3, 0, 0, 2, 4, 0, 0, 1, 2, 1, 0, 3, 2, 0, 0, 2, 0, 0, 0, 6, 0, 1, 0, 3, 2, 1, 2, 1, 3, 4, 0, 2, 0, 1, 3, 0, 1, 0, 1, 5, 1, 2, 2, 0, 2, 0, 3, 2, 0, 3, 1, 0, 3, 0, 5, 0, 1, 1, 1, 3, 2, 2, 1, 1, 0, 1, 1, 3, 0, 2, 5, 0, 2, 5, 2, 2, 3, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 3, 0, 0, 5, 2, 3, 1, 0, 1, 0, 2, 0, 0, 3, 0, 0, 1, 2, 0, 2, 2, 4, 6, 0, 0, 3, 6, 3, 4, 2, 0, 0, 2, 3, 0, 0, 0, 0, 4, 0, 3, 0, 0, 0, 1, 4, 5, 2, 5, 3, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 5, 2, 0, 0, 0, 3, 2, 4, 1, 1, 6, 1, 1, 3, 0, 2, 0, 0, 0, 0, 0, 6, 0, 1, 6, 0, 1, 0, 1, 2, 1, 0, 0, 0, 1, 1, 0, 0, 4, 5, 3, 3, 6, 2, 4, 2, 1, 6, 0, 0, 3, 1, 0, 3, 5, 0, 2, 4, 1, 0, 3, 1, 0, 5, 2, 1, 0, 1, 1, 0, 1, 0, 1, 5, 3, 0, 0, 0, 2, 0, 0, 3, 0, 1, 6, 1, 1, 1, 0, 0, 0, 4, 3, 2, 0, 5, 3, 0, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 4, 2, 6, 0, 5, 0, 2, 0, 1, 3, 3, 5, 0, 0, 1, 0, 0, 6, 0, 0, 0, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = []\n",
    "for img in tqdm(test_loader) :\n",
    "    img = img.to(device=device)\n",
    "    \n",
    "    predictions = softvoting(models, img)\n",
    "#     prediction = model(img)\n",
    "    \n",
    "#     results.append(int(torch.argmax(prediction.detach().cpu())))\n",
    "    results.append(int(torch.argmax(predictions[0])))\n",
    "    \n",
    "#     output = F.softmax(prediction.detach().cpu(), dim=1)\n",
    "#     print(output)\n",
    "#     (torch.argmax(output[0]))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.iloc[:,1] = results\n",
    "submission.to_csv('nfnet_vit_swin_Large.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5WJbUGECzzWF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet101d',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_100',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71']\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('efficientnetv2_rw_s', pretrained=True, num_classes=7)\n",
    "# model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=7)\n",
    "\n",
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z1ZpE0uk6_h8"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjWMP8ko4i8_",
    "outputId": "8da8d05c-019f-47d3-f1a5-2a60cef17386"
   },
   "outputs": [],
   "source": [
    "# for idx, (k, v) in enumerate(model.named_parameters()):\n",
    "#   print(idx, k)\n",
    "\n",
    "# for idx, param in enumerate(model.parameters()):\n",
    "#     if idx >= 765:\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "#     print(idx, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ufkrf9VnC35o"
   },
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training):\n",
    "    img = batch_item['img'].to(device)\n",
    "    label = batch_item['label'].to(device)\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6ne96ApEtWS",
    "outputId": "bc1c5e83-0cf6-44d6-9181-a6915a5a021d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:16,  2.43s/it, Epoch=1, Loss=2.294647, Total Loss=2.595269]\n",
      "2it [00:03,  1.95s/it, Epoch=1, Val Loss=2.288040, Total Val Loss=1.864299]\n",
      "7it [00:16,  2.31s/it, Epoch=2, Loss=1.185036, Total Loss=0.518740]\n",
      "2it [00:03,  1.93s/it, Epoch=2, Val Loss=1.239040, Total Val Loss=1.039335]\n",
      "7it [00:15,  2.27s/it, Epoch=3, Loss=0.673981, Total Loss=0.131293]\n",
      "2it [00:03,  1.95s/it, Epoch=3, Val Loss=0.836715, Total Val Loss=0.772324]\n",
      "7it [00:16,  2.32s/it, Epoch=4, Loss=0.136313, Total Loss=0.035211]\n",
      "2it [00:03,  2.00s/it, Epoch=4, Val Loss=0.706157, Total Val Loss=0.734229]\n",
      "7it [00:16,  2.31s/it, Epoch=5, Loss=0.156432, Total Loss=0.032473]\n",
      "2it [00:03,  1.95s/it, Epoch=5, Val Loss=0.792791, Total Val Loss=0.799475]\n",
      "7it [00:16,  2.30s/it, Epoch=6, Loss=0.048201, Total Loss=0.017607]\n",
      "2it [00:03,  1.94s/it, Epoch=6, Val Loss=0.800679, Total Val Loss=0.768865]\n",
      "7it [00:16,  2.30s/it, Epoch=7, Loss=0.099182, Total Loss=0.019057]\n",
      "2it [00:03,  1.99s/it, Epoch=7, Val Loss=0.843006, Total Val Loss=0.834054]\n",
      "7it [00:16,  2.37s/it, Epoch=8, Loss=0.043944, Total Loss=0.009622]\n",
      "2it [00:03,  1.95s/it, Epoch=8, Val Loss=0.774704, Total Val Loss=0.751414]\n",
      "7it [00:16,  2.30s/it, Epoch=9, Loss=0.018264, Total Loss=0.006567]\n",
      "2it [00:03,  1.99s/it, Epoch=9, Val Loss=0.771510, Total Val Loss=0.733353]\n",
      "7it [00:16,  2.31s/it, Epoch=10, Loss=0.144777, Total Loss=0.024723]\n",
      "2it [00:03,  1.97s/it, Epoch=10, Val Loss=0.790217, Total Val Loss=0.691948]\n"
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    \n",
    "    if np.min(val_loss_plot) == val_loss_plot[-1]:\n",
    "        torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KxX3YJaBExmF"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot, label='train_loss')\n",
    "plt.plot(val_loss_plot, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OnH1L7c5_w0W"
   },
   "outputs": [],
   "source": [
    "def predict(dataset):\n",
    "    model.eval()\n",
    "    tqdm_dataset = tqdm(enumerate(dataset))\n",
    "    training = False\n",
    "    results = []\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        img = batch_item['img'].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "        output = torch.tensor(torch.argmax(output, axis=-1), dtype=torch.int32).cpu().numpy()\n",
    "        results.extend(output)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7tDVBZFSekS4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\users\\quhb2\\anaconda3\\envs\\torch-1.9\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "149it [05:57,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qIPvoTJXemf1"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.iloc[:,1] = preds\n",
    "submission.to_csv('baseline2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "병해작물.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
