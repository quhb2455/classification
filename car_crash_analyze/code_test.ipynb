{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232cfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4107d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "\n",
    "from predictor import Predictor\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from models import simple_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f1c33",
   "metadata": {},
   "source": [
    "## 각각의 test frame을 추론하고, 50개(1 video = 50frame) frame을 평균내서 가장 높은 값을 가진 클래스를 할당 하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    \"BATCH_SIZE\" : 32,\n",
    "    \"MODEL_NAME\" : 'efficientnet_b0',\n",
    "    \"ENSEMBLE\" : None,\n",
    "    \"IMG_PATH\" : \"./data/div_2width_train/*\",\n",
    "    \"CSV_PATH\" : \"./data/new_test.csv\",\n",
    "    \"OUTPUT\" : \"./results/div_2width_effib0_224.csv\",\n",
    "    \"CHECKPOINT\" : [\"./ckpt/div_2width_effib0_224/1E-val1.0-efficientnet_b0.pth\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862ab2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOAD ... from ./ckpt/div_2width_effib0_224/1E-val1.0-efficientnet_b0.pth\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = simple_NN(args.MODEL_NAME, num_classes=13).to(device)\n",
    "predictor = Predictor(model, device, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d22b08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 2813/2813 [13:06<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, pred_inds = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690002be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'pred_value' : preds, 'pred_index' : pred_inds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = [0 for i in range(1800)]\n",
    "cnt = 0\n",
    "for j in tqdm(range(0, 90000, 50)) :    \n",
    "    best_score = 0\n",
    "    best_cls = 0\n",
    "    for i in range(13) :\n",
    "        mean_score = sum(df['pred_value'][j : j + 49][df['pred_index'] == i].values)/(len(df['pred_value'][j : j + 50][df['pred_index'] == i].values.tolist()) + +0.000001)\n",
    "        if mean_score >= best_score  :\n",
    "            best_score = mean_score\n",
    "            best_cls = i\n",
    "\n",
    "    pred_list[cnt] = best_cls\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0b7dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "df['label'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2f34dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./results/div_2width_effib0_224.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c48762",
   "metadata": {},
   "source": [
    "## 이미지 channel 단위로 겹치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11205993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6453e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    img_stack = []\n",
    "    label_stack = []\n",
    "    _transforms = A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        # A.Resize(224, 224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False,\n",
    "                    p=1.0),\n",
    "    ])\n",
    "    print(batch[:][0].shape)\n",
    "    for img, label in batch:\n",
    "        # img 나누기\n",
    "#         w_ratio = int(img.shape[1] / 16)\n",
    "#         h_ratio = int(img.shape[0] / 8) # 16\n",
    "\n",
    "        label_stack.append(label)\n",
    "        label_stack.append(img)\n",
    "#         for w in range(16):\n",
    "#             for h in range(8): # 16\n",
    "#                 cropped_img = _transforms(image=img[h * h_ratio: (h + 1) * h_ratio, w * w_ratio: (w + 1) * w_ratio])['image'].transpose(2, 0, 1)\n",
    "#                 img_stack.append(cropped_img.tolist())\n",
    "\n",
    "    return torch.Tensor(img_stack), torch.Tensor(label_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85eac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ChannelStackDataset(Dataset):\n",
    "    def __init__(self, _df, labels, transform=None):\n",
    "        self._df = _df\n",
    "        self.labels = labels\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self._df['img_path'].iloc[index]\n",
    "        \n",
    "        # print(img_path)\n",
    "        # image = cv2.imread(os.path.join('./data', *img_path.split('/')[2:]))\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if self.transform :\n",
    "            image = self.transform(image=image)['image']\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "csv_path = \"./data/div_2width_train.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "label_set = df['label']\n",
    "transform = A.Compose([\n",
    "                A.Resize(224, 224),\n",
    "                # A.Rotate(limit=(45), p=1),\n",
    "                # A.RandomGridShuffle(p=grid_shuffle_p, grid=(2,2)),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "ds = _ChannelStackDataset(df, label_set, transform)\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=False, num_workers=1)#, collate_fn=collate_fn)\n",
    "\n",
    "for img, label in dl :\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39423f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__._ChannelStackDataset at 0x1b2e6f4a4c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb2e45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1b2e6f5a850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in dl :\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f42a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
