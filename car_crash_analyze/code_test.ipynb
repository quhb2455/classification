{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232cfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from  easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4107d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "\n",
    "from predictor import Predictor\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from models import simple_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f1c33",
   "metadata": {},
   "source": [
    "## 각각의 test frame을 추론하고, 50개(1 video = 50frame) frame을 평균내서 가장 높은 값을 가진 클래스를 할당 하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    \"BATCH_SIZE\" : 32,\n",
    "    \"MODEL_NAME\" : 'efficientnet_b0',\n",
    "    \"ENSEMBLE\" : None,\n",
    "    \"IMG_PATH\" : \"./data/div_2width_train/*\",\n",
    "    \"CSV_PATH\" : \"./data/new_test.csv\",\n",
    "    \"OUTPUT\" : \"./results/div_2width_effib0_224.csv\",\n",
    "    \"CHECKPOINT\" : [\"./ckpt/div_2width_effib0_224/1E-val1.0-efficientnet_b0.pth\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862ab2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOAD ... from ./ckpt/div_2width_effib0_224/1E-val1.0-efficientnet_b0.pth\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = simple_NN(args.MODEL_NAME, num_classes=13).to(device)\n",
    "predictor = Predictor(model, device, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d22b08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 2813/2813 [13:06<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, pred_inds = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690002be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'pred_value' : preds, 'pred_index' : pred_inds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = [0 for i in range(1800)]\n",
    "cnt = 0\n",
    "for j in tqdm(range(0, 90000, 50)) :    \n",
    "    best_score = 0\n",
    "    best_cls = 0\n",
    "    for i in range(13) :\n",
    "        mean_score = sum(df['pred_value'][j : j + 49][df['pred_index'] == i].values)/(len(df['pred_value'][j : j + 50][df['pred_index'] == i].values.tolist()) + +0.000001)\n",
    "        if mean_score >= best_score  :\n",
    "            best_score = mean_score\n",
    "            best_cls = i\n",
    "\n",
    "    pred_list[cnt] = best_cls\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0b7dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "df['label'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2f34dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./results/div_2width_effib0_224.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c48762",
   "metadata": {},
   "source": [
    "## 이미지 channel 단위로 겹치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11205993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6453e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    img_stack = []\n",
    "    label_stack = []\n",
    "    _transforms = A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        # A.Resize(224, 224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False,\n",
    "                    p=1.0),\n",
    "    ])\n",
    "    print(batch[:][0].shape)\n",
    "    for img, label in batch:\n",
    "        # img 나누기\n",
    "#         w_ratio = int(img.shape[1] / 16)\n",
    "#         h_ratio = int(img.shape[0] / 8) # 16\n",
    "\n",
    "        label_stack.append(label)\n",
    "        label_stack.append(img)\n",
    "#         for w in range(16):\n",
    "#             for h in range(8): # 16\n",
    "#                 cropped_img = _transforms(image=img[h * h_ratio: (h + 1) * h_ratio, w * w_ratio: (w + 1) * w_ratio])['image'].transpose(2, 0, 1)\n",
    "#                 img_stack.append(cropped_img.tolist())\n",
    "\n",
    "    return torch.Tensor(img_stack), torch.Tensor(label_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85eac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ChannelStackDataset(Dataset):\n",
    "    def __init__(self, _df, labels, transform=None):\n",
    "        self._df = _df\n",
    "        self.labels = labels\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self._df['img_path'].iloc[index]\n",
    "        \n",
    "        # print(img_path)\n",
    "        # image = cv2.imread(os.path.join('./data', *img_path.split('/')[2:]))\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if self.transform :\n",
    "            image = self.transform(image=image)['image']\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "csv_path = \"./data/div_2width_train.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "label_set = df['label']\n",
    "transform = A.Compose([\n",
    "                A.Resize(224, 224),\n",
    "                # A.Rotate(limit=(45), p=1),\n",
    "                # A.RandomGridShuffle(p=grid_shuffle_p, grid=(2,2)),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "ds = _ChannelStackDataset(df, label_set, transform)\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=False, num_workers=1)#, collate_fn=collate_fn)\n",
    "\n",
    "for img, label in dl :\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39423f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__._ChannelStackDataset at 0x1b2e6f4a4c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb2e45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1b2e6f5a850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f7b8434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdl\u001b[49m :\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(label\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dl' is not defined"
     ]
    }
   ],
   "source": [
    "for img, label in dl :\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c68b7",
   "metadata": {},
   "source": [
    "## timing, weather, ego-involve + crash 학습용 csv 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b862d89",
   "metadata": {},
   "source": [
    "### timing\n",
    "- night = 0\n",
    "- day = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb79e48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day :  40400\n",
      "night :  5350\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/50frame_train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "_df = df[df['label'] != 0]\n",
    "\n",
    "new_label = [1 if label % 2 == 1 else 0 for label in _df['label'] ]\n",
    "print(\"day : \",new_label.count(1))\n",
    "print(\"night : \",new_label.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9a5457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quhb2\\AppData\\Local\\Temp\\ipykernel_42468\\3172057110.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['label'] = new_label\n"
     ]
    }
   ],
   "source": [
    "_df['label'] = new_label\n",
    "\n",
    "path = \"./data/50f_timing_train.csv\"\n",
    "_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8fc34182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.55140187, 1.        ])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day =  40400\n",
    "night =  5350\n",
    "z = [5350, 40400]\n",
    "np.max(z)/np.array(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f3efe",
   "metadata": {},
   "source": [
    "### weather\n",
    "- normal = 0\n",
    "- snowy = 1\n",
    "- Rainy = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ac2fbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal :  35800\n",
      "swnoy :  6450\n",
      "rainy :  3500\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/50frame_train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "_df = df[df['label'] != 0]\n",
    "\n",
    "new_label = []\n",
    "for label in _df['label'] : \n",
    "    \n",
    "    # normal\n",
    "    if label in [1,2,7,8] :\n",
    "        new_label.append(0)\n",
    "    \n",
    "    # swnoy\n",
    "    elif label in [3,4,9,10] :\n",
    "        new_label.append(1)\n",
    "    \n",
    "    # rainy\n",
    "    elif label in [5,6,11,12] :\n",
    "        new_label.append(2)\n",
    "        \n",
    "\n",
    "print(\"normal : \",new_label.count(0))\n",
    "print(\"swnoy : \",new_label.count(1))\n",
    "print(\"rainy : \",new_label.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71b24d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quhb2\\AppData\\Local\\Temp\\ipykernel_42468\\279117756.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['label'] = new_label\n"
     ]
    }
   ],
   "source": [
    "_df['label'] = new_label\n",
    "\n",
    "path = \"./data/50f_weather_train.csv\"\n",
    "_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "40817ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  5.5503876 , 10.22857143])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal =  35800\n",
    "swnoy =  6450\n",
    "rainy =  3500\n",
    "z = [normal, swnoy, rainy]\n",
    "np.max(z)/np.array(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9ee56",
   "metadata": {},
   "source": [
    "### ego-involve + crash \n",
    "- No ego + No crash = 0\n",
    "- No ego + crash = 1\n",
    "- ego + cash= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbe5a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ego + No crash :  89150\n",
      "No ego + crash :  21200\n",
      "ego + cash :  24550\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/50frame_train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "new_label = []\n",
    "for label in df['label'] :\n",
    "    # No ego + No crash\n",
    "    if label == 0 :\n",
    "        new_label.append(0)\n",
    "    \n",
    "    #No ego + crash = 1\n",
    "    elif label in [7, 8, 9, 10, 11, 12] : \n",
    "        new_label.append(1)\n",
    "    \n",
    "    # ego + cash = 2\n",
    "    elif label in [1, 2, 3, 4, 5, 6] :\n",
    "        new_label.append(2)\n",
    "    \n",
    "print(\"No ego + No crash : \",new_label.count(0))\n",
    "print(\"No ego + crash : \",new_label.count(1))\n",
    "print(\"ego + cash : \",new_label.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae291670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = new_label\n",
    "\n",
    "path = \"./data/50f_EgoCrash_train.csv\"\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a85fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d73d3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module) :\n",
    "    def __init__(self, alpha=2, gamma=2, logits=False, reduction='none') :\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets) :\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction=self.reduction)(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction :\n",
    "            return torch.mean(F_loss)\n",
    "        else :\n",
    "            return F_loss\n",
    "        \n",
    "crit = FocalLoss()\n",
    "# crit = nn.BCEWithLogitsLoss().to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cd32ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a= torch.tensor([1, 0, 0, 0, 0, 1, 1, 1], dtype=torch.float)\n",
    "a =  torch.tensor([1, 1,  1, 0], dtype=torch.float)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6972cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= torch.tensor([[1, 0], [1, 0], [0, 1],[0, 1]], dtype=torch.float)\n",
    "b.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "684002ab",
   "metadata": {},
   "source": [
    "## Ego + crash 모자이크 이미지 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f819dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\quhb2\\Documents\\git\\toy\\car_crash_analyze\\code_test.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/quhb2/Documents/git/toy/car_crash_analyze/code_test.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./data/50f_EgoCrash_train.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/quhb2/Documents/git/toy/car_crash_analyze/code_test.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"./data/50f_EgoCrash_train.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72435a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "edddd25bb01c7a9f6b77bab809d0d817375e814cb661fb0745c62e904a0f5921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
