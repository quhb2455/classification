{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>23785</td>\n",
       "      <td>20008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>48871</td>\n",
       "      <td>48195</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>42309</td>\n",
       "      <td>15545</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286</td>\n",
       "      <td>EC</td>\n",
       "      <td>37204</td>\n",
       "      <td>30020</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>65022</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>53355</td>\n",
       "      <td>46675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>65094</td>\n",
       "      <td>MC</td>\n",
       "      <td>55042</td>\n",
       "      <td>45080</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>65300</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>75860</td>\n",
       "      <td>27503</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>65371</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>42551</td>\n",
       "      <td>41800</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>65533</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>45190</td>\n",
       "      <td>33980</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id label  image_width  image_height  is_tma\n",
       "0           4  HGSC        23785         20008   False\n",
       "1          66  LGSC        48871         48195   False\n",
       "2          91  HGSC         3388          3388    True\n",
       "3         281  LGSC        42309         15545   False\n",
       "4         286    EC        37204         30020   False\n",
       "..        ...   ...          ...           ...     ...\n",
       "533     65022  LGSC        53355         46675   False\n",
       "534     65094    MC        55042         45080   False\n",
       "535     65300  HGSC        75860         27503   False\n",
       "536     65371  HGSC        42551         41800   False\n",
       "537     65533  HGSC        45190         33980   False\n",
       "\n",
       "[538 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"./data/train.csv\"\n",
    "df = pd.read_csv(p)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(df[\"is_tma\"].values.tolist()[0], bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 종류 및 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HGSC    222\n",
       "EC      124\n",
       "CC       99\n",
       "LGSC     47\n",
       "MC       46\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"./data/train.csv\"\n",
    "df = pd.read_csv(p)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 별 데이터 시각화\n",
    "- 크기를 512 x 512 로 줄여서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_path = \"./data/train_thumbnails\"\n",
    "p = \"./data/train.csv\"\n",
    "df = pd.read_csv(p)\n",
    "\n",
    "f, axs = plt.subplots(5,5, figsize=(50,50))\n",
    "\n",
    "\n",
    "label_name = df['label'].unique()\n",
    "for i, ln in enumerate(label_name) :\n",
    "    label_list = df['image_id'][df['label'] == ln].values\n",
    "    \n",
    "    while 1:\n",
    "        pick_num = np.random.choice(len(label_list), 5, replace=False)\n",
    "        pick_label = label_list[pick_num]\n",
    "        flag = False\n",
    "        for j, num in enumerate(pick_label) :\n",
    "            img_path = os.path.join(root_path, str(num)+\"_thumbnail.png\")\n",
    "            if os.path.exists(img_path) :\n",
    "                flag = True\n",
    "            else :\n",
    "                flag = False\n",
    "                break\n",
    "        \n",
    "    for j, num in enumerate(pick_label) :\n",
    "        img_path = os.path.join(root_path, str(num)+\"_thumbnail.png\")\n",
    "        \n",
    "        if os.path.exists(img_path) :\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (512, 512))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "            \n",
    "            axs[i][j].imshow(img)\n",
    "            axs[i][j].set_title(f\"{ln} : {num}_thumbnail.png\")\n",
    "            \n",
    "        else :\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1660,  1943,  1952,  3191,  4827,  4877,  5970,  6359,  6449,\n",
       "        7482,  7955,  8279,  9658, 10548, 11263, 12222, 12442, 13526,\n",
       "       13987, 14051, 15231, 15470, 15486, 16325, 16876, 17067, 17291,\n",
       "       18014, 18813, 20205, 21929, 22155, 22290, 22425, 22489, 24563,\n",
       "       25923, 25928, 26219, 26533, 26950, 27315, 28603, 29615, 29915,\n",
       "       30203, 30272, 30369, 31033, 32032, 35197, 36063, 36302, 38349,\n",
       "       38669, 38687, 39880, 40129, 40888, 41586, 42125, 42296, 42549,\n",
       "       42857, 43796, 44283, 44581, 44603, 44976, 45725, 45990, 46543,\n",
       "       46769, 47960, 48506, 51346, 52259, 52375, 52420, 52461, 52931,\n",
       "       53377, 54928, 55287, 56861, 56947, 57598, 57696, 58947, 58974,\n",
       "       59515, 60685, 60988, 61961, 62828, 63015, 63165, 63289, 64824],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 'CC']['image_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일정 pixel 값 이상이면 0으로 채워서 배경삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./data/train_thumbnails/\"\n",
    "fn = \"_thumbnail.png\"\n",
    "p = \"./data/train.csv\"\n",
    "df = pd.read_csv(p)\n",
    "no_tma_df = df[df[\"is_tma\"] == False]\n",
    "\n",
    "sampling_num = np.random.choice(len(no_tma_df), 5, replace=False)\n",
    "sampled_df = no_tma_df.iloc[sampling_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(5,6, figsize=(50,50))\n",
    "for i in range(6) :\n",
    "    for idx, _df in enumerate(sampled_df.iloc) :\n",
    "        path = os.path.join(root_path, str(_df['image_id'])+fn)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "        ori_shape = img.shape[:2]\n",
    "        \n",
    "        if i == 0 : \n",
    "            img[np.where((img > [200, 200, 200]).all(axis = 2))] = [0,0,0]\n",
    "            t = 200\n",
    "        elif i == 1 :\n",
    "            img[np.where((img > [215, 215, 215]).all(axis = 2))] = [0,0,0]\n",
    "            t = 215\n",
    "        elif i == 2 :\n",
    "            img[np.where((img > [225, 225, 225]).all(axis = 2))] = [0,0,0]\n",
    "            t = 225\n",
    "        elif i == 3 :\n",
    "            img[np.where((img > [235, 235, 235]).all(axis = 2))] = [0,0,0]\n",
    "            t = 235\n",
    "        elif i == 4 :\n",
    "            img[np.where((img > [245, 245, 245]).all(axis = 2))] = [0,0,0]\n",
    "            t = 255\n",
    "        \n",
    "        img = cv2.resize(img, (512, 512))\n",
    "        axs[idx][i].imshow(img)\n",
    "        axs[idx][i].set_title(\"threshold : \" + str(t))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1개의 이미지 내에 여러개의 객체가 있는 이미지 분할 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./data/train_thumbnails/\"\n",
    "fn = \"_thumbnail.png\"\n",
    "p = \"./data/train.csv\"\n",
    "df = pd.read_csv(p)\n",
    "no_tma_df = df[df[\"is_tma\"] == False]\n",
    "\n",
    "sampling_num = np.random.choice(len(no_tma_df), 5, replace=False)\n",
    "sampled_df = no_tma_df.iloc[sampling_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = [706, 1660, 1666, 2706, 1943, 1774, 46444, 48502, 61100, 59031]\n",
    "f, axs = plt.subplots(len(sampled_df), 6, figsize=(50,50))\n",
    "for i, _df in enumerate(sampled_df) :\n",
    "    path = os.path.join(root_path, str(_df)+fn)\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cropped_images= []\n",
    "    idx = 0\n",
    "    for j, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        cropped_image[np.where((cropped_image > [215, 215, 215]).all(axis = 2))] = [0,0,0]\n",
    "        # if w > 200 and h > 200 :\n",
    "        if np.sum(np.array(cropped_image))>10000000:\n",
    "            # cropped_images.append(cropped_image)\n",
    "            h, w = cropped_image.shape[:2]\n",
    "            cropped_image = cv2.resize(cropped_image, (512, 512))\n",
    "            axs[i][idx].imshow(cropped_image)\n",
    "            axs[i][idx].set_title(str(_df) + \" >> w : \" + str(w) + \" // h : \"+str(h))\n",
    "            idx += 1\n",
    "            \n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5, 6, 7]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [5,6,7]\n",
    "\n",
    "a = a+b\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ckpt/tf_efficientnetv2_s.in21k/rmbg_lossweight_effiv2s_512\\\\0E-val0.3833333333333334-tf_efficientnetv2_s.in21k.pth',\n",
       " './ckpt/tf_efficientnetv2_s.in21k/rmbg_lossweight_effiv2s_512\\\\2E-val0.3903846153846154-tf_efficientnetv2_s.in21k - 복사본.pth',\n",
       " './ckpt/tf_efficientnetv2_s.in21k/rmbg_lossweight_effiv2s_512\\\\3E-val0.3903846153846154-tf_efficientnetv2_s.in21k.pth',\n",
       " './ckpt/tf_efficientnetv2_s.in21k/rmbg_lossweight_effiv2s_512\\\\10E-val0.3903846153846154-tf_efficientnetv2_s.in21k - 복사본 - 복사본.pth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "p = \"./ckpt/tf_efficientnetv2_s.in21k/rmbg_lossweight_effiv2s_512/*.pth\"\n",
    "sorted(glob(p), key=lambda x:int(os.path.basename(x).split(\"E-\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models(\"*efficient*\", pretrained=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
