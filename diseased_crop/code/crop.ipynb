{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4636868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json \n",
    "import timm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa2ce4",
   "metadata": {},
   "source": [
    "# Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd44a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설명 csv 파일 참조\n",
    "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
    "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
    "risk = {'1':'초기','2':'중기','3':'말기'}\n",
    "\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "def label_preprocessing(path) :\n",
    "    labels = pd.read_csv(path)\n",
    "\n",
    "    label_encoder = {}\n",
    "    label_cnt = 0\n",
    "    previous_label = '0_00_0'\n",
    "    for i, label in enumerate(tqdm(sorted(labels['label']))) :\n",
    "        crop_val = label.split('_')[0] # crop\n",
    "        disease_val = label.split('_')[1] # disease\n",
    "        risk_val = label.split('_')[2] # risk\n",
    "\n",
    "        tmp_label = f'{crop_val}_{disease_val}_{risk_val}'\n",
    "        if previous_label != tmp_label :\n",
    "            train_label_encoder[tmp_label] = label_cnt\n",
    "            previous_label = tmp_label\n",
    "            label_cnt += 1\n",
    "\n",
    "    train_label_decoder = {val : key for key, val in train_label_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_preprocessing(path) :\n",
    "    labels = pd.read_csv(path)\n",
    "\n",
    "    label_encoder = {}\n",
    "    for i, label in enumerate(tqdm(sorted(labels['label']))) :\n",
    "        \n",
    "        if label in label_encoder\n",
    "        \n",
    "        tmp_label = f'{crop_val}_{disease_val}_{risk_val}'\n",
    "        if previous_label != tmp_label :\n",
    "            train_label_encoder[tmp_label] = label_cnt\n",
    "            previous_label = tmp_label\n",
    "            label_cnt += 1\n",
    "\n",
    "    train_label_decoder = {val : key for key, val in train_label_encoder.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45adac9d",
   "metadata": {},
   "source": [
    "# CSV feature - min, max value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195590dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_feature_dict(path, csv_features) :\n",
    "    \n",
    "    csv_files = sorted(glob(os.path.joing(path, '*/*.csv')))\n",
    "\n",
    "    temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
    "    max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "\n",
    "    # feature 별 최대값, 최솟값 계산\n",
    "    for csv in tqdm(csv_files[1:]):\n",
    "        temp_csv = pd.read_csv(csv)[csv_features]\n",
    "        temp_csv = temp_csv.replace('-',np.nan).dropna()\n",
    "        if len(temp_csv) == 0:\n",
    "            continue\n",
    "        temp_csv = temp_csv.astype(float)\n",
    "        temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "        max_arr = np.max([max_arr,temp_max], axis=0)\n",
    "        min_arr = np.min([min_arr,temp_min], axis=0)\n",
    "\n",
    "    # feature 별 최대값, 최솟값 dictionary return\n",
    "    return {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69b5c3",
   "metadata": {},
   "source": [
    "# Custom Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, transforms, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.files = files\n",
    "        self.label_encoder = train_label_encoder #label_encoder\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file = self.files[i]\n",
    "        file_name = file.split('\\\\')[-1]\n",
    "        \n",
    "        \n",
    "        # image\n",
    "        image_path = f'{file}/{file_name}.jpg'\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "#         img = img.astype(np.float32)/255\n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        img = img.transpose(2,0,1)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            json_path = f'{file}/{file_name}.json'\n",
    "            with open(json_path, 'r') as f:\n",
    "                json_file = json.load(f)\n",
    "            \n",
    "            crop = json_file['annotations']['crop']\n",
    "            disease = json_file['annotations']['disease']\n",
    "            risk = json_file['annotations']['risk']\n",
    "            label = f'{crop}_{disease}_{risk}'\n",
    "            \n",
    "            return {\n",
    "#                 'img' : torch.tensor(img, dtype=torch.float32),\n",
    "                'img' : torch.tensor(img, dtype=torch.float32) / 255.0,\n",
    "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'img' : torch.tensor(img, dtype=torch.float32)/ 255.0\n",
    "#                 'img' : torch.tensor(img, dtype=torch.float32)\n",
    "            }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
