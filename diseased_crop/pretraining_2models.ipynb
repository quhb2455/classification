{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71182e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json \n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b4f649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple___Apple_scab': 0,\n",
       " 'Apple___Black_rot': 1,\n",
       " 'Apple___Cedar_apple_rust': 2,\n",
       " 'Apple___healthy': 3,\n",
       " 'Blueberry___healthy': 4,\n",
       " 'Cherry_(including_sour)___healthy': 5,\n",
       " 'Cherry_(including_sour)___Powdery_mildew': 6,\n",
       " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7,\n",
       " 'Corn_(maize)___Common_rust_': 8,\n",
       " 'Corn_(maize)___healthy': 9,\n",
       " 'Corn_(maize)___Northern_Leaf_Blight': 10,\n",
       " 'Grape___Black_rot': 11,\n",
       " 'Grape___Esca_(Black_Measles)': 12,\n",
       " 'Grape___healthy': 13,\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 14,\n",
       " 'Orange___Haunglongbing_(Citrus_greening)': 15,\n",
       " 'Peach___Bacterial_spot': 16,\n",
       " 'Peach___healthy': 17,\n",
       " 'Pepper,_bell___Bacterial_spot': 18,\n",
       " 'Pepper,_bell___healthy': 19,\n",
       " 'Potato___Early_blight': 20,\n",
       " 'Potato___healthy': 21,\n",
       " 'Potato___Late_blight': 22,\n",
       " 'Raspberry___healthy': 23,\n",
       " 'Soybean___healthy': 24,\n",
       " 'Squash___Powdery_mildew': 25,\n",
       " 'Strawberry___healthy': 26,\n",
       " 'Strawberry___Leaf_scorch': 27,\n",
       " 'Tomato___Bacterial_spot': 28,\n",
       " 'Tomato___Early_blight': 29,\n",
       " 'Tomato___healthy': 30,\n",
       " 'Tomato___Late_blight': 31,\n",
       " 'Tomato___Leaf_Mold': 32,\n",
       " 'Tomato___Septoria_leaf_spot': 33,\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite': 34,\n",
       " 'Tomato___Target_Spot': 35,\n",
       " 'Tomato___Tomato_mosaic_virus': 36,\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 37}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Apple___Apple_scab',\n",
       " 1: 'Apple___Black_rot',\n",
       " 2: 'Apple___Cedar_apple_rust',\n",
       " 3: 'Apple___healthy',\n",
       " 4: 'Blueberry___healthy',\n",
       " 5: 'Cherry_(including_sour)___healthy',\n",
       " 6: 'Cherry_(including_sour)___Powdery_mildew',\n",
       " 7: 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 8: 'Corn_(maize)___Common_rust_',\n",
       " 9: 'Corn_(maize)___healthy',\n",
       " 10: 'Corn_(maize)___Northern_Leaf_Blight',\n",
       " 11: 'Grape___Black_rot',\n",
       " 12: 'Grape___Esca_(Black_Measles)',\n",
       " 13: 'Grape___healthy',\n",
       " 14: 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 15: 'Orange___Haunglongbing_(Citrus_greening)',\n",
       " 16: 'Peach___Bacterial_spot',\n",
       " 17: 'Peach___healthy',\n",
       " 18: 'Pepper,_bell___Bacterial_spot',\n",
       " 19: 'Pepper,_bell___healthy',\n",
       " 20: 'Potato___Early_blight',\n",
       " 21: 'Potato___healthy',\n",
       " 22: 'Potato___Late_blight',\n",
       " 23: 'Raspberry___healthy',\n",
       " 24: 'Soybean___healthy',\n",
       " 25: 'Squash___Powdery_mildew',\n",
       " 26: 'Strawberry___healthy',\n",
       " 27: 'Strawberry___Leaf_scorch',\n",
       " 28: 'Tomato___Bacterial_spot',\n",
       " 29: 'Tomato___Early_blight',\n",
       " 30: 'Tomato___healthy',\n",
       " 31: 'Tomato___Late_blight',\n",
       " 32: 'Tomato___Leaf_Mold',\n",
       " 33: 'Tomato___Septoria_leaf_spot',\n",
       " 34: 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 35: 'Tomato___Target_Spot',\n",
       " 36: 'Tomato___Tomato_mosaic_virus',\n",
       " 37: 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "village_data = os.listdir('./data/public/PlantVillage')\n",
    "label_encoder = {}\n",
    "for idx, data_name in enumerate(village_data) :\n",
    "    label_encoder[idx] = data_name\n",
    "\n",
    "label_decoder = {val:key for key, val in label_encoder.items()}\n",
    "display(label_decoder)\n",
    "display(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83eac1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    " \n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2423ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "class DeiT(nn.Module):\n",
    "    def __init__(self, model_name_1, n_classes):\n",
    "        super(DeiT, self).__init__()\n",
    "        self.model = timm.create_model(model_name_1, num_classes=n_classes, pretrained=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "    \n",
    "class EffiV2S(nn.Module):\n",
    "    def __init__(self, model_name_2, n_classes):\n",
    "        super(EffiV2S, self).__init__()\n",
    "        self.model = timm.create_model(model_name_2, num_classes=n_classes, pretrained=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "    \n",
    "class total_model(nn.Module):\n",
    "    def __init__(self, model_name_1, model_name_2, n_classes) :\n",
    "        super(total_model, self).__init__()\n",
    "        self.effi = EffiV2S(model_name_1, n_classes)\n",
    "        self.DeiT = DeiT(model_name_2, n_classes)\n",
    "        \n",
    "    def forward(self, input_224, input_288) : \n",
    "        output1 = self.effi(input_288)\n",
    "        output2 = self.DeiT(input_224)\n",
    "        \n",
    "        output = (output1 + output2) / 2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5265206",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")#(\"cpu\")\n",
    "batch_size = 8\n",
    "n_classes = 38\n",
    "model_name_1 = 'efficientnetv2_rw_s'\n",
    "model_name_2 = 'deit_small_patch16_224'\n",
    "learning_rate = 1e-4\n",
    "epochs = 15\n",
    "save_path = './model/public_vill_50k_pretrain_EffiDeit.pt'\n",
    "num_early_stopping = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554f910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VillageDataset(Dataset) :\n",
    "    def __init__(self, files, transform_224, transform_288, mode='train') :\n",
    "        super(VillageDataset, self).__init__()\n",
    "        self.files = files\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.transform_224 = transform_224\n",
    "        self.transform_288 = transform_288\n",
    "      \n",
    "    def __len__(self) :\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        file_path = self.files[idx]\n",
    "        \n",
    "        label = label_decoder[file_path.split('\\\\')[-2]]\n",
    "        \n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_224 = self.transform_224(image=img)['image']\n",
    "        img_288 = self.transform_288(image=img)['image']\n",
    "        \n",
    "        img_224 = img_224.transpose(2, 0, 1)\n",
    "        img_288 = img_288.transpose(2, 0, 1)\n",
    "        \n",
    "#         return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "        return {\n",
    "            'effi' : torch.tensor(img_288, dtype=torch.float32) / 255.0,\n",
    "            'deit' : torch.tensor(img_224, dtype=torch.float32) / 255.0,\n",
    "            'label' : torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "#         return torch.tensor(img, dtype=torch.float32) / 255.0, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018bbe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total :  54303\n",
      "train :  43442\n",
      "val :  10861\n"
     ]
    }
   ],
   "source": [
    "train_transforms_224 = A.Compose([\n",
    "                A.Resize(224 ,224),\n",
    "                A.OneOf([\n",
    "                    A.Rotate(),\n",
    "                    A.HorizontalFlip(),\n",
    "                    A.VerticalFlip()\n",
    "                ], p=1)\n",
    "            ])\n",
    "\n",
    "train_transforms_288 = A.Compose([\n",
    "                A.Resize(288 ,288),\n",
    "                A.OneOf([\n",
    "                    A.Rotate(),\n",
    "                    A.HorizontalFlip(),\n",
    "                    A.VerticalFlip()\n",
    "                ], p=1)\n",
    "            ])\n",
    "\n",
    "val_transforms_224 = A.Compose([\n",
    "    A.Resize(224,224)\n",
    "])\n",
    "val_transforms_288 = A.Compose([\n",
    "    A.Resize(288,288)\n",
    "])\n",
    "\n",
    "train = glob('./data/public/PlantVillage/*/*.JPG')\n",
    "print(\"total : \", len(train))\n",
    "label_list = [label_decoder[img_path.split('\\\\')[-2]] for img_path in train]\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2, shuffle=True, stratify=label_list)\n",
    "print(\"train : \", len(train))\n",
    "print(\"val : \", len(val))\n",
    "\n",
    "train_dataset = VillageDataset(train, train_transforms_224, train_transforms_288)\n",
    "val_dataset = VillageDataset(val, val_transforms_224, val_transforms_288)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87db2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = total_model(model_name_1, model_name_2, n_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202482e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):    \n",
    "    real = real.cpu()\n",
    "    pred = torch.argmax(pred, dim=1).cpu()\n",
    "    score = f1_score(real, pred, average='macro')\n",
    "    return score\n",
    "\n",
    "def train_step(batch_item, training):\n",
    "    img_effi = batch_item['effi'].to(device) # 288\n",
    "    img_deit = batch_item['deit'].to(device) # 224\n",
    "    label = batch_item['label'].to(device)\n",
    "\n",
    "    lam = np.random.beta(1.0, 1.0)\n",
    "    \n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # add - cutmix\n",
    "            rand_index = torch.randperm(img_deit.size()[0])\n",
    "            target_a = label\n",
    "            target_b = label[rand_index]\n",
    "            \n",
    "            # 224 size 기준으로 이미지 crop\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img_deit.size(), lam)\n",
    "            \n",
    "            img_deit[:, :, bbx1:bbx2, bby1:bby2] = img_deit[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            img_effi[:, :, bbx1:bbx2, bby1:bby2] = img_effi[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # lam 값은 공유\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img_deit.size()[-1] * img_deit.size()[-2]))\n",
    "            \n",
    "            output = model(img_deit, img_effi)\n",
    "            loss = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
    "#             output = model(img, csv_feature)\n",
    "#             loss = criterion(output, label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        score = accuracy_function(label, output)\n",
    "        return loss, score\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img_deit, img_effi)\n",
    "            loss = criterion(output, label)\n",
    "        score = accuracy_function(label, output)\n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e145c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5431it [21:19,  4.25it/s, Epoch=1, Loss=0.624950, Mean Loss=0.939954, Mean F-1=0.688476]\n",
      "1358it [02:01, 11.22it/s, Epoch=1, Val Loss=0.009675, Mean Val Loss=0.047106, Mean Val F-1=0.980876]\n",
      "5431it [23:46,  3.81it/s, Epoch=2, Loss=0.011112, Mean Loss=0.662797, Mean F-1=0.753075]\n",
      "1358it [02:40,  8.44it/s, Epoch=2, Val Loss=0.006284, Mean Val Loss=0.036876, Mean Val F-1=0.986077]\n",
      "5431it [28:51,  3.14it/s, Epoch=3, Loss=0.764464, Mean Loss=0.609953, Mean F-1=0.769400]\n",
      "1358it [04:57,  4.57it/s, Epoch=3, Val Loss=0.007251, Mean Val Loss=0.094473, Mean Val F-1=0.990559]\n",
      "2736it [16:40,  2.60it/s, Epoch=4, Loss=0.648836, Mean Loss=0.597982, Mean F-1=0.780314]"
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "metric_plot, val_metric_plot = [], []\n",
    "\n",
    "early_stopping = 0\n",
    "for epoch in range(epochs):\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "\n",
    "    tqdm_dataset = tqdm(enumerate(train_loader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, training)\n",
    "        total_loss += batch_loss\n",
    "        total_acc += batch_acc\n",
    "\n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Mean Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "            'Mean F-1' : '{:06f}'.format(total_acc/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    metric_plot.append(total_acc/(batch+1))\n",
    "\n",
    "    tqdm_dataset = tqdm(enumerate(val_loader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, training)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_acc += batch_acc\n",
    "\n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Mean Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "            'Mean Val F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    val_metric_plot.append(total_val_acc/(batch+1))\n",
    "    \n",
    "    if np.max(val_metric_plot) == val_metric_plot[-1]:\n",
    "        torch.save(model.state_dict(), f'{save_path}')\n",
    "        early_stopping = 0\n",
    "    \n",
    "    elif np.max(val_metric_plot) > val_metric_plot[-1]: \n",
    "        early_stopping += 1\n",
    "        print(f\"Early Stopping Step : [{early_stopping} / {num_early_stopping}]\")\n",
    "    \n",
    "    if early_stopping == num_early_stopping :\n",
    "        print(\"== Early Stop ==\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2206d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f58bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3206d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d54519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9e592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
