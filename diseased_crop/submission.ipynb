{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36593dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json \n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bebd2",
   "metadata": {},
   "source": [
    "# Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c99e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설명 csv 파일 참조\n",
    "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
    "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
    "risk = {'1':'초기','2':'중기','3':'말기'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7908b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 5767/5767 [00:00<00:00, 961618.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: '1_00_0',\n",
       " 1: '2_00_0',\n",
       " 2: '2_a5_2',\n",
       " 3: '3_00_0',\n",
       " 4: '3_a9_1',\n",
       " 5: '3_a9_2',\n",
       " 6: '3_a9_3',\n",
       " 7: '3_b3_1',\n",
       " 8: '3_b6_1',\n",
       " 9: '3_b7_1',\n",
       " 10: '3_b8_1',\n",
       " 11: '4_00_0',\n",
       " 12: '5_00_0',\n",
       " 13: '5_a7_2',\n",
       " 14: '5_b6_1',\n",
       " 15: '5_b7_1',\n",
       " 16: '5_b8_1',\n",
       " 17: '6_00_0',\n",
       " 18: '6_a11_1',\n",
       " 19: '6_a11_2',\n",
       " 20: '6_a12_1',\n",
       " 21: '6_a12_2',\n",
       " 22: '6_b4_1',\n",
       " 23: '6_b4_3',\n",
       " 24: '6_b5_1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'1_00_0': 0,\n",
       " '2_00_0': 1,\n",
       " '2_a5_2': 2,\n",
       " '3_00_0': 3,\n",
       " '3_a9_1': 4,\n",
       " '3_a9_2': 5,\n",
       " '3_a9_3': 6,\n",
       " '3_b3_1': 7,\n",
       " '3_b6_1': 8,\n",
       " '3_b7_1': 9,\n",
       " '3_b8_1': 10,\n",
       " '4_00_0': 11,\n",
       " '5_00_0': 12,\n",
       " '5_a7_2': 13,\n",
       " '5_b6_1': 14,\n",
       " '5_b7_1': 15,\n",
       " '5_b8_1': 16,\n",
       " '6_00_0': 17,\n",
       " '6_a11_1': 18,\n",
       " '6_a11_2': 19,\n",
       " '6_a12_1': 20,\n",
       " '6_a12_2': 21,\n",
       " '6_b4_1': 22,\n",
       " '6_b4_3': 23,\n",
       " '6_b5_1': 24}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_description = {}\n",
    "for key, value in disease.items():\n",
    "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
    "    for disease_code in value:\n",
    "        for risk_code in risk:\n",
    "            label = f'{key}_{disease_code}_{risk_code}'\n",
    "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n",
    "\n",
    "# ============= add\n",
    "labels = pd.read_csv('./data/train.csv')\n",
    "\n",
    "train_label_encoder = {}\n",
    "label_cnt = 0\n",
    "previous_label = '0_00_0'\n",
    "for i, label in enumerate(tqdm(sorted(labels['label']))) :\n",
    "    crop_val = label.split('_')[0] # crop\n",
    "    disease_val = label.split('_')[1] # disease\n",
    "    risk_val = label.split('_')[2] # risk\n",
    "    \n",
    "    tmp_label = f'{crop_val}_{disease_val}_{risk_val}'\n",
    "    if previous_label != tmp_label :\n",
    "        train_label_encoder[tmp_label] = label_cnt\n",
    "        previous_label = tmp_label\n",
    "        label_cnt += 1\n",
    "        \n",
    "train_label_decoder = {val : key for key, val in train_label_encoder.items()}\n",
    "display(train_label_decoder)\n",
    "display(train_label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a394a26",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e19b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, transforms):\n",
    "        self.files = files\n",
    "        self.label_encoder = train_label_encoder #label_encoder\n",
    "        \n",
    "        self.deit_transforms = transforms[0]\n",
    "        self.effi_transforms = transforms[1]\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file = self.files[i]\n",
    "        file_name = file.split('\\\\')[-1]\n",
    "        \n",
    "        \n",
    "        # image\n",
    "        image_path = f'{file}/{file_name}.jpg'\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        deit_img = self.deit_transforms(image=img)[\"image\"]\n",
    "        effi_img = self.effi_transforms(image=img)[\"image\"]\n",
    "        \n",
    "        deit_img = deit_img.transpose(2,0,1)\n",
    "        effi_img = effi_img.transpose(2,0,1)\n",
    "        \n",
    "        return {\n",
    "            'deit_img' : torch.tensor(deit_img, dtype=torch.float32)/ 255.0,\n",
    "            'effi_img' : torch.tensor(effi_img, dtype=torch.float32)/ 255.0,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d8361",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e82cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViT, self).__init__()\n",
    "        self.model = timm.create_model('vit_small_patch16_224', num_classes=25, pretrained=True)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "class pretrained_DeiT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pretrained_DeiT, self).__init__()\n",
    "        self.model = timm.create_model('deit_small_patch16_224', num_classes=38, pretrained=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "class pretrained_EffiV2S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pretrained_EffiV2S, self).__init__()\n",
    "        self.model = timm.create_model('efficientnetv2_rw_s', num_classes=38, pretrained=False)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    \n",
    "class Deit(nn.Module) :\n",
    "    def __init__(self, model_path=None, test=False) :\n",
    "        super(Deit, self).__init__()\n",
    "        self.pre_model = pretrained_DeiT()\n",
    "        if test == False :\n",
    "            self.pre_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        \n",
    "        self.fc = nn.Linear(38, 25)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.pre_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class EffiV2S(nn.Module) :\n",
    "    def __init__(self, model_path=None, test=False) :\n",
    "        super(EffiV2S, self).__init__()\n",
    "        self.pre_model = pretrained_EffiV2S()\n",
    "        if test == False :\n",
    "            self.pre_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        \n",
    "        self.fc = nn.Linear(38, 25)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.pre_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86948eb1",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e666b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")#(\"cpu\")\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa1952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deit_transforms = A.Compose([\n",
    "    A.Resize(224, 224)\n",
    "])\n",
    "\n",
    "effi_transforms = A.Compose([\n",
    "    A.Resize(288, 288)\n",
    "])\n",
    "\n",
    "test = sorted(glob('data/test/*'))\n",
    "test_dataset = CustomDataset(test, (deit_transforms, effi_transforms))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef146b",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58254701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def softvoting(models, img, n_classes=25) :\n",
    "\n",
    "    predicts = torch.zeros(img.size(0), n_classes)\n",
    "    with torch.no_grad() :\n",
    "        for model in models :\n",
    "            output = model(img)\n",
    "            output = F.softmax(output.cpu(), dim=1)\n",
    "            predicts += output\n",
    "\n",
    "    return predicts.detach().cpu() / len(models)\n",
    "\n",
    "\n",
    "def _softvoting(models, img, n_classes=25) :\n",
    "\n",
    "    predicts = torch.zeros(img.size(0), n_classes)\n",
    "    with torch.no_grad() :\n",
    "        for model in models :\n",
    "            output = model(img)\n",
    "            output = F.softmax(output.cpu(), dim=1)\n",
    "            predicts += output\n",
    "\n",
    "    return predicts.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f90d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, models, model_name) :\n",
    "    tqdm_dataset = tqdm(enumerate(dataset))\n",
    "    results = []\n",
    "    for batch, batch_item in tqdm_dataset :\n",
    "        if model_name == 'effi' :\n",
    "            img = batch_item['effi_img'].to(device)\n",
    "\n",
    "        elif model_name == 'deit' :\n",
    "            img = batch_item['deit_img'].to(device)\n",
    "            \n",
    "        predictions = softvoting(models, img)\n",
    "#         print(predictions.shape)\n",
    "        batch_result = [int(torch.argmax(prediction)) for prediction in predictions]\n",
    "        \n",
    "        results.extend(predictions)\n",
    "#         results.append(predictions)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def _predict(dataset, models, model_name) :\n",
    "    tqdm_dataset = tqdm(enumerate(dataset))\n",
    "    results = []\n",
    "    for batch, batch_item in tqdm_dataset :\n",
    "        if model_name == 'effi' :\n",
    "            img = batch_item['effi_img'].to(device)\n",
    "\n",
    "        elif model_name == 'deit' :\n",
    "            img = batch_item['deit_img'].to(device)\n",
    "            \n",
    "        predictions = _softvoting(models, img)\n",
    "#         print(predictions.shape)\n",
    "#         batch_result = [int(torch.argmax(prediction)) for prediction in predictions]\n",
    "        \n",
    "#         results.extend(predictions)\n",
    "        results.append(predictions)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e2f6c",
   "metadata": {},
   "source": [
    "## K fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4230171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_models_path = glob('./model/k_fold_50k_pretrained_deit/*.pt')\n",
    "models = []\n",
    "for kfold_model_path in kfold_models_path :\n",
    "    model = Deit(model_path)\n",
    "#     model = EffiV2S(model_path)\n",
    "    model.load_state_dict(torch.load(kfold_model_path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "preds = predict(test_dataloader, models)\n",
    "\n",
    "preds_cp = preds\n",
    "\n",
    "preds_cp = np.array([train_label_decoder[int(val)] for val in preds_cp])\n",
    "submission_csv = pd.read_csv('./data/sample_submission.csv')\n",
    "submission_csv['label'] = preds_cp\n",
    "submission_csv.to_csv('./data/kfold_public_vill_50k_pretrain_Deit_S16patch224_25E.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46853acb",
   "metadata": {},
   "source": [
    "## single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4333b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_model_path = './model/k_fold_50k_pretrained_effiv2S/4_f94_public_vill_50k_pretrain_efficientnetv2S.pt'\n",
    "# model = EffiV2S(model_path)\n",
    "# model.load_state_dict(torch.load(single_model_path, map_location=device))\n",
    "# model.to(device).eval()\n",
    "\n",
    "# preds = predict(test_dataloader, model)\n",
    "\n",
    "# preds_cp = preds\n",
    "\n",
    "# preds_cp = np.array([train_label_decoder[int(val)] for val in preds_cp])\n",
    "# submission_csv = pd.read_csv('./data/sample_submission.csv')\n",
    "# submission_csv['label'] = preds_cp\n",
    "# submission_csv.to_csv('./data/4fold_public_vill_50k_pretrain_efficientnetv2S.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a83bb1",
   "metadata": {},
   "source": [
    "## 2 - kind of models\n",
    "- effiv2(2) + deit(2) = 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902357d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3245it [11:54,  4.54it/s]\n",
      "3245it [09:30,  5.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# effi_model_path = ['./model/k_fold_50k_pretrained_effiv2S/4_f9462_public_vill_50k_pretrain_efficientnetv2S.pt',\n",
    "#                './model/k_fold_50k_pretrained_effiv2S/1_f9222_public_vill_50k_pretrain_efficientnetv2S.pt']\n",
    "\n",
    "# deit_model_path = ['./model/k_fold_50k_pretrained_deit/1_f9164_public_vill_50k_pretrain_Deit_S16patch224_25E.pt',\n",
    "#               './model/k_fold_50k_pretrained_deit/4_f9082_public_vill_50k_pretrain_Deit_S16patch224_25E.pt']\n",
    "\n",
    "# ensemble_models = [effi_model_path[0], effi_model_path[1], deit_model_path[0], deit_model_path[1]]\n",
    "\n",
    "# effi_models = []\n",
    "# deit_models = []\n",
    "# for ensemble_model_path in ensemble_models :\n",
    "    \n",
    "#     if 'efficient' in ensemble_model_path :\n",
    "#         model = EffiV2S(test=True)\n",
    "#         model.load_state_dict(torch.load(ensemble_model_path, map_location=device))\n",
    "#         model.to(device).eval()\n",
    "#         effi_models.append(model)\n",
    "        \n",
    "#     elif 'Deit' in ensemble_model_path :\n",
    "#         model = Deit(test=True)\n",
    "#         model.load_state_dict(torch.load(ensemble_model_path, map_location=device))\n",
    "#         model.to(device).eval()\n",
    "#         deit_models.append(model)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# effi_preds = _predict(test_dataloader, effi_models, model_name='effi')\n",
    "# deit_preds = _predict(test_dataloader, deit_models, model_name='deit')\n",
    "\n",
    "# effi_preds_cp = effi_preds\n",
    "# deit_preds_cp = deit_preds\n",
    "\n",
    "\n",
    "# # display(len(effi_preds_cp))\n",
    "# # display(effi_preds_cp[0].shape)\n",
    "\n",
    "# # display(len(deit_preds_cp))\n",
    "# # display(deit_preds_cp[0].shape)\n",
    "\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for effi, deit in zip(effi_preds_cp, deit_preds_cp) :\n",
    "#     sum_pred = (effi + deit) / 4\n",
    "    \n",
    "#     batch_result = [int(torch.argmax(prediction)) for prediction in sum_pred]    \n",
    "    \n",
    "#     results.extend(batch_result)\n",
    "# # print(len(results))\n",
    "# predictions = np.array([train_label_decoder[int(val)] for val in results])\n",
    "# submission_csv = pd.read_csv('./data/sample_submission.csv')\n",
    "# submission_csv['label'] = predictions\n",
    "# submission_csv.to_csv('./data/effi_f9462f9222_deit_f9164f9082.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f761462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c55c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cp = np.array([train_label_decoder[int(val)] for val in preds_cp])\n",
    "submission_csv = pd.read_csv('./data/sample_submission.csv')\n",
    "submission_csv['label'] = preds_cp\n",
    "submission_csv.to_csv('./data/effi_f9462f9222_deit_f9164f9082.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
