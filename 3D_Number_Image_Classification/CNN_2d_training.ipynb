{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cac8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py # .h5 파일을 읽기 위한 패키지\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import timm\n",
    "from itertools import permutations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "from cnn_3d import effi, resnet, resneXt\n",
    "\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a45b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174f946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, id_list, label_list, point_list):\n",
    "        self.id_list = id_list\n",
    "        self.label_list = label_list\n",
    "        self.point_list = point_list\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.id_list[index]\n",
    "        \n",
    "        # h5파일을 바로 접근하여 사용하면 학습 속도가 병목 현상으로 많이 느릴 수 있습니다.\n",
    "        points = self.point_list[str(image_id)][:]\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            rand_degree = np.random.choice([-np.pi/12, -np.pi/8, -np.pi/6, -np.pi/4, -np.pi/3], 3)\n",
    "            rotated_points = self.rotate(rand_degree[0], rand_degree[1], rand_degree[2], points)\n",
    "            image = self.get_vector(rotated_points, x_y_z=CFG['voxel_grid'])\n",
    "            label = self.label_list[index]\n",
    "            return torch.Tensor(image).unsqueeze(0), label\n",
    "        else:\n",
    "            image = self.get_vector(points, x_y_z=CFG['voxel_grid'])\n",
    "            return torch.Tensor(image).unsqueeze(0)\n",
    "    \n",
    "    def rotate(self, a, b, c, dots):\n",
    "        mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
    "        my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
    "        mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
    "        m = np.dot(np.dot(mx,my),mz)\n",
    "        dots = np.dot(dots, m.T)\n",
    "        return dots\n",
    "\n",
    "    \n",
    "    def get_vector(self, points, x_y_z=[16, 16, 16]):\n",
    "        # 3D Points -> [16,16,16]\n",
    "        xyzmin = np.min(points, axis=0) - 0.001\n",
    "        xyzmax = np.max(points, axis=0) + 0.001\n",
    "\n",
    "        diff = max(xyzmax-xyzmin) - (xyzmax-xyzmin)\n",
    "        xyzmin = xyzmin - diff / 2\n",
    "        xyzmax = xyzmax + diff / 2\n",
    "\n",
    "        segments = []\n",
    "        shape = []\n",
    "\n",
    "        for i in range(3):\n",
    "            # note the +1 in num \n",
    "            if type(x_y_z[i]) is not int:\n",
    "                raise TypeError(\"x_y_z[{}] must be int\".format(i))\n",
    "            s, step = np.linspace(xyzmin[i], xyzmax[i], num=(x_y_z[i] + 1), retstep=True)\n",
    "            segments.append(s)\n",
    "            shape.append(step)\n",
    "\n",
    "        n_voxels = x_y_z[0] * x_y_z[1] * x_y_z[2]\n",
    "        n_x = x_y_z[0]\n",
    "        n_y = x_y_z[1]\n",
    "        n_z = x_y_z[2]\n",
    "\n",
    "        structure = np.zeros((len(points), 4), dtype=int)\n",
    "        structure[:,0] = np.searchsorted(segments[0], points[:,0]) - 1\n",
    "        structure[:,1] = np.searchsorted(segments[1], points[:,1]) - 1\n",
    "        structure[:,2] = np.searchsorted(segments[2], points[:,2]) - 1\n",
    "\n",
    "        # i = ((y * n_x) + x) + (z * (n_x * n_y))\n",
    "        structure[:,3] = ((structure[:,1] * n_x) + structure[:,0]) + (structure[:,2] * (n_x * n_y)) \n",
    "\n",
    "        vector = np.zeros(n_voxels)\n",
    "        count = np.bincount(structure[:,3])\n",
    "        vector[:len(count)] = count\n",
    "\n",
    "        vector = vector.reshape(n_z, n_y, n_x)\n",
    "        return vector\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bd13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _CustomDataset(Dataset):\n",
    "    def __init__(self, id_list, label_list, point_list, dim='2d', shape=224):\n",
    "        self.id_list = id_list\n",
    "        self.label_list = label_list\n",
    "        self.point_list = point_list\n",
    "        self.dim = dim\n",
    "        self._shape = shape\n",
    "        self.per = list(permutations([0,1,2], 2))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.id_list[index]\n",
    "        \n",
    "        # h5파일을 바로 접근하여 사용하면 학습 속도가 병목 현상으로 많이 느릴 수 있습니다.\n",
    "        points = self.point_list[str(image_id)][:]\n",
    "        \n",
    "        # training\n",
    "        if self.label_list is not None:\n",
    "            rand_degree = np.random.choice([-np.pi/12, -np.pi/8, -np.pi/6, -np.pi/4, -np.pi/3], 3)\n",
    "            rotated_points = self.rotate(rand_degree[0], rand_degree[1], rand_degree[2], points)\n",
    "            \n",
    "            label = self.label_list[index]\n",
    "            \n",
    "            # image\n",
    "            if self.dim == '2d' :\n",
    "                image = self.sliced_section_6ch(rotated_points)  \n",
    "                return torch.Tensor(image), label\n",
    "            \n",
    "            # vector\n",
    "            else :\n",
    "                image = self.get_vector(rotated_points, x_y_z=CFG['voxel_grid'])\n",
    "                return torch.Tensor(image).unsqueeze(0), label\n",
    "        \n",
    "        # test\n",
    "        else:\n",
    "            # image\n",
    "            if self.dim == '2d' :\n",
    "                image = self.sliced_section_6ch(points)  \n",
    "                return torch.Tensor(image)\n",
    "            \n",
    "            # vector\n",
    "            else :\n",
    "                image = self.get_vector(points, x_y_z=CFG['voxel_grid'])\n",
    "                return torch.Tensor(image).unsqueeze(0)\n",
    "    \n",
    "    def rotate(self, a, b, c, dots):\n",
    "        mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
    "        my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
    "        mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
    "        m = np.dot(np.dot(mx,my),mz)\n",
    "        dots = np.dot(dots, m.T)\n",
    "        return dots\n",
    "\n",
    "    \n",
    "    def get_vector(self, points, x_y_z=[16, 16, 16]):\n",
    "        # 3D Points -> [16,16,16]\n",
    "        xyzmin = np.min(points, axis=0) - 0.001\n",
    "        xyzmax = np.max(points, axis=0) + 0.001\n",
    "\n",
    "        diff = max(xyzmax-xyzmin) - (xyzmax-xyzmin)\n",
    "        xyzmin = xyzmin - diff / 2\n",
    "        xyzmax = xyzmax + diff / 2\n",
    "\n",
    "        segments = []\n",
    "        shape = []\n",
    "\n",
    "        for i in range(3):\n",
    "            # note the +1 in num \n",
    "            if type(x_y_z[i]) is not int:\n",
    "                raise TypeError(\"x_y_z[{}] must be int\".format(i))\n",
    "            s, step = np.linspace(xyzmin[i], xyzmax[i], num=(x_y_z[i] + 1), retstep=True)\n",
    "            segments.append(s)\n",
    "            shape.append(step)\n",
    "\n",
    "        n_voxels = x_y_z[0] * x_y_z[1] * x_y_z[2]\n",
    "        n_x = x_y_z[0]\n",
    "        n_y = x_y_z[1]\n",
    "        n_z = x_y_z[2]\n",
    "\n",
    "        structure = np.zeros((len(points), 4), dtype=int)\n",
    "        structure[:,0] = np.searchsorted(segments[0], points[:,0]) - 1\n",
    "        structure[:,1] = np.searchsorted(segments[1], points[:,1]) - 1\n",
    "        structure[:,2] = np.searchsorted(segments[2], points[:,2]) - 1\n",
    "\n",
    "        # i = ((y * n_x) + x) + (z * (n_x * n_y))\n",
    "        structure[:,3] = ((structure[:,1] * n_x) + structure[:,0]) + (structure[:,2] * (n_x * n_y)) \n",
    "\n",
    "        vector = np.zeros(n_voxels)\n",
    "        count = np.bincount(structure[:,3])\n",
    "        vector[:len(count)] = count\n",
    "\n",
    "        vector = vector.reshape(n_z, n_y, n_x)\n",
    "        return vector\n",
    "    \n",
    "    def sliced_section_6ch(self, points) :\n",
    "                # 3D Points -> [16,16,16]\n",
    "        xyzmin = np.min(points, axis=0) - 0.001\n",
    "        xyzmax = np.max(points, axis=0) + 0.001\n",
    "\n",
    "        diff = max(xyzmax-xyzmin) - (xyzmax-xyzmin)\n",
    "        xyzmin = xyzmin - diff / 2\n",
    "        xyzmax = xyzmax + diff / 2\n",
    "\n",
    "        segments = []\n",
    "        shape = []\n",
    "\n",
    "        for i in range(3):\n",
    "            # note the +1 in num \n",
    "#             print(type(self._shape))\n",
    "            if type(self._shape) is not int:\n",
    "                raise TypeError(\"shape must be int\")\n",
    "            s, step = np.linspace(xyzmin[i], xyzmax[i], num=(self._shape + 1), retstep=True)\n",
    "            segments.append(s)\n",
    "            shape.append(step)\n",
    "\n",
    "        structure = np.zeros((len(points), 3), dtype=int)\n",
    "        structure[:, 0] = np.searchsorted(segments[0], points[:,0]) - 1        \n",
    "        structure[:, 1] = np.searchsorted(segments[1], points[:,1]) - 1\n",
    "        structure[:, 2] = np.searchsorted(segments[2], points[:,2]) - 1\n",
    "        \n",
    "        # shape = C, H, W\n",
    "        imgs = np.zeros((6, self._shape, self._shape))\n",
    "        for idx, (i,j) in enumerate(self.per) :\n",
    "            imgs[idx, -structure[:, i], structure[:, j]] = 1\n",
    "        \n",
    "        return imgs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52200b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for data, label in tqdm(iter(train_loader)):\n",
    "            data, label = data.float().to(device), label.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        val_loss, val_acc = validation(model, criterion, val_loader, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss)}] Val Loss : [{val_loss}] Val ACC : [{val_acc}]')\n",
    "        \n",
    "        if best_score < val_acc:\n",
    "            best_score = val_acc\n",
    "            torch.save(model.state_dict(), './model/'+str(epoch)+'E-val'+str(best_score)+'-'+CFG['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67acf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    model_preds = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in tqdm(iter(val_loader)):\n",
    "            data, label = data.float().to(device), label.long().to(device)\n",
    "            \n",
    "            model_pred = model(data)\n",
    "            loss = criterion(model_pred, label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return np.mean(val_loss), accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2162ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in tqdm(iter(test_loader)):\n",
    "            data, label = data.float().to(device), label.long().to(device)\n",
    "            \n",
    "            model_pred = model(data)\n",
    "            \n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ffea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dim_change(nn.Module) :\n",
    "    def __init__(self, shape_2d=224, in_channel=1) :\n",
    "        super().__init__()\n",
    "        self.conv3d = nn.Conv3d(in_channel, 1, 3)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((shape_2d))\n",
    "        self.conv2d = nn.Conv2d(shape_2d, 3, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv3d(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2d(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff230a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, model_name, shape_2d=224, in_channel=1, dim_changer=False) :\n",
    "        super().__init__()\n",
    "        \n",
    "        if dim_changer :\n",
    "            self.dim_changer = dim_change(shape_2d, in_channel)\n",
    "            self.model = timm.create_model(model_name=model_name, num_classes=10, pretrained=True)\n",
    "        \n",
    "        else :\n",
    "            self.dim_changer = dim_changer\n",
    "\n",
    "            if model_name.split('-')[-1] == 'efficientnet' :\n",
    "                self.model = effi.EfficientNet3D.from_name(model_name, \n",
    "                                                      override_params={'num_classes': 10}, \n",
    "                                                      in_channels=1)\n",
    "            elif model_name == 'resneXt' :\n",
    "                self.model = resneXt.resnet101(\n",
    "                                num_classes=10,\n",
    "                                shortcut_type=\"B\",\n",
    "                                cardinality=CFG['voxel_grid'][0] * 2,\n",
    "                                spatial_size=CFG['voxel_grid'][0],\n",
    "                                sample_duration=1)\n",
    "                \n",
    "            elif model_name =='resnet' :\n",
    "                self.model = resnet.ResNet(num_layers=CFG['num_layers'],\n",
    "                               in_channels=CFG['in_channels'],\n",
    "                               stride=CFG['stride'],\n",
    "                               num_classes=10).to(device)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        if self.dim_changer :\n",
    "            x = self.model(self.dim_changer(x))\n",
    "        else :\n",
    "            x = self.model(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ec37c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':64,\n",
    "    'SEED':41, \n",
    "    'output' : '6ch_img-effi_b0.pth',\n",
    "    'model_name' : 'efficientnet_b0',\n",
    "    'num_layers' : [3,4,6,3],\n",
    "    'in_channels' : [8, 32 ,64, 128],\n",
    "    'stride' : [1,1,1,1],\n",
    "    'voxel_grid' : [128, 128, 128]\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f034b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./data/train.csv')\n",
    "all_points = h5py.File('./data/train.h5', 'r')\n",
    "# all_points = np.load('./data/train.npy', allow_pickle=True)\n",
    "\n",
    "train_df = all_df.iloc[:int(len(all_df)*0.8)]\n",
    "val_df = all_df.iloc[int(len(all_df)*0.8) : int(len(all_df)*0.9)]\n",
    "test_df = all_df.iloc[int(len(all_df)*0.9) :]\n",
    "\n",
    "# train_dataset = CustomDataset(train_df['ID'].values, train_df['label'].values, all_points)\n",
    "# train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "# val_dataset = CustomDataset(val_df['ID'].values, val_df['label'].values, all_points)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "# test_dataset = CustomDataset(test_df['ID'].values, test_df['label'].values, all_points)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "train_dataset = _CustomDataset(train_df['ID'].values, train_df['label'].values, all_points, dim='2d', shape=224)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = _CustomDataset(val_df['ID'].values, val_df['label'].values, all_points, dim='2d', shape=224)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "test_dataset = _CustomDataset(test_df['ID'].values, test_df['label'].values, all_points, dim='2d', shape=224)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5f0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN(CFG['model_name'], shape_2d=288, in_channel=1, dim_changer=True).to(device)\n",
    "model = timm.create_model(model_name=CFG['model_name'], num_classes=10, pretrained=True, in_chans=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "276d84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = effi.EfficientNet3D.from_name(\n",
    "#             'efficientnet-b3', \n",
    "#             override_params={'num_classes': 10}, \n",
    "#             in_channels=1)\n",
    "# summary(model.to(\"cuda\"), input_size=(1,128,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f1ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resneXt.resnet101(\n",
    "#                 num_classes=10,\n",
    "#                 shortcut_type=\"B\",\n",
    "#                 cardinality=64,\n",
    "#                 spatial_size=32,\n",
    "#                 sample_duration=1)\n",
    "# summary(model.to(\"cuda\"), input_size=(1,32,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4bcda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet.ResNet(num_layers=CFG['num_layers'],\n",
    "#                in_channels=CFG['in_channels'],\n",
    "#                stride=CFG['stride'],\n",
    "#                num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d55f3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41a15dd73e1467ea5b64ba95457fa8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a487aee177304d33b437f46deaa24a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.5088406831264496] Val Loss : [0.33130504167344] Val ACC : [0.8976]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ea3dac9747424e94a4b884f6714cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee8358ee58f4740b0cb6e0ad7a8186e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.1901017424225807] Val Loss : [0.19719855463768862] Val ACC : [0.9358]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b580aea3dae4e3eab226985b8bc8b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97185a42db374fd5b588d8851f162dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.1354466692507267] Val Loss : [0.09708018498377333] Val ACC : [0.9682]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2b7a2956c8447d825379f78b63b910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8302ae90c68442ff99c4787df45b0ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.09176970025151968] Val Loss : [0.07865223127617678] Val ACC : [0.9754]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2fbfac0c254f75b82d4eeed1b65370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4867b55170364e09a360200281ab4844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.06536214575134218] Val Loss : [0.060010814331943475] Val ACC : [0.9794]\n"
     ]
    }
   ],
   "source": [
    "# model = ResNet(num_classes=10).to(device)\n",
    "model.eval()\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                      T_max=CFG['EPOCHS'], \n",
    "                                                      eta_min=1e-4)\n",
    "\n",
    "train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28259082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569227e3d19c4a4b8005385b9f128d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.9744\n"
     ]
    }
   ],
   "source": [
    "test_acc = test(model, test_loader, device)\n",
    "print(f\"Test Accuracy : {round(test_acc, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24f215",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "369e1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/sample_submission.csv')\n",
    "test_points = h5py.File('./data/test.h5', 'r')\n",
    "\n",
    "test_dataset = _CustomDataset(test_df['ID'].values, None, test_points, dim='2d', shape=224)\n",
    "# test_dataset = CustomDataset(test_df['ID'].values, None, test_points)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "checkpoint = torch.load('./model/5E-val0.9794-6ch_img-effi_b0.pth')\n",
    "# model = CNN(CFG['model_name'], shape_2d=288, in_channel=1, dim_changer=True).to(device)\n",
    "model = timm.create_model(model_name=CFG['model_name'], num_classes=10, pretrained=True, in_chans=6)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b177a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device, dim_changer=None):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(test_loader)):\n",
    "            data = data.float().to(device)\n",
    "            if dim_changer :\n",
    "                batch_pred = model(dim_changer(data))\n",
    "            else :\n",
    "                batch_pred = model(data)\n",
    "            \n",
    "            model_preds += batch_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e215c4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1410e5fd2b449aeb4e5a121c71bbea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee2507eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = preds\n",
    "\n",
    "test_df.to_csv('./submission/5E-val0.9794-6ch_img-effi_b0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef675d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
