{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c16ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py # .h5 파일을 읽기 위한 패키지\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from cfg.voxelnet_cfg import config as cfg \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418d62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "# conv2d + bn + relu\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k,s,p, activation=True, batch_norm=True):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=k,stride=s,padding=p)\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x=self.bn(x)\n",
    "        if self.activation:\n",
    "            return F.relu(x,inplace=True)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# conv3d + bn + relu\n",
    "class Conv3d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, k, s, p, batch_norm=True):\n",
    "        super(Conv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=k, stride=s, padding=p)\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm3d(out_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "# Fully Connected Network\n",
    "class FCN(nn.Module):\n",
    "\n",
    "    def __init__(self,cin,cout):\n",
    "        super(FCN, self).__init__()\n",
    "        self.cout = cout\n",
    "        self.linear = nn.Linear(cin, cout)\n",
    "        self.bn = nn.BatchNorm1d(cout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # KK is the stacked k across batch\n",
    "#         print(\"1. FCN x.shape : \",x.shape)\n",
    "        kk, t, _ = x.shape\n",
    "#         N, D, H, W = x.shape\n",
    "\n",
    "        x = self.linear(x.view(kk * t, -1))\n",
    "#         x = self.linear(x.view(N*D*H, -1))\n",
    "        \n",
    "\n",
    "#         print(\"2. FCN x.shape : \", x.shape)\n",
    "        x = F.relu(self.bn(x))\n",
    "        \n",
    "        return x.view(kk,t, -1)\n",
    "#         return x.view(N, -1, H, x.shape[1])\n",
    "\n",
    "# Voxel Feature Encoding layer\n",
    "class VFE(nn.Module):\n",
    "\n",
    "    def __init__(self,cin,cout):\n",
    "        super(VFE, self).__init__()\n",
    "        assert cout % 2 == 0\n",
    "        self.units = cout // 2\n",
    "        self.fcn = FCN(cin,self.units)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # point-wise feauture\n",
    "        pwf = self.fcn(x)\n",
    "        \n",
    "        #locally aggregated feature\n",
    "#         print(\"1. VEF pwf.shape : \", pwf.shape)\n",
    "#         print(\"1. VEF torch max pwf shape : \",  torch.max(pwf,2)[0].shape)\n",
    "#         print(\"1. VEF torch max pwf unsq(1) shape : \",  torch.max(pwf,2)[0].unsqueeze(2).shape)\n",
    "#         print(\"1. VEF torch max pwf unsq(1) repeat(1,35,1) shape : \",  torch.max(pwf,2)[0].unsqueeze(2).repeat(1,1,cfg.T,1).shape)\n",
    "        laf = torch.max(pwf,1)[0].unsqueeze(1).repeat(1,cfg.T,1)\n",
    "#         laf = torch.max(pwf,2)[0].unsqueeze(2).repeat(1,1,cfg.T,1)\n",
    "#         print(\"2. VEF laf.shape : \", laf.shape)\n",
    "        \n",
    "        # point-wise concat feature\n",
    "        pwcf = torch.cat((pwf,laf),dim=2)\n",
    "#         pwcf = torch.cat((pwf,laf),dim=3)\n",
    "#         print(\"3. VEF pwcf.shape : \", pwcf.shape)\n",
    "\n",
    "        # apply mask\n",
    "#         print(\"4. VEF mask shape : \", mask.shape)\n",
    "#         print(\"4. VEF mask unsq(2) shape : \", mask.unsqueeze(2).shape)\n",
    "#         print(\"4. VEF mask unsq(2) repeat(1,1, ??) shape : \", mask.unsqueeze(2).repeat(1, 1, self.units * 2).shape)\n",
    "        mask = mask.unsqueeze(2).repeat(1, 1, self.units * 2)\n",
    "#         mask = mask.unsqueeze(3).repeat(1, 1, 1, self.units * 2)\n",
    "#         print(\"4. VEF mask.shape : \", mask.shape)\n",
    "        pwcf = pwcf * mask.float()\n",
    "\n",
    "        return pwcf\n",
    "\n",
    "# Stacked Voxel Feature Encoding\n",
    "class SVFE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVFE, self).__init__()\n",
    "#         self.vfe_1 = VFE(6,32)\n",
    "        self.vfe_1 = VFE(7,32)\n",
    "        self.vfe_2 = VFE(32,128)\n",
    "        self.fcn = FCN(128,128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mask = torch.ne(torch.max(x,2)[0], 0)\n",
    "#         print(\"SVFE Mask value : \", mask)\n",
    "        x = self.vfe_1(x, mask)\n",
    "        x = self.vfe_2(x, mask)\n",
    "        x = self.fcn(x)\n",
    "#         print(\"SVFE x.shape: \",x.shape)\n",
    "        # element-wise max pooling\n",
    "        x = torch.max(x,1)[0]\n",
    "        return x\n",
    "\n",
    "# Convolutional Middle Layer\n",
    "class CML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CML, self).__init__()\n",
    "        self.conv3d_1 = Conv3d(128, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n",
    "        self.conv3d_2 = Conv3d(64, 64, 3, s=(1, 1, 1), p=(0, 1, 1))\n",
    "        self.conv3d_3 = Conv3d(64, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d_1(x)\n",
    "        x = self.conv3d_2(x)\n",
    "        x = self.conv3d_3(x)\n",
    "        return x\n",
    "\n",
    "class RPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RPN, self).__init__()\n",
    "        self.in_c = 448 # 192\n",
    "        self.out_c = 576 # 256\n",
    "        self.score_c = 1728 # 768\n",
    "        self.cls_c = 2560 # 640\n",
    "        \n",
    "        self.block_1 = [Conv2d(self.in_c, self.in_c, 3, 2, 1)]\n",
    "        self.block_1 += [Conv2d(self.in_c, self.in_c, 3, 1, 1) for _ in range(3)]\n",
    "        self.block_1 = nn.Sequential(*self.block_1)\n",
    "\n",
    "        self.block_2 = [Conv2d(self.in_c, self.in_c, 3, 2, 1)]\n",
    "        self.block_2 += [Conv2d(self.in_c, self.in_c, 3, 1, 1) for _ in range(5)]\n",
    "        self.block_2 = nn.Sequential(*self.block_2)\n",
    "\n",
    "        self.block_3 = [Conv2d(self.in_c, self.out_c, 3, 2, 1)]\n",
    "        self.block_3 += [nn.Conv2d(self.out_c, self.out_c, 3, 1, 1) for _ in range(5)]\n",
    "        self.block_3 = nn.Sequential(*self.block_3)\n",
    "\n",
    "        self.deconv_1 = nn.Sequential(nn.ConvTranspose2d(self.out_c, self.out_c, 4, 4, 0),nn.BatchNorm2d(self.out_c))\n",
    "        self.deconv_2 = nn.Sequential(nn.ConvTranspose2d(self.in_c, self.out_c, 2, 2, 0),nn.BatchNorm2d(self.out_c))\n",
    "        self.deconv_3 = nn.Sequential(nn.ConvTranspose2d(self.in_c, self.out_c, 1, 1, 0),nn.BatchNorm2d(self.out_c))\n",
    "\n",
    "        self.score_head = Conv2d(self.score_c, 10, 1, 1, 0, activation=False, batch_norm=False)\n",
    "#         self.reg_head = Conv2d(768, 7 * cfg.anchors_per_position, 1, 1, 0, activation=False, batch_norm=False)\n",
    "        self.cls = Classifier(cin=self.cls_c)\n",
    "    def forward(self,x, batch_size):\n",
    "        x = self.block_1(x)\n",
    "        x_skip_1 = x\n",
    "        x = self.block_2(x)\n",
    "        x_skip_2 = x\n",
    "        x = self.block_3(x)\n",
    "#         print(\"RPN block_3 x.shape : \",x.shape)\n",
    "        x_0 = self.deconv_1(x)\n",
    "#         print(\"RPN deconv_1 x_0.shape : \",x_0.shape)\n",
    "        x_1 = self.deconv_2(x_skip_2)\n",
    "#         print(\"RPN deconv_2 x_1.shape : \",x_1.shape)\n",
    "        x_2 = self.deconv_3(x_skip_1)\n",
    "#         print(\"RPN deconv_3 x_2.shape : \",x_2.shape)\n",
    "        x = torch.cat((x_0,x_1,x_2),1)\n",
    "        x = self.score_head(x)\n",
    "        x = self.cls(x.view(batch_size, -1))\n",
    "#         print(\"RPN cls x.shape : \",x.shape)\n",
    "        return x #self.score_head(x),self.reg_head(x)\n",
    "    \n",
    "    \n",
    "# classifier\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, cin, num_classes=10, dropout_rate=0.5):\n",
    "        super(Classifier, self).__init__()  \n",
    "        \n",
    "        self.linear_1 = nn.Sequential(\n",
    "            nn.Linear(cin, cin//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.linear_2 = nn.Sequential(\n",
    "            nn.Linear(cin//2, cin//4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.linear_3 = nn.Linear(cin//4, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # KK is the stacked k across batch\n",
    "#         print(\"classifier x.shape : \", x.shape)\n",
    "#         print(\"classifier x.view.shape : \", x.view(2,-1).shape)\n",
    "        b, f, *_ = x.shape\n",
    "        x = self.linear_1(x.view(b, -1))\n",
    "        x = self.linear_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class VoxelNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VoxelNet, self).__init__()\n",
    "        self.svfe = SVFE()\n",
    "        self.cml = CML()\n",
    "        self.rpn = RPN()\n",
    "        self.cls = Classifier(cin=64)\n",
    "        \n",
    "    def voxel_indexing(self, sparse_features, coords, batch_size):\n",
    "        dim = sparse_features.shape[-1]\n",
    "#         print(\"sparse_features.shape : \", sparse_features.shape)\n",
    "        \n",
    "        coords= coords.type(torch.long)\n",
    "#         print(\"coords.shape : \", coords.shape)\n",
    "#         print(\"coords values [:,0]: \",coords[:,0])\n",
    "        dense_feature = torch.zeros(dim, batch_size, cfg.D, cfg.H, cfg.W).to(cfg.device)\n",
    "#         print(\"dense_feature.shape : \", dense_feature.shape)\n",
    "        dense_feature[:, coords[:,0], coords[:,1], coords[:,2], coords[:,3]]= sparse_features.transpose(0,1)\n",
    "#         dense_feature[:, coords[:,0], coords[:,1], coords[:,2]]= sparse_features\n",
    "        return dense_feature.transpose(0, 1)\n",
    "\n",
    "    def forward(self, voxel_features, voxel_coords, batch_size):\n",
    "\n",
    "        # feature learning network\n",
    "        vwfs = self.svfe(voxel_features)\n",
    "        vwfs = self.voxel_indexing(vwfs,voxel_coords, batch_size)\n",
    "\n",
    "        # convolutional middle network\n",
    "        cml_out = self.cml(vwfs)\n",
    "        cml_out = cml_out.view(batch_size, -1,cfg.H, cfg.W)\n",
    "#         print(\"cml_out.shape : \", cml_out.shape)\n",
    "\n",
    "        # region proposal network\n",
    "        score = self.rpn(cml_out, batch_size)\n",
    "        # merge the depth and feature dim into one, output probability score map and regression map\n",
    "        # psm,rm = self.rpn(cml_out.view(cfg.N,-1,cfg.H, cfg.W))\n",
    "        \n",
    "        # classifier\n",
    "#         print(\"score shape : \", score)\n",
    "\n",
    "        return score #psm, rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0a15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_collate(batch):\n",
    "    voxel_features = []\n",
    "    voxel_coords = []\n",
    "    train = True if len(batch[0]) == 3 else False\n",
    "    \n",
    "    for i, sample in enumerate(batch):\n",
    "        voxel_features.append(sample[0])\n",
    "        voxel_coords.append(np.pad(sample[1], ((0,0), (1,0)), mode='constant', constant_values=i))\n",
    "\n",
    "    if train :\n",
    "        return np.concatenate(voxel_features), np.concatenate(voxel_coords), np.array(batch)[:, 2].astype(np.long)\n",
    "    else :\n",
    "        return np.concatenate(voxel_features), np.concatenate(voxel_coords), len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ace2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelDataset(Dataset) :\n",
    "    def __init__(self, id_list, label_list, point_list) :\n",
    "        self.id_list = id_list\n",
    "        self.label_list = label_list\n",
    "        self.point_list = point_list\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        image_id = self.id_list[index]\n",
    "        points= self.point_list[str(image_id)][:]\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            points = self.rand_sampling(points, low_rate=0.8, high_rate=0.6)\n",
    "#             points = self.grid_cutout(points, low=3, high=7)\n",
    "            \n",
    "            points= self.trans_axis_range(points, axis=[0,1,2])\n",
    "            x_degree = self.rand_degree(-np.pi/2, np.pi/2)\n",
    "            y_degree = np.random.choice([-np.pi/2, np.pi/2])#self.rand_degree(-np.pi/4, np.pi/4)\n",
    "            z_degree = self.rand_degree(-np.pi/6, np.pi/6)\n",
    "            \n",
    "            if CFG['rand_rotation'] :\n",
    "                points = self.rand_rotation(x_degree, y_degree, z_degree, points, p=0.80)\n",
    "                \n",
    "            else :    \n",
    "                points = self.rotation(x_degree, y_degree, z_degree, points)\n",
    "                \n",
    "            points = self.jittering(points, (-0.02, 0.02))\n",
    "            points = self.scaling(points, (0.98, 1.02))\n",
    "            voxel_features, voxel_coords= self.voxelization(points)\n",
    "            label = self.label_list[index]\n",
    "            return voxel_features, voxel_coords, label\n",
    "        \n",
    "        else:\n",
    "            # TTA\n",
    "            points = self.rand_sampling(points, low_rate=0.8, high_rate=0.6)\n",
    "#             points = self.grid_cutout(points, low=3, high=7)\n",
    "            points= self.trans_axis_range(points, axis=[0,1,2])                \n",
    "            points = self.jittering(points, (-0.02, 0.02))\n",
    "            points = self.scaling(points, (0.98, 1.02))\n",
    "            voxel_features, voxel_coords= self.voxelization(points)\n",
    "            return voxel_features, voxel_coords\n",
    "    \n",
    "    def rand_rotation(self, x_degree, y_degree, z_degree, point, p=0.5) :\n",
    "        _p = np.random.uniform(0, 1)\n",
    "        if _p < p :\n",
    "            return self.rotation(x_degree, y_degree, z_degree, point)\n",
    "        \n",
    "        else :\n",
    "            return point\n",
    "            \n",
    "    def rotation(self, a, b, c, dots):\n",
    "        mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
    "        my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
    "        mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
    "        m = np.dot(np.dot(mx,my),mz)\n",
    "        dots = np.dot(dots, m.T)\n",
    "        return dots\n",
    "    \n",
    "    def jittering(self, point, scale_range) :\n",
    "        point += np.random.uniform(*scale_range, size=point.shape) \n",
    "        return point\n",
    "    \n",
    "    def scaling(self, point, scale_range) :\n",
    "        point *= np.random.uniform(*scale_range)\n",
    "        return point\n",
    "    \n",
    "    def rand_sampling(self, point, low_rate=0.8, high_rate=0.6) :\n",
    "        point_num = point.shape[0]\n",
    "        \n",
    "        if point_num >= 20000 :\n",
    "            sampling_rate=high_rate\n",
    "        else :\n",
    "            sampling_rate=low_rate\n",
    "            \n",
    "        sampling_idx = np.sort(np.random.choice(point_num, int(point_num * sampling_rate) , replace=False))\n",
    "        point = point[sampling_idx, :]\n",
    "        return point\n",
    "    \n",
    "    def rand_degree(self, *rotation_range) :\n",
    "        assert len([rotation_range]) != 2, 'expected 2 parameters, but given more or less'\n",
    "        return np.random.uniform(*rotation_range)\n",
    "    \n",
    "    def trans_axis_range(self, point, axis=[0]) :\n",
    "        # Transform train point range to test point range\n",
    "        point[:, axis] = point[:, axis] / (np.max(np.abs(cfg.train_range[axis])) + 0.1) * (np.min(np.abs(cfg.test_range[axis])) - 0.1)\n",
    "        return point\n",
    "    \n",
    "    def point_normalize(self, point, test=False) :\n",
    "        axis=[0, 1, 2]\n",
    "        xyzmin = np.min(point, axis=0)\n",
    "        xyzmax = np.max(point, axis=0)\n",
    "        if not test :\n",
    "            point[:, axis] = (point[:, axis] + np.abs(cfg.train_range[axis, 0])) / (np.sum(np.abs(cfg.train_range[axis]), 1))\n",
    "            \n",
    "        else :\n",
    "            point[:, axis] = (point[:, axis] + np.abs(cfg.test_range[axis, 0])) / (np.sum(np.abs(cfg.test_range[axis]), 1))\n",
    "        return point, xyzmin, xyzmax\n",
    "    \n",
    "    def grid_cutout(self, points, low=5, high=10) :\n",
    "        num_drop = np.random.randint(low, high)\n",
    "        xyzmax = np.max(points, 0)\n",
    "        xyzmin = np.min(points, 0)\n",
    "\n",
    "        r, s = np.linspace(xyzmin[:], xyzmax[:], num=64, endpoint=False, retstep=True)\n",
    "\n",
    "        x_pick = np.sort(np.random.choice(r[:, 0], num_drop))\n",
    "        y_pick = np.sort(np.random.choice(r[:, 1], num_drop))\n",
    "        z_pick = np.sort(np.random.choice(r[:, 2], num_drop))\n",
    "\n",
    "        for idx, pick in enumerate([x_pick, y_pick, z_pick]) :\n",
    "            cut_list = []\n",
    "            for i in range(num_drop):\n",
    "                r = np.where(((pick[i]< points) & (points < pick[i] + s[idx])))[0]\n",
    "                if r.shape[0] != 0 :\n",
    "                    cut_list.append(r)\n",
    "            \n",
    "            if len(cut_list) != 0 :\n",
    "                cut_list = np.unique(np.concatenate(cut_list))\n",
    "\n",
    "                diff_point = np.setdiff1d(np.arange(points.shape[0]), cut_list)\n",
    "                points = points[diff_point, :] \n",
    "        return points\n",
    "\n",
    "    def voxelization(self, point):# ,xyzmin, xyzmax) :\n",
    "        point_reflectance = np.zeros((point.shape[0],1))\n",
    "        point = np.concatenate((point, point_reflectance), 1)\n",
    "        \n",
    "        voxel_coords = ((point[:, :3] - np.array([cfg.test_range[0][0], cfg.test_range[1][0], cfg.test_range[2][0]])) / \n",
    "                       (cfg.vw, cfg.vh, cfg.vd)).astype(np.int32)\n",
    "        \n",
    "        # convert to (D,H,W)\n",
    "        voxel_coords = voxel_coords[:, [2,1,0]]\n",
    "        voxel_coords, inv_ind, voxel_counts = np.unique(voxel_coords, \n",
    "                                                        axis=0, \n",
    "                                                        return_inverse=True, \n",
    "                                                        return_counts=True)\n",
    "\n",
    "        voxel_features = []\n",
    "        for i in range(len(voxel_coords)) :\n",
    "            voxel = np.zeros((cfg.T, 7), dtype=np.float32)\n",
    "            pts = point[inv_ind == i]\n",
    "            \n",
    "            # Random sampling\n",
    "            if voxel_counts[i] > cfg.T :\n",
    "                random_sampling = np.random.randint(0, pts.shape[0], size=cfg.T)\n",
    "                pts = pts[random_sampling, : ]\n",
    "                voxel_counts[i] = cfg.T\n",
    "            \n",
    "            voxel[:pts.shape[0], :] = np.concatenate((pts, pts[:, :3] - np.mean(pts[:, :3], 0)), axis=1)\n",
    "            voxel_features.append(voxel)\n",
    "\n",
    "        return np.array(voxel_features), voxel_coords\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f51c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(label,pred) :\n",
    "    model_preds = pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    true_labels = label.detach().cpu().numpy().tolist()\n",
    "    return accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1497f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    collect_answ = {str(k):0 for k in range(10)}\n",
    "    wrong_answ = {str(k):0 for k in range(10)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tqdm_val = tqdm(iter(val_loader))\n",
    "        for vf, vc, label in tqdm_val:\n",
    "            vf = torch.tensor(vf).to(device)\n",
    "            vc = torch.tensor(vc).to(device)\n",
    "            label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "\n",
    "            model_pred = model(vf, vc, batch_size=label.shape[0])\n",
    "            \n",
    "            model_preds = model_pred.argmax(1).detach().cpu().numpy()\n",
    "            true_labels = label.detach().cpu().numpy()\n",
    "            \n",
    "            wrong = model_preds[model_preds != true_labels]\n",
    "            collect = model_preds[model_preds == true_labels]\n",
    "            \n",
    "            for i in range(10) :\n",
    "                wrong_answ[str(i)] += wrong[wrong == i].shape[0]\n",
    "                collect_answ[str(i)] += collect[collect == i].shape[0]\n",
    "            \n",
    "    return wrong_answ, collect_answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b07c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':45,\n",
    "    'BATCH_SIZE':32,\n",
    "    'rand_rotation' : True,\n",
    "    'checkpoint' : './ckpt/16E-val0.9734-focal-randrotate-randsample-jitter-scale-axis-voxelnet.pth',\n",
    "    'reuse' : True\n",
    "}\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e7cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./data/train.csv')\n",
    "all_points = h5py.File('./data/train.h5', 'r')\n",
    "\n",
    "train_df = all_df.iloc[:int(len(all_df)*0.8)]\n",
    "val_df = all_df.iloc[int(len(all_df)*0.8):]\n",
    "\n",
    "train_dataset = VoxelDataset(train_df['ID'].values, train_df['label'].values, all_points)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], collate_fn=detection_collate, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = VoxelDataset(val_df['ID'].values, val_df['label'].values, all_points)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], collate_fn=detection_collate, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e1b523c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7979f81cf846422a9aa7978714385259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = VoxelNet().to(device)\n",
    "checkpoint = torch.load(CFG['checkpoint'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "wrong_answ, collect_answ = validation(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aafcf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 294,\n",
       " '1': 4374,\n",
       " '2': 804,\n",
       " '3': 476,\n",
       " '4': 204,\n",
       " '5': 22,\n",
       " '6': 83,\n",
       " '7': 98,\n",
       " '8': 403,\n",
       " '9': 263}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8120cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 230,\n",
       " '1': 822,\n",
       " '2': 319,\n",
       " '3': 284,\n",
       " '4': 220,\n",
       " '5': 165,\n",
       " '6': 238,\n",
       " '7': 221,\n",
       " '8': 211,\n",
       " '9': 269}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_answ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79effc",
   "metadata": {},
   "source": [
    "## 정답률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a6bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 :  0.2282\n",
      "class 1 :  0.7372\n",
      "class 2 :  0.3112\n",
      "class 3 :  0.2784\n",
      "class 4 :  0.2316\n",
      "class 5 :  0.1829\n",
      "class 6 :  0.2439\n",
      "class 7 :  0.2105\n",
      "class 8 :  0.2149\n",
      "class 9 :  0.2767\n"
     ]
    }
   ],
   "source": [
    "for i in range(10) :\n",
    "    print(f\"class {i} : \", round((collect_answ[str(i)]/val_df['label'][val_df['label'] == i].count()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf000b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'str'> 999\n",
      "1 <class 'str'> 1107\n",
      "2 <class 'str'> 999\n",
      "3 <class 'str'> 982\n",
      "4 <class 'str'> 903\n",
      "5 <class 'str'> 871\n",
      "6 <class 'str'> 964\n",
      "7 <class 'str'> 1011\n",
      "8 <class 'str'> 944\n",
      "9 <class 'str'> 949\n"
     ]
    }
   ],
   "source": [
    "for i, (k,v) in enumerate(collect_answ.items()) :\n",
    "    print(i,type(k),v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1310eff",
   "metadata": {},
   "source": [
    "## 오답으로 가장 많이 선택된 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3867b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : 11\n",
      "class 1 : 23\n",
      "class 2 : 34\n",
      "class 3 : 21\n",
      "class 4 : 19\n",
      "class 5 : 23\n",
      "class 6 : 19\n",
      "class 7 : 37\n",
      "class 8 : 28\n",
      "class 9 : 56\n"
     ]
    }
   ],
   "source": [
    "for i in range(10) :\n",
    "    print(f\"class {i} : {wrong_answ[str(i)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aca5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(10) :\n",
    "    a.append(round(collect_answ[str(i)]/val_df['label'][val_df['label'] == i].count(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8febcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611799999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb918b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
