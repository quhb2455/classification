{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32523444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py # .h5 파일을 읽기 위한 패키지\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from cfg.voxelnet_cfg import config as cfg \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cb3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "# conv2d + bn + relu\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k,s,p, activation=True, batch_norm=True):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=k,stride=s,padding=p)\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x=self.bn(x)\n",
    "        if self.activation:\n",
    "            return F.relu(x,inplace=True)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# conv3d + bn + relu\n",
    "class Conv3d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, k, s, p, batch_norm=True):\n",
    "        super(Conv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=k, stride=s, padding=p)\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm3d(out_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "# Fully Connected Network\n",
    "class FCN(nn.Module):\n",
    "\n",
    "    def __init__(self,cin,cout):\n",
    "        super(FCN, self).__init__()\n",
    "        self.cout = cout\n",
    "        self.linear = nn.Linear(cin, cout)\n",
    "        self.bn = nn.BatchNorm1d(cout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # KK is the stacked k across batch\n",
    "#         print(\"1. FCN x.shape : \",x.shape)\n",
    "        kk, t, _ = x.shape\n",
    "#         N, D, H, W = x.shape\n",
    "\n",
    "        x = self.linear(x.view(kk * t, -1))\n",
    "#         x = self.linear(x.view(N*D*H, -1))\n",
    "        \n",
    "\n",
    "#         print(\"2. FCN x.shape : \", x.shape)\n",
    "        x = F.relu(self.bn(x))\n",
    "        \n",
    "        return x.view(kk,t, -1)\n",
    "#         return x.view(N, -1, H, x.shape[1])\n",
    "\n",
    "# Voxel Feature Encoding layer\n",
    "class VFE(nn.Module):\n",
    "\n",
    "    def __init__(self,cin,cout):\n",
    "        super(VFE, self).__init__()\n",
    "        assert cout % 2 == 0\n",
    "        self.units = cout // 2\n",
    "        self.fcn = FCN(cin,self.units)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # point-wise feauture\n",
    "        pwf = self.fcn(x)\n",
    "        \n",
    "        #locally aggregated feature\n",
    "#         print(\"1. VEF pwf.shape : \", pwf.shape)\n",
    "#         print(\"1. VEF torch max pwf shape : \",  torch.max(pwf,2)[0].shape)\n",
    "#         print(\"1. VEF torch max pwf unsq(1) shape : \",  torch.max(pwf,2)[0].unsqueeze(2).shape)\n",
    "#         print(\"1. VEF torch max pwf unsq(1) repeat(1,35,1) shape : \",  torch.max(pwf,2)[0].unsqueeze(2).repeat(1,1,cfg.T,1).shape)\n",
    "        laf = torch.max(pwf,1)[0].unsqueeze(1).repeat(1,cfg.T,1)\n",
    "#         laf = torch.max(pwf,2)[0].unsqueeze(2).repeat(1,1,cfg.T,1)\n",
    "#         print(\"2. VEF laf.shape : \", laf.shape)\n",
    "        \n",
    "        # point-wise concat feature\n",
    "        pwcf = torch.cat((pwf,laf),dim=2)\n",
    "#         pwcf = torch.cat((pwf,laf),dim=3)\n",
    "#         print(\"3. VEF pwcf.shape : \", pwcf.shape)\n",
    "\n",
    "        # apply mask\n",
    "#         print(\"4. VEF mask shape : \", mask.shape)\n",
    "#         print(\"4. VEF mask unsq(2) shape : \", mask.unsqueeze(2).shape)\n",
    "#         print(\"4. VEF mask unsq(2) repeat(1,1, ??) shape : \", mask.unsqueeze(2).repeat(1, 1, self.units * 2).shape)\n",
    "        mask = mask.unsqueeze(2).repeat(1, 1, self.units * 2)\n",
    "#         mask = mask.unsqueeze(3).repeat(1, 1, 1, self.units * 2)\n",
    "#         print(\"4. VEF mask.shape : \", mask.shape)\n",
    "        pwcf = pwcf * mask.float()\n",
    "\n",
    "        return pwcf\n",
    "\n",
    "# Stacked Voxel Feature Encoding\n",
    "class SVFE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVFE, self).__init__()\n",
    "#         self.vfe_1 = VFE(6,32)\n",
    "        self.vfe_1 = VFE(7,32)\n",
    "        self.vfe_2 = VFE(32,128)\n",
    "        self.fcn = FCN(128,128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mask = torch.ne(torch.max(x,2)[0], 0)\n",
    "#         print(\"SVFE Mask value : \", mask)\n",
    "        x = self.vfe_1(x, mask)\n",
    "        x = self.vfe_2(x, mask)\n",
    "        x = self.fcn(x)\n",
    "#         print(\"SVFE x.shape: \",x.shape)\n",
    "        # element-wise max pooling\n",
    "        x = torch.max(x,1)[0]\n",
    "        return x\n",
    "\n",
    "# Convolutional Middle Layer\n",
    "class CML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CML, self).__init__()\n",
    "        self.conv3d_1 = Conv3d(128, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n",
    "        self.conv3d_2 = Conv3d(64, 64, 3, s=(1, 1, 1), p=(0, 1, 1))\n",
    "        self.conv3d_3 = Conv3d(64, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d_1(x)\n",
    "        x = self.conv3d_2(x)\n",
    "        x = self.conv3d_3(x)\n",
    "        return x\n",
    "\n",
    "class RPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RPN, self).__init__()\n",
    "        self.block_1 = [Conv2d(192, 192, 3, 2, 1)]\n",
    "        self.block_1 += [Conv2d(192, 192, 3, 1, 1) for _ in range(3)]\n",
    "        self.block_1 = nn.Sequential(*self.block_1)\n",
    "\n",
    "        self.block_2 = [Conv2d(192, 192, 3, 2, 1)]\n",
    "        self.block_2 += [Conv2d(192, 192, 3, 1, 1) for _ in range(5)]\n",
    "        self.block_2 = nn.Sequential(*self.block_2)\n",
    "\n",
    "        self.block_3 = [Conv2d(192, 256, 3, 2, 1)]\n",
    "        self.block_3 += [nn.Conv2d(256, 256, 3, 1, 1) for _ in range(5)]\n",
    "        self.block_3 = nn.Sequential(*self.block_3)\n",
    "\n",
    "        self.deconv_1 = nn.Sequential(nn.ConvTranspose2d(256, 256, 4, 4, 0),nn.BatchNorm2d(256))\n",
    "        self.deconv_2 = nn.Sequential(nn.ConvTranspose2d(192, 256, 2, 2, 0),nn.BatchNorm2d(256))\n",
    "        self.deconv_3 = nn.Sequential(nn.ConvTranspose2d(192, 256, 1, 1, 0),nn.BatchNorm2d(256))\n",
    "\n",
    "        self.score_head = Conv2d(768, 10, 1, 1, 0, activation=False, batch_norm=False)\n",
    "#         self.reg_head = Conv2d(768, 7 * cfg.anchors_per_position, 1, 1, 0, activation=False, batch_norm=False)\n",
    "        self.cls = Classifier(cin=640)\n",
    "    def forward(self,x, batch_size):\n",
    "        x = self.block_1(x)\n",
    "        x_skip_1 = x\n",
    "        x = self.block_2(x)\n",
    "        x_skip_2 = x\n",
    "        x = self.block_3(x)\n",
    "#         print(\"RPN block_3 x.shape : \",x.shape)\n",
    "        x_0 = self.deconv_1(x)\n",
    "#         print(\"RPN deconv_1 x_0.shape : \",x_0.shape)\n",
    "        x_1 = self.deconv_2(x_skip_2)\n",
    "#         print(\"RPN deconv_2 x_1.shape : \",x_1.shape)\n",
    "        x_2 = self.deconv_3(x_skip_1)\n",
    "#         print(\"RPN deconv_3 x_2.shape : \",x_2.shape)\n",
    "        x = torch.cat((x_0,x_1,x_2),1)\n",
    "#         print(\"RPN cat x.shape : \",x.shape)\n",
    "        x = self.score_head(x)\n",
    "#         print(\"RPN score_head x.shape : \",x.shape)\n",
    "        x = self.cls(x.view(batch_size, -1))\n",
    "#         print(\"RPN cls x.shape : \",x.shape)\n",
    "        return x #self.score_head(x),self.reg_head(x)\n",
    "    \n",
    "    \n",
    "# classifier\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, cin, num_classes=10, dropout_rate=0.5):\n",
    "        super(Classifier, self).__init__()  \n",
    "        \n",
    "        self.linear_1 = nn.Sequential(\n",
    "            nn.Linear(cin, cin//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.linear_2 = nn.Sequential(\n",
    "            nn.Linear(cin//2, cin//4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.linear_3 = nn.Linear(cin//4, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # KK is the stacked k across batch\n",
    "#         print(\"classifier x.shape : \", x.shape)\n",
    "#         print(\"classifier x.view.shape : \", x.view(2,-1).shape)\n",
    "        b, f, *_ = x.shape\n",
    "        x = self.linear_1(x.view(b, -1))\n",
    "        x = self.linear_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class VoxelNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VoxelNet, self).__init__()\n",
    "        self.svfe = SVFE()\n",
    "        self.cml = CML()\n",
    "        self.rpn = RPN()\n",
    "        self.cls = Classifier(cin=64)\n",
    "        \n",
    "    def voxel_indexing(self, sparse_features, coords, batch_size):\n",
    "        dim = sparse_features.shape[-1]\n",
    "#         print(\"sparse_features.shape : \", sparse_features.shape)\n",
    "        \n",
    "        coords= coords.type(torch.long)\n",
    "#         print(\"coords.shape : \", coords.shape)\n",
    "#         print(\"coords values [:,0]: \",coords[:,0])\n",
    "        dense_feature = torch.zeros(dim, batch_size, cfg.D, cfg.H, cfg.W).to(cfg.device)\n",
    "#         print(\"dense_feature.shape : \", dense_feature.shape)\n",
    "        dense_feature[:, coords[:,0], coords[:,1], coords[:,2], coords[:,3]]= sparse_features.transpose(0,1)\n",
    "#         dense_feature[:, coords[:,0], coords[:,1], coords[:,2]]= sparse_features\n",
    "        return dense_feature.transpose(0, 1)\n",
    "\n",
    "    def forward(self, voxel_features, voxel_coords, batch_size):\n",
    "\n",
    "        # feature learning network\n",
    "        vwfs = self.svfe(voxel_features)\n",
    "        vwfs = self.voxel_indexing(vwfs,voxel_coords, batch_size)\n",
    "\n",
    "        # convolutional middle network\n",
    "        cml_out = self.cml(vwfs)\n",
    "        cml_out = cml_out.view(batch_size, -1,cfg.H, cfg.W)\n",
    "#         print(\"cml_out.shape : \", cml_out.shape)\n",
    "\n",
    "        # region proposal network\n",
    "        score = self.rpn(cml_out, batch_size)\n",
    "        # merge the depth and feature dim into one, output probability score map and regression map\n",
    "        # psm,rm = self.rpn(cml_out.view(cfg.N,-1,cfg.H, cfg.W))\n",
    "        \n",
    "        # classifier\n",
    "#         print(\"score shape : \", score)\n",
    "\n",
    "        return score #psm, rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c7a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_collate(batch):\n",
    "    voxel_features = []\n",
    "    voxel_coords = []\n",
    "    train = True if len(batch[0]) == 3 else False\n",
    "    \n",
    "    for i, sample in enumerate(batch):\n",
    "        voxel_features.append(sample[0])\n",
    "        voxel_coords.append(np.pad(sample[1], ((0,0), (1,0)), mode='constant', constant_values=i))\n",
    "\n",
    "    if train :\n",
    "        return np.concatenate(voxel_features), np.concatenate(voxel_coords), np.array(batch)[:, 2].astype(np.long)\n",
    "    else :\n",
    "        return np.concatenate(voxel_features), np.concatenate(voxel_coords), len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73538de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelDataset(Dataset) :\n",
    "    def __init__(self, id_list, label_list, point_list) :\n",
    "        self.id_list = id_list\n",
    "        self.label_list = label_list\n",
    "        self.point_list = point_list\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        image_id = self.id_list[index]\n",
    "        points= self.point_list[str(image_id)][:]\n",
    "        points = self.rand_sampling(points)\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            points= self.trans_axis_range(points, axis=[0,1,2])\n",
    "            x_degree = self.rand_degree(-np.pi/4, np.pi/4)\n",
    "            y_degree = self.rand_degree(-np.pi/4, np.pi/4)\n",
    "            z_degree = self.rand_degree(-np.pi/6, np.pi/6)\n",
    "            \n",
    "            if CFG['rand_rotation'] :\n",
    "                points = self.rand_rotation(x_degree, y_degree, z_degree, points, p=0.80)\n",
    "                \n",
    "            else :    \n",
    "                points = self.rotation(x_degree, y_degree, z_degree, points)\n",
    "                \n",
    "            points = self.jittering(points, (-0.05, 0.05))\n",
    "            points = self.scaling(points, (0.95, 1.05))\n",
    "            voxel_features, voxel_coords= self.voxelization(points)\n",
    "            label = self.label_list[index]\n",
    "            return voxel_features, voxel_coords, label\n",
    "        \n",
    "        else:\n",
    "            # TTA\n",
    "            points= self.trans_axis_range(points, axis=[0,1,2])\n",
    "            points = self.jittering(points, (-0.05, 0.05))\n",
    "            points = self.scaling(points, (0.95, 1.05))\n",
    "            voxel_features, voxel_coords= self.voxelization(points)\n",
    "            return voxel_features, voxel_coords\n",
    "    \n",
    "    def rand_rotation(self, x_degree, y_degree, z_degree, point, p=0.5) :\n",
    "        _p = np.random.uniform(0, 1)\n",
    "        if _p < p :\n",
    "            return self.rotation(x_degree, y_degree, z_degree, point)\n",
    "        \n",
    "        else :\n",
    "            return point\n",
    "            \n",
    "    def rotation(self, a, b, c, dots):\n",
    "        mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
    "        my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
    "        mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
    "        m = np.dot(np.dot(mx,my),mz)\n",
    "        dots = np.dot(dots, m.T)\n",
    "        return dots\n",
    "    \n",
    "    def jittering(self, point, scale_range) :\n",
    "        point += np.random.uniform(*scale_range, size=point.shape) \n",
    "        return point\n",
    "    \n",
    "    def scaling(self, point, scale_range) :\n",
    "        point *= np.random.uniform(*scale_range)\n",
    "        return point\n",
    "    \n",
    "    def rand_sampling(self, point) :\n",
    "        point_num = point.shape[0]\n",
    "        \n",
    "        if point_num >= 20000 :\n",
    "            sampling_rate=0.6\n",
    "        else :\n",
    "            sampling_rate=0.8\n",
    "            \n",
    "        sampling_idx = np.sort(np.random.choice(point_num, int(point_num * sampling_rate) , replace=False))\n",
    "        point = point[sampling_idx, :]\n",
    "        return point\n",
    "    \n",
    "    def rand_degree(self, *rotation_range) :\n",
    "        assert len([rotation_range]) != 2, 'expected 2 parameters, but given more or less'\n",
    "        return np.random.uniform(*rotation_range)\n",
    "    \n",
    "    def trans_axis_range(self, point, axis=[0]) :\n",
    "        # Transform train point range to test point range\n",
    "        point[:, axis] = point[:, axis] / (np.max(np.abs(cfg.train_range[axis])) + 0.1) * (np.min(np.abs(cfg.test_range[axis])) - 0.1)\n",
    "        return point\n",
    "    \n",
    "    def point_normalize(self, point, test=False) :\n",
    "        axis=[0, 1, 2]\n",
    "        xyzmin = np.min(point, axis=0)\n",
    "        xyzmax = np.max(point, axis=0)\n",
    "        if not test :\n",
    "            point[:, axis] = (point[:, axis] + np.abs(cfg.train_range[axis, 0])) / (np.sum(np.abs(cfg.train_range[axis]), 1))\n",
    "            \n",
    "        else :\n",
    "            point[:, axis] = (point[:, axis] + np.abs(cfg.test_range[axis, 0])) / (np.sum(np.abs(cfg.test_range[axis]), 1))\n",
    "        return point, xyzmin, xyzmax\n",
    "    \n",
    "    def voxelization(self, point):# ,xyzmin, xyzmax) :\n",
    "        point_reflectance = np.zeros((point.shape[0],1))\n",
    "        point = np.concatenate((point, point_reflectance), 1)\n",
    "        \n",
    "        voxel_coords = ((point[:, :3] - np.array([cfg.test_range[0][0], cfg.test_range[1][0], cfg.test_range[2][0]])) / \n",
    "                       (cfg.vw, cfg.vh, cfg.vd)).astype(np.int32)\n",
    "\n",
    "        # convert to (D,H,W)\n",
    "        voxel_coords = voxel_coords[:, [2,1,0]]\n",
    "        voxel_coords, inv_ind, voxel_counts = np.unique(voxel_coords, \n",
    "                                                        axis=0, \n",
    "                                                        return_inverse=True, \n",
    "                                                        return_counts=True)\n",
    "        \n",
    "        voxel_features = []\n",
    "        for i in range(len(voxel_coords)) :\n",
    "            voxel = np.zeros((cfg.T, 7), dtype=np.float32)\n",
    "            pts = point[inv_ind == i]\n",
    "            \n",
    "            # Random sampling\n",
    "            if voxel_counts[i] > cfg.T :\n",
    "                random_sampling = np.random.randint(0, pts.shape[0], size=cfg.T)\n",
    "                pts = pts[random_sampling, : ]\n",
    "                voxel_counts[i] = cfg.T\n",
    "            \n",
    "            voxel[:pts.shape[0], :] = np.concatenate((pts, pts[:, :3] - np.mean(pts[:, :3], 0)), axis=1)\n",
    "            voxel_features.append(voxel)\n",
    "\n",
    "        return np.array(voxel_features), voxel_coords\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b1c94",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecfc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f985339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(label,pred) :\n",
    "    model_preds = pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    true_labels = label.detach().cpu().numpy().tolist()\n",
    "    return accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ccf513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_load(model, optimizer, ckpt) :\n",
    "    checkpoint = torch.load(ckpt)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "#                                                            T_max=CFG['cosine_lr_T_max'], \n",
    "#                                                            eta_min=CFG['cosine_lr_eta_min'])\n",
    "#     scheduler = CosineAnnealingWarmUpRestarts(optimizer, \n",
    "#                                               T_0=7, \n",
    "#                                               T_mult=1, \n",
    "#                                               eta_max=0.001,  \n",
    "#                                               T_up=3, \n",
    "#                                               gamma=0.5)\n",
    "\n",
    "    optimizer.param_groups[0]['initial_lr'] = CFG['LEARNING_RATE']\n",
    "    optimizer.param_groups[0]['lr'] = CFG['LEARNING_RATE']\n",
    "    epoch = CFG['EPOCHS']\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "    return model, optimizer, scheduler, checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00c5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    \n",
    "    if CFG['reuse'] :\n",
    "        model, optimizer, scheduler, E = weight_load(model, optimizer, CFG['checkpoint'])\n",
    "    else :\n",
    "        E = 0\n",
    "    \n",
    "    # tensorboard\n",
    "    log_writter = SummaryWriter(CFG['LOG'])\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    for epoch in range(E, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        training_bar = tqdm(iter(train_loader))\n",
    "        batch = 1\n",
    "        \n",
    "        for vf, vc, label in training_bar:\n",
    "                \n",
    "            vf = torch.tensor(vf).to(device)\n",
    "            vc = torch.tensor(vc).to(device)\n",
    "            label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(vf, vc, batch_size=label.shape[0])\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            acc = cal_acc(label, output)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            training_bar.set_postfix({\n",
    "                'Training Loss' : np.mean(train_loss), \n",
    "                'Training ACC' : np.mean(train_acc)})\n",
    "            \n",
    "            \n",
    "            log_writter.add_scalar('Training Loss',\n",
    "                                    loss.item(),\n",
    "                                    epoch * len(train_loader) + batch)\n",
    "            log_writter.add_scalar('Training Accuracy',\n",
    "                                    acc,\n",
    "                                    epoch * len(train_loader) + batch)\n",
    "            log_writter.add_scalar('Learning Rate',\n",
    "                                    optimizer.param_groups[0]['lr'],\n",
    "                                    epoch * len(train_loader) + batch)\n",
    "            batch += 1\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        val_loss, val_acc = validation(model, criterion, val_loader, device, log_writter)\n",
    "        \n",
    "        log_writter.add_scalar('Validation Loss',\n",
    "                                val_loss,\n",
    "                                epoch)\n",
    "        log_writter.add_scalar('Validation Accuracy',\n",
    "                                val_acc,\n",
    "                                epoch)\n",
    "        \n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss)}] Val Loss : [{val_loss}] Val ACC : [{val_acc}]')\n",
    "        \n",
    "        if best_score < val_acc:\n",
    "            best_score = val_acc\n",
    "            torch.save({\n",
    "                    \"epoch\" : epoch,\n",
    "                    \"model_state_dict\" : model.state_dict(),\n",
    "                    \"optimizer_state_dict\" : optimizer.state_dict()\n",
    "                }, './ckpt/'+str(epoch)+'E-val'+str(best_score)+'-'+CFG['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e8fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device, log_writter):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    model_preds = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for vf, vc, label in tqdm(iter(val_loader)):\n",
    "            vf = torch.tensor(vf).to(device)\n",
    "            vc = torch.tensor(vc).to(device)\n",
    "            label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "\n",
    "            model_pred = model(vf, vc, batch_size=label.shape[0])\n",
    "            loss = criterion(model_pred, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            \n",
    "    return np.mean(val_loss), accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c53a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':45,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':64,\n",
    "    \n",
    "#     'cosine_lr_eta_min' : 1e-4,\n",
    "#     'cosine_lr_T_max' : 10,\n",
    "    'weight_decay' : 0.001,\n",
    "    'rand_rotation' : True,\n",
    "    \n",
    "    'LOG' : \"./tensorboard/randrotate-randsample-jitter-scale-axis-voxelnet/10\",   \n",
    "    'output' : 'lambdalr-randrotate-randsample-jitter-scale-axis-voxelnet.pth',\n",
    "    \n",
    "    'checkpoint' : './ckpt/25E-val0.9599-randrotate-randsample-jitter-scale-axis-voxelnet.pth',\n",
    "    'reuse' : True\n",
    "}\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a15cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./data/train.csv')\n",
    "all_points = h5py.File('./data/train.h5', 'r')\n",
    "\n",
    "train_df = all_df.iloc[:int(len(all_df)*0.8)]\n",
    "val_df = all_df.iloc[int(len(all_df)*0.8):]\n",
    "\n",
    "train_dataset = VoxelDataset(train_df['ID'].values, train_df['label'].values, all_points)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], collate_fn=detection_collate, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = VoxelDataset(val_df['ID'].values, val_df['label'].values, all_points)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], collate_fn=detection_collate, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc765ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975bac775549435f9f8ca3f128f2d288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60e23ab1a71482cb4a753c6219eea05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [25] Train Loss : [0.1959461316972971] Val Loss : [0.19418480935370086] Val ACC : [0.9388]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0593b5232c7745a7b6c7ba99268cdce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3900fa74534b7e9e4427da9a229df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [26] Train Loss : [0.17732841677665712] Val Loss : [0.16929251816906746] Val ACC : [0.9453]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266e56267b36462f948032ba5df49b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c624f95df4e4a9122ed354f6c8906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [27] Train Loss : [0.17326202832758428] Val Loss : [0.16219046029742737] Val ACC : [0.9504]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae983619c754105b5d0f92767ea878d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba905e91b40450aa774af798cc154e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [28] Train Loss : [0.1649622159436345] Val Loss : [0.17141519327926788] Val ACC : [0.9448]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7891d719d04df481888e7a90645531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e87963394254a74acf2de40675c2cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = VoxelNet().to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), \n",
    "                             lr = CFG[\"LEARNING_RATE\"], \n",
    "                             weight_decay=CFG['weight_decay'])\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "#                                                       T_max=CFG['cosine_lr_T_max'], \n",
    "#                                                       eta_min=CFG['cosine_lr_eta_min'])\n",
    "epoch = CFG['EPOCHS']\n",
    "optimizer.param_groups[0]['initial_lr'] = CFG['LEARNING_RATE']\n",
    "optimizer.param_groups[0]['lr'] = CFG['LEARNING_RATE']\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "# scheduler = CosineAnnealingWarmUpRestarts(optimizer, \n",
    "#                                           T_0=7, \n",
    "#                                           T_mult=1, \n",
    "#                                           eta_max=0.001,  \n",
    "#                                           T_up=3, \n",
    "#                                           gamma=0.5)\n",
    "scheduler = None\n",
    "\n",
    "train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0707111",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f614852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device, dim_changer=None):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        for vf, vc, batch_size in tqdm(iter(test_loader)):\n",
    "            vf = torch.tensor(vf).to(device)\n",
    "            vc = torch.tensor(vc).to(device)\n",
    "\n",
    "            batch_pred = model(vf, vc, batch_size=batch_size)\n",
    "            \n",
    "            model_preds += batch_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a74e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/sample_submission.csv')\n",
    "test_points = h5py.File('./data/test.h5', 'r')\n",
    "\n",
    "test_dataset = VoxelDataset(test_df['ID'].values, None, test_points)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'],  collate_fn=detection_collate, shuffle=False, num_workers=0)\n",
    "\n",
    "checkpoint = torch.load('./ckpt/25E-val0.9599-randrotate-randsample-jitter-scale-axis-voxelnet.pth')\n",
    "model = VoxelNet().to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b139487",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0febf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = preds\n",
    "\n",
    "test_df.to_csv('./submission/tta-25E-val0.9599-axistrans-randrotate-randsample-jitter-scale-axis-voxelnet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6955f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
