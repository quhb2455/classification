{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32523444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py # .h5 파일을 읽기 위한 패키지\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from cfg.voxelnet_cfg import config as cfg \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "67cb3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "# conv2d + bn + relu\n",
    "class Conv2d(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,k,s,p, activation=True, batch_norm=True):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=k,stride=s,padding=p)\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        self.activation = activation\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x=self.bn(x)\n",
    "        if self.activation:\n",
    "            return F.relu(x,inplace=True)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# conv3d + bn + relu\n",
    "class Conv3d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, k, s, p, batch_norm=True):\n",
    "        super(Conv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=k, stride=s, padding=p)\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm3d(out_channels)\n",
    "        else:\n",
    "            self.bn = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "# Fully Connected Network\n",
    "class FCN(nn.Module):\n",
    "\n",
    "    def __init__(self,cin,cout):\n",
    "        super(FCN, self).__init__()\n",
    "        self.cout = cout\n",
    "        self.linear = nn.Linear(cin, cout)\n",
    "        self.bn = nn.BatchNorm1d(cout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # KK is the stacked k across batch\n",
    "        kk, t, _ = x.shape\n",
    "        x = self.linear(x.view(kk*t,-1))\n",
    "        x = F.relu(self.bn(x))\n",
    "        return x.view(kk,t,-1)\n",
    "\n",
    "# Voxel Feature Encoding layer\n",
    "class VFE(nn.Module):\n",
    "\n",
    "    def __init__(self,cin,cout):\n",
    "        super(VFE, self).__init__()\n",
    "        assert cout % 2 == 0\n",
    "        self.units = cout // 2\n",
    "        self.fcn = FCN(cin,self.units)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # point-wise feauture\n",
    "        pwf = self.fcn(x)\n",
    "        #locally aggregated feature\n",
    "        laf = torch.max(pwf,1)[0].unsqueeze(1).repeat(1,cfg.T,1)\n",
    "        # point-wise concat feature\n",
    "        pwcf = torch.cat((pwf,laf),dim=2)\n",
    "        # apply mask\n",
    "        mask = mask.unsqueeze(2).repeat(1, 1, self.units * 2)\n",
    "        pwcf = pwcf * mask.float()\n",
    "\n",
    "        return pwcf\n",
    "\n",
    "# Stacked Voxel Feature Encoding\n",
    "class SVFE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVFE, self).__init__()\n",
    "        self.vfe_1 = VFE(7,32)\n",
    "        self.vfe_2 = VFE(32,128)\n",
    "        self.fcn = FCN(128,128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mask = torch.ne(torch.max(x,2)[0], 0)\n",
    "        x = self.vfe_1(x, mask)\n",
    "        x = self.vfe_2(x, mask)\n",
    "        x = self.fcn(x)\n",
    "        # element-wise max pooling\n",
    "        x = torch.max(x,1)[0]\n",
    "        return x\n",
    "\n",
    "# Convolutional Middle Layer\n",
    "class CML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CML, self).__init__()\n",
    "        self.conv3d_1 = Conv3d(128, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n",
    "        self.conv3d_2 = Conv3d(64, 64, 3, s=(1, 1, 1), p=(0, 1, 1))\n",
    "        self.conv3d_3 = Conv3d(64, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d_1(x)\n",
    "        x = self.conv3d_2(x)\n",
    "        x = self.conv3d_3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# classifier\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, cin, num_classes=10, dropout_rate=0.5):\n",
    "        super(Classifier, self).__init__()  \n",
    "        \n",
    "        self.linear_1 = nn.Sequential(\n",
    "            nn.Linear(cin, cin//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.linear_2 = nn.Sequential(\n",
    "            nn.Linear(cin//2, cin//4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.linear_3 = nn.Linear(cin//4, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # KK is the stacked k across batch\n",
    "        b, f, _ = x.shape\n",
    "        x = self.linear_1(x.view(b * f, -1))\n",
    "        x = self.linear_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class VoxelNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VoxelNet, self).__init__()\n",
    "        self.svfe = SVFE()\n",
    "        self.cml = CML()\n",
    "#         self.rpn = RPN()\n",
    "        self.cls = Classifier(cin=64)\n",
    "        \n",
    "    def voxel_indexing(self, sparse_features, coords):\n",
    "        dim = sparse_features.shape[-1]\n",
    "        print(sparse_features.shape)\n",
    "        dense_feature = torch.zeros(dim, cfg.N, cfg.D, cfg.H, cfg.W).to(cfg.device)\n",
    "\n",
    "        dense_feature[:, coords[:,0], coords[:,1], coords[:,2], coords[:,3]]= sparse_features\n",
    "\n",
    "        return dense_feature.transpose(0, 1)\n",
    "\n",
    "    def forward(self, voxel_features, voxel_coords):\n",
    "\n",
    "        # feature learning network\n",
    "        vwfs = self.svfe(voxel_features)\n",
    "        vwfs = self.voxel_indexing(vwfs,voxel_coords)\n",
    "\n",
    "        # convolutional middle network\n",
    "        cml_out = self.cml(vwfs)\n",
    "\n",
    "        # region proposal network\n",
    "\n",
    "        # merge the depth and feature dim into one, output probability score map and regression map\n",
    "        # psm,rm = self.rpn(cml_out.view(cfg.N,-1,cfg.H, cfg.W))\n",
    "        \n",
    "        # classifier\n",
    "        score = self.cls(cml_out)\n",
    "\n",
    "        return score #psm, rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "470749a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([1,2,8,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1b2ed515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_collate(batch):\n",
    "    voxel_features = []\n",
    "    voxel_coords = []\n",
    "    label = []\n",
    "    shapes = [s[0].shape[0] for s in batch]\n",
    "    ind_max = np.argmax(shapes)\n",
    "    ind_min = np.argmin(shapes)\n",
    "    diff_shapes = shapes[ind_max] - shapes[ind_min]\n",
    "    \n",
    "    for i, sample in enumerate(batch):\n",
    "        print(\"diff_shapes : \", diff_shapes)\n",
    "        print(\"sample[0] : \" ,sample[0].shape)\n",
    "        print(\"sample[1] : \" ,sample[1].shape)\n",
    "        if ind_max == i :\n",
    "            voxel_features.append(sample[0])\n",
    "            voxel_coords.append(sample[1])\n",
    "        else :\n",
    "            voxel_features.append(F.pad(sample[0], (0,0,0,0,diff_shapes,0), \"constant\", 0))\n",
    "            print(\"voxel_Feauture : \", F.pad(sample[0], (0,0,0,0,diff_shapes,0)).shape)\n",
    "#         voxel_coords.append(\n",
    "#             F.pad(sample[1], (0, 0, 1, 0), mode='constant', value=i))\n",
    "        \n",
    "            voxel_coords.append(F.pad(sample[1], (0,0,diff_shapes,0), \"constant\", 0))\n",
    "            print(\"voxel_coord : \", F.pad(sample[1], (0,0,diff_shapes,0)).shape)\n",
    "        \n",
    "        label.append(sample[2])\n",
    "\n",
    "    return torch.stack(voxel_features, dim=0), torch.stack(voxel_coords, dim=0), torch.Tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e73538de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelDataset(Dataset) :\n",
    "    def __init__(self, id_list, label_list, point_list) :\n",
    "        self.id_list = id_list\n",
    "        self.label_list = label_list\n",
    "        self.point_list = point_list\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        image_id = self.id_list[index]\n",
    "        \n",
    "        points= self.point_list[str(image_id)][:]\n",
    "        voxel_features, voxel_coords= self.voxelization(points)\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return torch.Tensor(voxel_features), torch.Tensor(voxel_coords), label\n",
    "        else:\n",
    "            return torch.Tensor(voxel_features), torch.Tensor(voxel_coords)\n",
    "    \n",
    "    def voxelization(self, point) :\n",
    "        voxel_coords = ((point - np.array([cfg.xrange[0], cfg.yrange[0], cfg.zrange[0]])) / \n",
    "                       (cfg.vw, cfg.vh, cfg.vd)).astype(np.int32)\n",
    "        \n",
    "        # convert to (D,H,W)\n",
    "        voxel_coords = voxel_coords[:, [2,1,0]]\n",
    "        voxel_coords, inv_ind, voxel_counts = np.unique(voxel_coords, \n",
    "                                                        axis=0, \n",
    "                                                        return_inverse=True, \n",
    "                                                        return_counts=True)\n",
    "        \n",
    "        \n",
    "        voxel_features = []\n",
    "        for i in range(len(voxel_coords)) :\n",
    "            voxel = np.zeros((cfg.T, 7), dtype=np.float32)\n",
    "            pts = point[inv_ind == i]\n",
    "            if voxel_counts[i] > cfg.T :\n",
    "                pts = pts[:cfg.T, : ]\n",
    "                voxel_counts[i] = cfg.T\n",
    "            \n",
    "            voxel[:pts.shape[0], :6] = np.concatenate((pts[:, :3], pts[:, :3] - np.mean(pts[:, :3], 0)), axis=1)\n",
    "            voxel_features.append(voxel)\n",
    "\n",
    "        return np.array(voxel_features), voxel_coords\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e172b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./data/train.csv')\n",
    "all_points = h5py.File('./data/train.h5', 'r')\n",
    "\n",
    "train_df = all_df.iloc[:int(len(all_df)*0.8)]\n",
    "\n",
    "train_dataset = VoxelDataset(train_df['ID'].values, train_df['label'].values, all_points)\n",
    "train_loader = DataLoader(train_dataset, batch_size = cfg.N,  collate_fn=detection_collate, shuffle=True, num_workers=0)\n",
    "\n",
    "model = VoxelNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "528908e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_shapes :  16\n",
      "sample[0] :  torch.Size([18, 35, 7])\n",
      "sample[1] :  torch.Size([18, 3])\n",
      "voxel_Feauture :  torch.Size([34, 35, 7])\n",
      "voxel_coord :  torch.Size([34, 3])\n",
      "diff_shapes :  16\n",
      "sample[0] :  torch.Size([34, 35, 7])\n",
      "sample[1] :  torch.Size([34, 3])\n",
      "train f :  torch.Size([2, 34, 35, 7])\n",
      "train c :  torch.Size([2, 34, 3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [243]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain f : \u001b[39m\u001b[38;5;124m\"\u001b[39m, f\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain c : \u001b[39m\u001b[38;5;124m\"\u001b[39m, c\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36mVoxelNet.forward\u001b[1;34m(self, voxel_features, voxel_coords)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, voxel_features, voxel_coords):\n\u001b[0;32m    164\u001b[0m \n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# feature learning network\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     vwfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxel_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     vwfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_indexing(vwfs,voxel_coords)\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# convolutional middle network\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36mSVFE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     92\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mne(torch\u001b[38;5;241m.\u001b[39mmax(x,\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvfe_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvfe_2(x, mask)\n\u001b[0;32m     95\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcn(x)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36mVFE.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# point-wise feauture\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     pwf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m#locally aggregated feature\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     laf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(pwf,\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,cfg\u001b[38;5;241m.\u001b[39mT,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36mFCN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# KK is the stacked k across batch\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     kk, t, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x\u001b[38;5;241m.\u001b[39mview(kk\u001b[38;5;241m*\u001b[39mt,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     57\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "for f, c, l in train_loader :\n",
    "    print(\"train f : \", f.shape)\n",
    "    print(\"train c : \", c.shape)\n",
    "    a = model(f,c)\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e81b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888abbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f614852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
