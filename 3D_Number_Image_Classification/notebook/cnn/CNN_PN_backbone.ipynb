{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc61e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointnet.train import setup as train_setup\n",
    "from pointnet.test import setup as test_setup\n",
    "from pointnet.utils.train_utils import CheckpointSaver, set_seeds\n",
    "\n",
    "from cnn import models, utils\n",
    "from cnn.datasets import *\n",
    "\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bdfe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PN_CNN_ENSEMBLE(nn.Module) :\n",
    "    def __init__(self,pn, cnn) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pn = pn\n",
    "        self.cnn = cnn\n",
    "        self.cnn_flatten = nn.Sequential(            \n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2304, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, pn_input, cnn_input) :\n",
    "        pn_output = self.pn(pn_input)\n",
    "        cnn_output = self.cnn_flatten(self.cnn.model.forward_features(cnn_input))\n",
    "        output = self.classifier(torch.concat([pn_output,cnn_output], dim=1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074e2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, \n",
    "               cnn_valid_loader, pn_valid_loader,\n",
    "               device, log_writter):\n",
    "    \n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    model_preds = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for (pn, label), (img, _) in tqdm(zip(pn_valid_loader, cnn_valid_loader)):\n",
    "            label = label.to(device)\n",
    "            output = model(pn.to(device), img.to(device))\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            model_preds += output.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()            \n",
    "            \n",
    "    return np.mean(val_loss), accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcef213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, criterion, \n",
    "             cnn_train_loader, cnn_valid_loader, \n",
    "             pn_train_loader, pn_valid_loader,\n",
    "             device) :\n",
    "        \n",
    "    # tensorboard\n",
    "    log_writter = SummaryWriter(train_arg['LOG'])\n",
    "    best_score = 0\n",
    "    for epoch in range(1, train_arg['EPOCHS'] + 1) :\n",
    "        \n",
    "        tqdm_train = tqdm(zip(pn_train_loader, cnn_train_loader))\n",
    "        train_acc, train_loss = [], []\n",
    "        \n",
    "        for batch, ((pn, label), (img, _)) in enumerate(tqdm_train, start=1) :\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "                        \n",
    "            label = label.to(device)\n",
    "            output = model(pn.to(device), img.to(device))\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            acc = utils.score(label, output)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            tqdm_train.set_postfix({\n",
    "                'Training Acc' : np.mean(train_acc),\n",
    "                'Training Loss' : np.mean(train_loss)\n",
    "            })\n",
    "            \n",
    "            data = {\n",
    "                'training loss' : loss.item(),\n",
    "                'training acc' : acc\n",
    "            }\n",
    "            utils.logging(log_writter, data, epoch * len(pn_train_loader) + batch)\n",
    "        \n",
    "        # validation\n",
    "        val_loss, val_acc = validation(model, criterion, \n",
    "                                       cnn_valid_loader, pn_valid_loader,\n",
    "                                       device, log_writter)\n",
    "        \n",
    "        data = {\n",
    "            'validation loss' : val_loss,\n",
    "            'validation acc' : val_acc\n",
    "        }\n",
    "        utils.logging(log_writter, data, epoch)\n",
    "        print(f'Epoch : [{epoch}] Val Loss : [{val_loss}] Val ACC : [{val_acc}]')\n",
    "        \n",
    "        if best_score < val_acc:\n",
    "            best_score = val_acc\n",
    "            torch.save({\n",
    "                    \"epoch\" : epoch,\n",
    "                    \"model_state_dict\" : model.state_dict(),\n",
    "                    \"optimizer_state_dict\" : optimizer.state_dict()\n",
    "                }, './ckpt/'+str(epoch)+'E-val'+str(best_score)+'-'+train_arg['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561955ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_arg = EasyDict({\n",
    "    \"config\" : \"./pointnet/configs/pointnet2_config.yaml\",\n",
    "    \"workspace\" : './pointnet/workspace',\n",
    "    \"tensorboard_dir\" : \"./pointnet/runs\",\n",
    "    'restore_path' : './pointnet/workspace/pointnet2/checkpoints/best.epoch0099-score0.9676.pth',\n",
    "    \"write_lr\" : \"n\",\n",
    "    \"seed\" : 2455,\n",
    "    \"save_step\" : 10,\n",
    "    \"continue_train\" : \"y\",\n",
    "})\n",
    "\n",
    "train_arg = EasyDict({\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':16,\n",
    "    \n",
    "    'output' : 'pointnet_effib0_ensemble.pth',\n",
    "    'LOG' : \"./tensorboard/pn_cnn\",   \n",
    "})\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058fac3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 40000\n",
      "val data: 10000\n",
      "loading model from ./pointnet/workspace/pointnet2/checkpoints/best.epoch0099-score0.9676.pth...\n",
      "Error(s) in loading state_dict for PointNet2Cls:\n",
      "\tUnexpected key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.5.weight\", \"classifier.5.bias\", \"classifier.5.running_mean\", \"classifier.5.running_var\", \"classifier.5.num_batches_tracked\", \"classifier.8.weight\", \"classifier.8.bias\". \n",
      "ignore unmatching keys...\n",
      "config path: ./pointnet/configs/pointnet2_config.yaml\n"
     ]
    }
   ],
   "source": [
    "_, _, _, dataloaders, _, pn_model, _, _, _, _, _, _, _, _ =train_setup(pn_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89336b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = models.CNN('efficientnet_b0').to(device)\n",
    "checkpoint = torch.load('./ckpt/69E-val0.9611-4fold_3fold_2fold_1fold_0fold_scratch-weigt_freeze10E-mixup25E-grid_shuffle35E-focal-effib0.pth')\n",
    "cnn_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_train_loader = dataloaders['train']\n",
    "pn_valid_loader = dataloaders['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8621eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_set, label_set, transform = image_label_dataset(df_path='./data/train.csv', \n",
    "                                                     img_path = './data/img/224img_train/*',\n",
    "                                                     div=0.8, grid_shuffle_p=0, training=True)\n",
    "cnn_train_loader, cnn_valid_loader = train_and_valid_dataload(img_set, label_set, transform, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b20e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_model = utils.weight_freeze(pn_model)\n",
    "cnn_model = utils.weight_freeze(cnn_model)\n",
    "ensemble_model = PN_CNN_ENSEMBLE(pn_model, cnn_model).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(ensemble_model.parameters(), \n",
    "                             lr=train_arg['LEARNING_RATE'])\n",
    "criterion = nn.CrossEntropyLoss() #FocalLoss(CFG['focal_alpha'], CFG['focal_gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d88e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [18:15,  2.28it/s, Training Acc=0.961, Training Loss=0.179]\n",
      "625it [04:26,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Val Loss : [0.06749554616883396] Val ACC : [0.9798]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [17:34,  2.37it/s, Training Acc=0.975, Training Loss=0.0876]\n",
      "625it [04:13,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Val Loss : [0.05453034588862211] Val ACC : [0.9837]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [17:28,  2.38it/s, Training Acc=0.979, Training Loss=0.0709]\n",
      "625it [04:13,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Val Loss : [0.05328896128199995] Val ACC : [0.9842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [17:32,  2.38it/s, Training Acc=0.98, Training Loss=0.0627] \n",
      "625it [04:26,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Val Loss : [0.0559958429697901] Val ACC : [0.984]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [19:29,  2.14it/s, Training Acc=0.983, Training Loss=0.0558]\n",
      "625it [04:43,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Val Loss : [0.05118099400047213] Val ACC : [0.9851]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training(ensemble_model, optimizer, criterion, \n",
    "         cnn_train_loader, cnn_valid_loader, \n",
    "         pn_train_loader, pn_valid_loader,\n",
    "         device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfbf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, pn_loader, cnn_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        for (pn, _), img in tqdm(zip(pn_loader, cnn_loader)):\n",
    "            \n",
    "            output = model(pn.to(device), img.to(device))\n",
    "            \n",
    "            model_preds += output.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045cedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_arg = EasyDict({\n",
    "    \"batch_size\" : 16,\n",
    "    \"csv_filename\" : \"5E-val0.9851-pointnet_effib0_ensemble\",\n",
    "    \"config\" : \"./pointnet/configs/pointnet2_config.yaml\",\n",
    "    \"workspace\" : './pointnet/workspace',\n",
    "    \"seed\" : None,\n",
    "})\n",
    "\n",
    "test_arg = EasyDict({\n",
    "    'batch_size' : 16,\n",
    "})\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7b4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: 40000\n",
      "loading model from ./pointnet/workspace\\pointnet2\\checkpoints\\best.epoch0099-score0.9676.pth...\n",
      "Error(s) in loading state_dict for PointNet2Cls:\n",
      "\tUnexpected key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.5.weight\", \"classifier.5.bias\", \"classifier.5.running_mean\", \"classifier.5.running_var\", \"classifier.5.num_batches_tracked\", \"classifier.8.weight\", \"classifier.8.bias\". \n",
      "ignore unmatching keys...\n"
     ]
    }
   ],
   "source": [
    "_, pn_loader, pn_model, _, _ = test_setup(pn_arg)\n",
    "cnn_model = models.CNN('efficientnet_b0').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525a45f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./ckpt/5E-val0.9851-pointnet_effib0_ensemble.pth')\n",
    "\n",
    "ensemble_model = PN_CNN_ENSEMBLE(pn_model, cnn_model).to(device)\n",
    "ensemble_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e9b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = img_parser('./data/img/224img_test/*', None, training=False)\n",
    "transform = transform_parser(grid_shuffle_p=0)\n",
    "cnn_loader = custom_dataload(test_img, None, test_arg.batch_size, transform, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70981de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [18:09,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = predict(ensemble_model, pn_loader, cnn_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c5772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/sample_submission.csv')\n",
    "test_df['label'] = preds\n",
    "test_df.to_csv('./submission/5E-val0.9851-pointnet_effib0_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17aa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
