{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3f2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _18color_faiss import BaseMain\n",
    "\n",
    "cfg = {\n",
    "        \"mode\" : \"train\", #train, #infer\n",
    "        \n",
    "        \"model_name\" : \"seresnext50_32x4d\", #\"tf_efficientnetv2_m.in21k\", #\"swinv2_base_window12to16_192to256_22kft1k\",\n",
    "        # \"tf_efficientnet_b4\", #\"resnetv2_101x1_bit\", #\"resnetv2_152x2_bit\", #\"resnetv2_50x1_bit\",\n",
    "        #\"tf_efficientnetv2_s.in21k\",#\"eva_large_patch14_196.in22k_ft_in1k\",, #\"wide_resnet101_2\", #\"seresnext50_32x4d\"\n",
    "        #\"beit_base_patch16_224.in22k_ft_in22k\", #\"convnextv2_base.fcmae_ft_in1k\", #\"seresnet101\", #\"seresnext101_64x4d\"\n",
    "        #\"nf_resnet50\",#\"nfnet_f1\"\n",
    "        \"num_classes\" : 18,\n",
    "        \n",
    "        \"learning_rate\" : 5e-4,\n",
    "        \"focal_alpha\" : 2,\n",
    "        \"focal_gamma\" : 2,\n",
    "        \"resize\" : 224,\n",
    "        \n",
    "        \"data_train_path\" : \"./Dataset/Train\",\n",
    "        \"data_train_csv_path\" : \"./Dataset/aug_info_etri20_color_train.csv\",\n",
    "        \"data_valid_path\" : \"./Dataset/Validation\",\n",
    "        \"data_valid_csv_path\" : \"./Dataset/info_etri20_color_validation.csv\",\n",
    "        \n",
    "        \"data_infer_path\" : \"/aif/Dataset/Test/\",\n",
    "        \"data_infer_csv_path\" : \"/aif/Dataset/info_etri20_color_test.csv\",\n",
    "        # \"data_infer_path\" : \"./sub-task2/Dataset/Test_sample\",\n",
    "        # \"data_infer_csv_path\" : \"./sub-task2/Dataset/info_etri20_color_test_sample.csv\",\n",
    "        \n",
    "        \"epochs\" : 80,\n",
    "        \"batch_size\" : 32,\n",
    "        \"num_worker\" : 4,\n",
    "        \"early_stop_patient\" : 30,\n",
    "        \n",
    "        \"reuse\" : True, #True, #False\n",
    "        \"weight_path\" : \"./ckpt/seresnext50_32x4d/SpatialAug_SmallSize_GridTTA/77E-val0.6163044630766803-seresnext50_32x4d.pth\",\n",
    "        \n",
    "        \"save_path\" : \"./ckpt/seresnext50_32x4d/OfflineAug\",\n",
    "        \"output_path\" : \"./output/seresnext50_32x4d/OfflineAug\",\n",
    "        \"log_path\" : \"./logging/OfflineAug\",\n",
    "        \"device\" : \"cuda\",\n",
    "        \n",
    "        \"binary_mode\" : False,\n",
    "        \n",
    "        \"loss_weight\" : [0.8622, 1.2872, 1.0935, 0.9228, 0.9122, 1.0983, 1.1635, 1.0886,\n",
    "                        1.015 , 1.1258, 0.9061, 0.9446, 0.9728, 0.8595, 0.9743, 0.9163,\n",
    "                        0.9292, 0.9281],\n",
    "        \n",
    "        \n",
    "        \"seed\": 2455,\n",
    "        \"note\" : [\"offline aug for distance smapling data\",\n",
    "                \"Cutmix 사용\", \"CE Loss 사용\", \"Adam Optim 사용\"]\n",
    "    } \n",
    "\n",
    "cfg[\"shuffle\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c696dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_main = BaseMain(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c88bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "resize = 224\n",
    "transform = A.Compose([\n",
    "    A.Resize(resize, resize),\n",
    "    A.Normalize(),\n",
    "    # A.Normalize(mean=(0.548172032,0.467046563,0.434142448),\n",
    "    #             std=(0.12784231,0.122905336,0.119736256)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04b1b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 18])\n",
      "tensor([ 3,  8,  9,  3, 16, 16, 16,  8, 16,  3,  7,  7,  3, 11, 12,  1, 10,  1,\n",
      "        16, 17,  6,  8, 15, 13,  0,  5,  2,  8,  9,  7, 11,  0])\n",
      "torch.Size([32, 18])\n",
      "tensor([ 9, 10,  5,  0,  0, 16,  1, 11,  5,  2,  0, 13,  1, 10, 10, 13,  0,  8,\n",
      "         3,  0, 12,  6, 10, 14, 11, 15,  6,  9, 15,  2, 17,  7])\n",
      "torch.Size([32, 18])\n",
      "tensor([ 0, 17,  1, 17,  9, 12,  0,  0, 12,  6, 14,  5,  1, 12,  9,  8, 17,  0,\n",
      "        11, 16,  9,  0, 13,  8, 11,  0,  4, 17, 17,  7,  0,  4])\n",
      "torch.Size([32, 18])\n",
      "tensor([ 9,  0,  4, 12,  0, 13,  0, 11, 11, 11, 11,  8, 13, 14,  1, 13, 11,  4,\n",
      "         2, 10,  3,  9, 15, 17,  1, 14,  1, 16, 12, 15,  5, 15])\n",
      "torch.Size([32, 18])\n",
      "tensor([15, 17,  6, 10,  0, 12,  5,  4, 12, 11, 11, 17,  1, 10, 10,  1,  9,  5,\n",
      "         1,  7,  7,  6, 10,  6,  7,  7,  8, 14,  0, 16, 11,  1])\n",
      "torch.Size([32, 18])\n",
      "tensor([16,  6,  1,  4, 14, 12, 11,  7, 13,  3, 12,  3, 11,  9,  5,  0,  7,  6,\n",
      "         8, 12, 15, 16,  5, 12,  3,  5,  3,  7,  5,  0,  6,  7])\n",
      "torch.Size([32, 18])\n",
      "tensor([ 8,  1, 13,  9,  9, 12,  6,  2,  4, 11,  7, 14,  7, 10,  4, 11,  6,  2,\n",
      "        12,  6,  9, 10,  5,  5, 17, 14,  0,  9,  3,  8,  9,  3])\n",
      "torch.Size([32, 18])\n",
      "tensor([ 7, 14,  5, 17,  6,  4, 17, 13,  0,  6, 10, 12,  2,  5,  9, 11, 10, 17,\n",
      "        15, 15, 17,  2,  5,  7,  4,  8, 10,  4, 16, 17, 16,  8])\n",
      "torch.Size([32, 18])\n",
      "tensor([ 0,  8, 15,  9, 14,  8, 17, 16,  1,  2, 10, 12,  8, 15, 15, 13,  0, 15,\n",
      "        15,  7,  9, 16,  1,  9,  6,  9, 14, 11, 13,  6,  6,  1])\n",
      "torch.Size([32, 18])\n",
      "tensor([14,  4,  2,  4, 14, 15, 15,  3, 12, 11,  4, 17, 17,  3, 13,  8, 14, 16,\n",
      "        15,  7,  0,  3,  6,  4,  2,  1, 13, 16, 16,  9, 13, 15])\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "embs = []\n",
    "labels = []\n",
    "for img, label in base_main.valid_loader :\n",
    "    img = img.to(cfg[\"device\"])\n",
    "    emb = base_main.model(img)\n",
    "    \n",
    "    print(emb.shape)\n",
    "    print(label)\n",
    "    \n",
    "    embs.append(emb.detach().cpu().numpy())\n",
    "    labels.append(label.detach().cpu().numpy())\n",
    "    if cnt == 10 :\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87cb70bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 18)\n",
      "(320,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "_embs = np.concatenate([*embs], axis=0)\n",
    "_labels = np.concatenate([*labels], axis=0)\n",
    "print(_embs.shape)\n",
    "print(_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2d0f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "u = umap.UMAP()\n",
    "embedding = u.fit_transform(_embs, _labels)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ab534e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "# _emb = emb.detach().cpu().numpy()\n",
    "v = embedding[32:]\n",
    "q = embedding[:32]\n",
    "\n",
    "ncentroids = 18\n",
    "niter = 20\n",
    "verbose = True\n",
    "d = v.shape[1]\n",
    "kmeans = faiss.Kmeans(d, ncentroids, niter=niter, verbose=verbose)\n",
    "kmeans.train(v)\n",
    "\n",
    "output = kmeans.index.search(q, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dbd25ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.6818657e-01, 4.2748642e-01, 1.0984039e-01, 6.2202835e-01,\n",
       "       1.5490580e+00, 2.3709488e-01, 8.7512970e-02, 1.8310547e-04,\n",
       "       1.7451048e+00, 1.0868359e+00, 5.7999802e-01, 4.3184662e-01,\n",
       "       9.3663597e-01, 3.6287308e-02, 2.1261597e-01, 6.7300415e-01,\n",
       "       9.8933029e-01, 4.4744873e-01, 1.4165373e+00, 2.5086975e-01,\n",
       "       4.4952774e-01, 4.1925240e-01, 1.0943222e-01, 6.0192966e-01,\n",
       "       9.7041321e-01, 2.4757385e-03, 8.3040619e-01, 2.3669052e-01,\n",
       "       3.4387970e-01, 1.3944473e+00, 1.0197449e-01, 5.7863617e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bddc74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  2, 15, 10, 13, 17,  8,  4, 13, 10, 10, 10, 10, 11,  2,  5, 11,\n",
       "        5, 13,  9,  2, 10,  0,  3, 11, 12, 15,  2, 15,  6, 11, 12],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c42215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  7,  8, 14, 13, 17, 16, 15, 11,  7,  3, 13, 13,  6,  4, 15,  5,  6,\n",
       "        13,  1, 12,  8,  2, 15,  1,  3, 16, 14, 16, 14, 11, 15])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([ 3,  8,  9,  3, 16, 16, 16,  8, 16,  3,  7,  7,  3, 11, 12,  1, 10,  1,\n",
    "        16, 17,  6,  8, 15, 13,  0,  5,  2,  8,  9,  7, 11,  0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aba1c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "2\n",
      "[[ 2.77829289e+00 -1.78601861e+00]\n",
      " [ 2.04424691e+00  4.55984211e+00]\n",
      " [-3.43056393e+00  4.04125309e+00]\n",
      " [-7.73954717e-03  1.87284362e+00]\n",
      " [ 1.80512943e+01  2.44813770e-01]\n",
      " [-9.01733589e+00  1.31401405e+01]\n",
      " [ 4.42787933e+00  2.32777262e+00]\n",
      " [-2.74525452e+00  8.20581317e-01]\n",
      " [-3.99737048e+00  2.77527118e+00]\n",
      " [-4.77781248e+00  3.43265629e+00]\n",
      " [ 3.69156361e+00 -5.97504497e-01]\n",
      " [-4.99571413e-02  3.98870254e+00]\n",
      " [ 1.34061837e+00  4.70820141e+00]\n",
      " [ 1.97944522e+00  5.31260490e-01]\n",
      " [-4.93685102e+00  1.23555765e+01]\n",
      " [ 3.98814249e+00  4.97100973e+00]\n",
      " [-1.89098418e+00  5.68493414e+00]\n",
      " [-1.23347187e+00  3.11454535e+00]]\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__swig_destroy__', '__weakref__', 'add', 'add_c', 'add_with_ids', 'add_with_ids_c', 'assign', 'assign_c', 'check_compatible_for_merge', 'code_size', 'codes', 'compute_distance_subset', 'compute_residual', 'compute_residual_n', 'd', 'get_CodePacker', 'get_FlatCodesDistanceComputer', 'get_distance_computer', 'get_xb', 'is_trained', 'merge_from', 'metric_arg', 'metric_type', 'ntotal', 'range_search', 'range_search_c', 'reconstruct', 'reconstruct_batch', 'reconstruct_batch_c', 'reconstruct_c', 'reconstruct_n', 'reconstruct_n_c', 'remove_ids', 'remove_ids_c', 'reset', 'sa_code_size', 'sa_decode', 'sa_decode_c', 'sa_encode', 'sa_encode_c', 'search', 'search_and_reconstruct', 'search_and_reconstruct_c', 'search_c', 'this', 'thisown', 'train', 'train_c', 'verbose']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(kmeans.k)\n",
    "print(kmeans.d)\n",
    "print(kmeans.centroids)\n",
    "print(dir(kmeans.index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
