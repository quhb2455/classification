{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a514df6",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2589e20",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d14845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c92feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(filename, label):\n",
    "    img_read = tf.io.read_file(filename)\n",
    "    img_decode = tf.image.decode_jpeg(img_read, channels=3)\n",
    "    img_resize = tf.image.resize(img_decode, [224,224])\n",
    "    return img_resize, label\n",
    "\n",
    "def create_dataset(filenames, labels) :\n",
    "    BATCH_SIZE = 16\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac6ea471",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "labels = []\n",
    "with open('./casia/label/label.txt', 'r') as f :\n",
    "    lines = f.readlines()\n",
    "    for line in lines :\n",
    "        line = line.strip()\n",
    "        names.append(line.split()[0])\n",
    "        labels.append([int(i) for i in line.split()[1:]])\n",
    "    \n",
    "image_path = './casia/img'    \n",
    "image_names = [os.path.join(image_path, name) for name in names ]\n",
    "\n",
    "dataset = create_dataset(image_names, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185a3d1",
   "metadata": {},
   "source": [
    "### Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6ed9307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 204,358\n",
      "Trainable params: 204,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(224,224,3)))\n",
    "model.add(layers.Conv2D(32,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(128,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64,3,padding='same', activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816dceb2",
   "metadata": {},
   "source": [
    "### define metrics and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e68527c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC')\n",
    "]\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint('./check/cp.ckpt',\n",
    "                                        save_weights_only=True,\n",
    "                                      save_freq='epoch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        factor=0.1, patience=5,\n",
    "                                        min_lr=1e-13)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af32b1a",
   "metadata": {},
   "source": [
    "### model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24d2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "             metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df37371",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecfd8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 397s 634ms/step - loss: 0.4389 - accuracy: 0.8066 - precision: 0.6447 - recall: 0.4599 - AUC: 0.8283\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 482s 771ms/step - loss: 0.3757 - accuracy: 0.8364 - precision: 0.7133 - recall: 0.5495 - AUC: 0.8661\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 463s 740ms/step - loss: 0.3575 - accuracy: 0.8460 - precision: 0.7302 - recall: 0.5840 - AUC: 0.8795\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,\n",
    "                    batch_size=16,\n",
    "                    epochs=3, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d75dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50 = tf.keras.applications.resnet.ResNet50(input_shape=(256,256,3),\n",
    "                                                 weights='imagenet',\n",
    "                                                 include_top=False)\n",
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66facf6a",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d22e6",
   "metadata": {},
   "source": [
    "### dataload - non augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6612bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(filename, label) :\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [256,256])\n",
    "    return img, label\n",
    "\n",
    "def create_dataset(filenames, labels) :\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1203c",
   "metadata": {},
   "source": [
    "### dataload - augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51edcdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 10000/10000 [00:11<00:00, 887.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "names = []\n",
    "labels = []\n",
    "with open('./casia/label/label.txt', 'r') as f :\n",
    "    lines = f.readlines()\n",
    "    for line in lines :\n",
    "        line = line.strip()\n",
    "        names.append(line.split()[0])\n",
    "        labels.append([int(i) for i in line.split()[1:]])\n",
    "\n",
    "image_path = './casia/img'\n",
    "image_list = [os.path.join(image_path,name) for name in names]\n",
    "\n",
    "def create_img_dataset(image_list) :\n",
    "    imgs = []\n",
    "    for image in tqdm(image_list) :\n",
    "        img = cv2.imread(image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, dsize=(256,256))\n",
    "        imgs.append(img)\n",
    "        \n",
    "    return np.array(imgs)\n",
    "\n",
    "image_dataset = create_img_dataset(image_list)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45143838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image dataset : (10000, 256, 256, 3)\n",
      "label dataset : (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "print('image dataset :',image_dataset.shape)\n",
    "print('label dataset :',labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b23b33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc27cd",
   "metadata": {},
   "source": [
    "### Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c43061f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_12  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 297,414\n",
      "Trainable params: 297,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers, activations\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(64, 3, padding='same', input_shape=(256,256,3)))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(64, 3, padding='same'))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602eb396",
   "metadata": {},
   "source": [
    "### define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19b4f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =[\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef1a24",
   "metadata": {},
   "source": [
    "### define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33ca6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('./ckpt_test/cp.ckpt',\n",
    "                                      save_weights_only=True,\n",
    "                                      save_freq='epoch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        patience=3,\n",
    "                                        factor=0.01,\n",
    "                                        min_lr=1e-13)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7598a",
   "metadata": {},
   "source": [
    "### model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5edd61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2ae4417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch : 0\n",
      "\n",
      "\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 1.3684 - accuracy: 0.7188 - precision: 0.3125 - recall: 0.2381 - AUC: 0.7057 - val_loss: 1.1500 - val_accuracy: 0.7500 - val_precision: 0.5000 - val_recall: 0.6667 - val_AUC: 0.7245\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 0 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.0290 - accuracy: 0.7500 - precision: 0.5000 - recall: 0.6667 - AUC: 0.7454 - val_loss: 0.9736 - val_accuracy: 0.7917 - val_precision: 0.6250 - val_recall: 0.4167 - val_AUC: 0.8403\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 1 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.9380 - accuracy: 0.8021 - precision: 0.5625 - recall: 0.4286 - AUC: 0.8295 - val_loss: 1.2463 - val_accuracy: 0.7292 - val_precision: 0.4375 - val_recall: 0.6364 - val_AUC: 0.7408\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 2 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.4586 - accuracy: 0.6771 - precision: 0.4062 - recall: 0.5200 - AUC: 0.6961 - val_loss: 0.7571 - val_accuracy: 0.7083 - val_precision: 0.3750 - val_recall: 0.6000 - val_AUC: 0.7987\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 3 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.8006 - accuracy: 0.7917 - precision: 0.6452 - recall: 0.6897 - AUC: 0.7470 - val_loss: 0.5864 - val_accuracy: 0.7083 - val_precision: 0.2500 - val_recall: 0.2000 - val_AUC: 0.5921\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 4 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.5466 - accuracy: 0.7188 - precision: 0.3750 - recall: 0.2609 - AUC: 0.6724 - val_loss: 0.7579 - val_accuracy: 0.6042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.4857\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 5 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6214 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - AUC: 0.6351 - val_loss: 0.4413 - val_accuracy: 0.7917 - val_precision: 0.5000 - val_recall: 0.4000 - val_AUC: 0.7461\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 6 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.4320 - accuracy: 0.8229 - precision: 0.6250 - recall: 0.4762 - AUC: 0.7467 - val_loss: 0.4711 - val_accuracy: 0.8333 - val_precision: 0.6250 - val_recall: 0.5000 - val_AUC: 0.7908\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 7 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.4988 - accuracy: 0.7812 - precision: 0.6500 - recall: 0.4815 - AUC: 0.7751 - val_loss: 0.7165 - val_accuracy: 0.7292 - val_precision: 0.5000 - val_recall: 0.6154 - val_AUC: 0.7396\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 8 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.3777 - accuracy: 0.8438 - precision: 0.5172 - recall: 0.9375 - AUC: 0.9055 - val_loss: 0.5177 - val_accuracy: 0.7708 - val_precision: 0.5714 - val_recall: 0.6154 - val_AUC: 0.8077\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 9 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.6051 - accuracy: 0.7396 - precision: 0.5556 - recall: 0.5357 - AUC: 0.7663 - val_loss: 0.3571 - val_accuracy: 0.8750 - val_precision: 0.7500 - val_recall: 0.6000 - val_AUC: 0.8816\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 10 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.4475 - accuracy: 0.8125 - precision: 0.6250 - recall: 0.4545 - AUC: 0.7838 - val_loss: 0.4311 - val_accuracy: 0.7500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.7580\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'lr'])\n",
      "Batch : 11 Acc : [0.8066164255142212, 0.8363832831382751, 0.8460333943367004] Loss : [0.4388664662837982, 0.3756559491157532, 0.35753577947616577] Precision : [0.6447128653526306, 0.7132712006568909, 0.7302035093307495] Recall: [0.4599234163761139, 0.5495144128799438, 0.5839830636978149] AUC : [0.8282502293586731, 0.8660832643508911, 0.8795175552368164]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-13a2b7b987d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     for (batch_img, batch_label), (val_img, val_label) in zip(datagen.flow(image_dataset, labels, batch_size=16, subset='training'),\n\u001b[0;32m     13\u001b[0m                datagen.flow(image_dataset, labels, batch_size=8, subset='validation')):\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mhistoty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "STEPS_PER_EPOCH=len(image_dataset)/16\n",
    "\n",
    "for epoch in range(EPOCHS) :\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Epoch :\",e)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    batch = 0\n",
    "    for (batch_img, batch_label), (val_img, val_label) in zip(datagen.flow(image_dataset, labels, batch_size=16, subset='training'),\n",
    "               datagen.flow(image_dataset, labels, batch_size=8, subset='validation')):\n",
    "            histoty = model.fit(batch_img, batch_label, validation_data=(val_img, val_label), verbose=1)\n",
    "            print(history.history.keys())\n",
    "            acc = history.history['accuracy']\n",
    "            loss = history.history['loss']\n",
    "#             val_acc = history.history['val_acc']\n",
    "#             val_loss = history.history['val_loss']\n",
    "            precision = history.history['precision']\n",
    "#             val_precision = history.history['val_precision']\n",
    "            recall = history.history['recall']\n",
    "#             val_recall = history.history['val_recall']\n",
    "            AUC = history.history['AUC']\n",
    "#             val_AUC = history.history['val_AUC']\n",
    "            print(\"Batch : {} Acc : {} Loss : {} Precision : {} Recall: {} AUC : {}\".format(batch ,acc, loss, precision, recall, AUC))\n",
    "            batch += 1\n",
    "            \n",
    "            if batch >= STEPS_PER_EPOCH :\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08047846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6bfc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 297,674\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers, activations\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(layers.Conv2D(64, 3, padding='same', input_shape=(256,256,3)))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "model2.add(layers.MaxPool2D())\n",
    "\n",
    "model2.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "model2.add(layers.MaxPool2D())\n",
    "\n",
    "model2.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "model2.add(layers.MaxPool2D())\n",
    "\n",
    "model2.add(layers.Conv2D(64, 3, padding='same'))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "model2.add(layers.GlobalAveragePooling2D())\n",
    "model2.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "model2.summary()\n",
    "metrics =[\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC')\n",
    "]\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('./ckpt_test/cp.ckpt',\n",
    "                                      save_weights_only=True,\n",
    "                                      save_freq='epoch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        patience=3,\n",
    "                                        factor=0.01,\n",
    "                                        min_lr=1e-13)\n",
    "]\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc4342e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs :  0\n",
      "0\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9181WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"conv2d_47_input:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1765 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9181 - val_loss: 0.1600 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9661\n",
      "1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1478 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9547 - val_loss: 0.1556 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9575\n",
      "2\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1974 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9091 - val_loss: 0.1820 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9201\n",
      "3\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1827 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9107 - val_loss: 0.1438 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9688\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2037 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9003 - val_loss: 0.2479 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8490\n",
      "5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1723 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9344 - val_loss: 0.1757 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9280\n",
      "6\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2036 - accuracy: 0.9125 - precision: 0.6111 - recall: 0.3438 - AUC: 0.9003 - val_loss: 0.1995 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8993\n",
      "7\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1913 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9089 - val_loss: 0.1644 - val_accuracy: 0.9125 - val_precision: 0.5556 - val_recall: 0.6250 - val_AUC: 0.9557\n",
      "8\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2098 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8821 - val_loss: 0.1899 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9028\n",
      "9\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1805 - accuracy: 0.9469 - precision: 0.9412 - recall: 0.5000 - AUC: 0.9187 - val_loss: 0.1186 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9722\n",
      "10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1701 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9287 - val_loss: 0.2035 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.9123\n",
      "11\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1929 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9087 - val_loss: 0.1381 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9635\n",
      "12\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1662 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9340 - val_loss: 0.1642 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9523\n",
      "13\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1376 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9635 - val_loss: 0.1279 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9627\n",
      "14\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1814 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9183 - val_loss: 0.2469 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8446\n",
      "15\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1797 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9271 - val_loss: 0.1792 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9253\n",
      "16\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1764 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9301 - val_loss: 0.3147 - val_accuracy: 0.8500 - val_precision: 0.1667 - val_recall: 0.1250 - val_AUC: 0.8082\n",
      "17\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1954 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9087 - val_loss: 0.1651 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9418\n",
      "18\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1638 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9343 - val_loss: 0.1796 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9089\n",
      "19\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1743 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9325 - val_loss: 0.1860 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9401\n",
      "20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1769 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9287 - val_loss: 0.2753 - val_accuracy: 0.8500 - val_precision: 0.2500 - val_recall: 0.2500 - val_AUC: 0.8516\n",
      "21\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1961 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9154 - val_loss: 0.3191 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8108\n",
      "22\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1542 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9412 - val_loss: 0.1272 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9818\n",
      "23\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2126 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.8965 - val_loss: 0.2185 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8628\n",
      "24\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1961 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.8967 - val_loss: 0.1422 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9670\n",
      "25\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1994 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.8889 - val_loss: 0.1877 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9227\n",
      "26\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1893 - accuracy: 0.9219 - precision: 0.6522 - recall: 0.4688 - AUC: 0.9186 - val_loss: 0.0947 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9931\n",
      "27\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1279 - accuracy: 0.9531 - precision: 0.8696 - recall: 0.6250 - AUC: 0.9660 - val_loss: 0.2330 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8750\n",
      "28\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2151 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8903 - val_loss: 0.1843 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9271\n",
      "29\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2366 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8742 - val_loss: 0.2440 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8498\n",
      "30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1848 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9261 - val_loss: 0.1762 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9306\n",
      "31\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2081 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9047 - val_loss: 0.1121 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1765 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9262 - val_loss: 0.2286 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8741\n",
      "33\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1818 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.9352 - val_loss: 0.1978 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8845\n",
      "34\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2001 - accuracy: 0.9187 - precision: 0.7500 - recall: 0.2812 - AUC: 0.9026 - val_loss: 0.2750 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8099\n",
      "35\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1616 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9454 - val_loss: 0.1510 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9540\n",
      "36\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2157 - accuracy: 0.9062 - precision: 0.6000 - recall: 0.1875 - AUC: 0.9028 - val_loss: 0.2382 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8438\n",
      "37\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1471 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9634 - val_loss: 0.2360 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8915\n",
      "38\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1483 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9657 - val_loss: 0.2505 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8351\n",
      "39\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1883 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9112 - val_loss: 0.2186 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8403\n",
      "40\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1432 - accuracy: 0.9531 - precision: 0.9474 - recall: 0.5625 - AUC: 0.9551 - val_loss: 0.1397 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9627\n",
      "41\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1333 - accuracy: 0.9563 - precision: 0.9500 - recall: 0.5938 - AUC: 0.9590 - val_loss: 0.1747 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.9323\n",
      "42\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1566 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9469 - val_loss: 0.1735 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9314\n",
      "43\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1866 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9255 - val_loss: 0.2175 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9097\n",
      "44\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1790 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9259 - val_loss: 0.1172 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9826\n",
      "45\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1737 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9360 - val_loss: 0.2164 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9271\n",
      "46\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2153 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9085 - val_loss: 0.1834 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8872\n",
      "47\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1961 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9043 - val_loss: 0.1701 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9323\n",
      "48\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1445 - accuracy: 0.9344 - precision: 0.7037 - recall: 0.5938 - AUC: 0.9600 - val_loss: 0.1399 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9705\n",
      "49\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1807 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9236 - val_loss: 0.0878 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1400 - accuracy: 0.9562 - precision: 0.8750 - recall: 0.6562 - AUC: 0.9510 - val_loss: 0.1660 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9557\n",
      "51\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1779 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9222 - val_loss: 0.1110 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9818\n",
      "52\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1759 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9237 - val_loss: 0.2150 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9193\n",
      "53\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1874 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9123 - val_loss: 0.1799 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9280\n",
      "54\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1703 - accuracy: 0.9312 - precision: 0.9167 - recall: 0.3438 - AUC: 0.9376 - val_loss: 0.1456 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9609\n",
      "55\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1629 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9393 - val_loss: 0.2860 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8038\n",
      "56\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2042 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.8922 - val_loss: 0.2231 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.8602\n",
      "57\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2481 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8271 - val_loss: 0.2139 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8906\n",
      "58\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1813 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9226 - val_loss: 0.1398 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9731\n",
      "59\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1475 - accuracy: 0.9594 - precision: 0.8800 - recall: 0.6875 - AUC: 0.9454 - val_loss: 0.1539 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9618\n",
      "60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1352 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9677 - val_loss: 0.1805 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9054\n",
      "61\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1770 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9360 - val_loss: 0.2138 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8672\n",
      "62\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1755 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9449 - val_loss: 0.2365 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8837\n",
      "63\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1350 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.5312 - AUC: 0.9607 - val_loss: 0.1228 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9748\n",
      "64\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1628 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9530 - val_loss: 0.1462 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9688\n",
      "65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1611 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9398 - val_loss: 0.1266 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9618\n",
      "66\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1856 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9230 - val_loss: 0.2182 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8793\n",
      "67\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2204 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.8770 - val_loss: 0.1427 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9462\n",
      "68\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1488 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9619 - val_loss: 0.1320 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9618\n",
      "69\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1772 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9267 - val_loss: 0.2330 - val_accuracy: 0.8625 - val_precision: 0.2000 - val_recall: 0.1250 - val_AUC: 0.9002\n",
      "70\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1610 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9441 - val_loss: 0.1668 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9410\n",
      "71\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1937 - accuracy: 0.9156 - precision: 0.6190 - recall: 0.4062 - AUC: 0.9226 - val_loss: 0.1501 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9644\n",
      "72\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2089 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8867 - val_loss: 0.2419 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9097\n",
      "73\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1922 - accuracy: 0.9094 - precision: 0.5652 - recall: 0.4062 - AUC: 0.9172 - val_loss: 0.0777 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9965\n",
      "74\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2211 - accuracy: 0.9000 - precision: 0.5000 - recall: 0.2188 - AUC: 0.8951 - val_loss: 0.1610 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9332\n",
      "75\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1602 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9472 - val_loss: 0.2205 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8802\n",
      "76\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2423 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.8472 - val_loss: 0.1385 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9670\n",
      "77\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1930 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9220 - val_loss: 0.1726 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.9410\n",
      "78\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2276 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.8801 - val_loss: 0.2089 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "79\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1669 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9408 - val_loss: 0.1065 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9896\n",
      "80\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2239 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.8932 - val_loss: 0.2167 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8681\n",
      "81\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1667 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9449 - val_loss: 0.1383 - val_accuracy: 0.9250 - val_precision: 0.6000 - val_recall: 0.7500 - val_AUC: 0.9722\n",
      "82\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1537 - accuracy: 0.9438 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9514 - val_loss: 0.2373 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8359\n",
      "83\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2022 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.8923 - val_loss: 0.1581 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9427\n",
      "84\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2114 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.8907 - val_loss: 0.1616 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9557\n",
      "85\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1897 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9093 - val_loss: 0.1646 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9158\n",
      "86\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1943 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9125 - val_loss: 0.1395 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9479\n",
      "87\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1892 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9149 - val_loss: 0.1460 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9549\n",
      "88\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1732 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9337 - val_loss: 0.1637 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9323\n",
      "89\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1730 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9351 - val_loss: 0.2187 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "90\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1984 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9141 - val_loss: 0.2019 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.8976\n",
      "91\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1734 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9392 - val_loss: 0.2122 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8993\n",
      "92\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1939 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.9120 - val_loss: 0.2152 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8724\n",
      "93\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1846 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9200 - val_loss: 0.1660 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9844\n",
      "94\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1541 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9600 - val_loss: 0.2158 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8924\n",
      "95\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1369 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9721 - val_loss: 0.1699 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9531\n",
      "96\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2118 - accuracy: 0.9156 - precision: 0.7273 - recall: 0.2500 - AUC: 0.8961 - val_loss: 0.2580 - val_accuracy: 0.8875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8455\n",
      "97\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2716 - accuracy: 0.9062 - precision: 0.5556 - recall: 0.3125 - AUC: 0.8285 - val_loss: 0.2075 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.9062\n",
      "98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1379 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9652 - val_loss: 0.1784 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9297\n",
      "99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2667 - accuracy: 0.9062 - precision: 0.5714 - recall: 0.2500 - AUC: 0.8370 - val_loss: 0.2260 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8681\n",
      "100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1854 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9193 - val_loss: 0.1770 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.9418\n",
      "101\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1822 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9121 - val_loss: 0.2420 - val_accuracy: 0.9000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8689\n",
      "102\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2269 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.8661 - val_loss: 0.1470 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9332\n",
      "103\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2254 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8740 - val_loss: 0.0982 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9792\n",
      "104\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2611 - accuracy: 0.8937 - precision: 0.4375 - recall: 0.2188 - AUC: 0.8669 - val_loss: 0.2251 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8976\n",
      "105\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1452 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9559 - val_loss: 0.2385 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8715\n",
      "106\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1679 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9427 - val_loss: 0.3031 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8064\n",
      "107\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1803 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9364 - val_loss: 0.1368 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9826\n",
      "108\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1944 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.9166 - val_loss: 0.1182 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9722\n",
      "109\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1716 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9335 - val_loss: 0.2122 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.9253\n",
      "110\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2101 - accuracy: 0.9156 - precision: 0.6667 - recall: 0.3125 - AUC: 0.9021 - val_loss: 0.2266 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8585\n",
      "111\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1462 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9561 - val_loss: 0.1428 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9618\n",
      "112\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1847 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9241 - val_loss: 0.1319 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9653\n",
      "113\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2050 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9045 - val_loss: 0.1666 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9002\n",
      "114\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2700 - accuracy: 0.8969 - precision: 0.4737 - recall: 0.2812 - AUC: 0.8448 - val_loss: 0.1869 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9097\n",
      "115\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1718 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9389 - val_loss: 0.1436 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9505\n",
      "116\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2321 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.8644 - val_loss: 0.2329 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "117\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2060 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.9039 - val_loss: 0.2162 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8672\n",
      "118\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2087 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.8945 - val_loss: 0.1928 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9349\n",
      "119\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2132 - accuracy: 0.9094 - precision: 0.5714 - recall: 0.3750 - AUC: 0.9012 - val_loss: 0.1303 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9627\n",
      "120\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2075 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9073 - val_loss: 0.1653 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9549\n",
      "121\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1819 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9212 - val_loss: 0.1628 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9635\n",
      "122\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2016 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.9037 - val_loss: 0.1804 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9054\n",
      "123\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2385 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.8573 - val_loss: 0.1567 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9549\n",
      "124\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1383 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9710 - val_loss: 0.1945 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9132\n",
      "125\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1690 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9430 - val_loss: 0.2248 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8576\n",
      "126\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1844 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9314 - val_loss: 0.2606 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8099\n",
      "127\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1532 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9511 - val_loss: 0.1868 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8915\n",
      "128\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1846 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9195 - val_loss: 0.2198 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8733\n",
      "129\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1824 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9278 - val_loss: 0.1503 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9384\n",
      "130\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2467 - accuracy: 0.8969 - precision: 0.4737 - recall: 0.2812 - AUC: 0.8494 - val_loss: 0.0926 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9896\n",
      "131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2340 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.8617 - val_loss: 0.1781 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9323\n",
      "132\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1947 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9210 - val_loss: 0.2266 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8993\n",
      "133\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1933 - accuracy: 0.9469 - precision: 1.0000 - recall: 0.4688 - AUC: 0.8885 - val_loss: 0.1782 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9323\n",
      "134\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1809 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9373 - val_loss: 0.1500 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9427\n",
      "135\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1796 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9191 - val_loss: 0.1114 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9792\n",
      "136\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2004 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.8927 - val_loss: 0.2050 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8941\n",
      "137\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1636 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9470 - val_loss: 0.1575 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9531\n",
      "138\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1820 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9167 - val_loss: 0.1445 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "139\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1828 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9296 - val_loss: 0.1532 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9592\n",
      "140\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2191 - accuracy: 0.9156 - precision: 0.6923 - recall: 0.2812 - AUC: 0.8775 - val_loss: 0.1582 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9661\n",
      "141\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1748 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9326 - val_loss: 0.2071 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8915\n",
      "142\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1970 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.8951 - val_loss: 0.2845 - val_accuracy: 0.8500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8351\n",
      "143\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1949 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9095 - val_loss: 0.3515 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.7214\n",
      "144\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1591 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9487 - val_loss: 0.2009 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9436\n",
      "145\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1703 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9454 - val_loss: 0.1906 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9045\n",
      "146\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1791 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9343 - val_loss: 0.2183 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9010\n",
      "147\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1416 - accuracy: 0.9500 - precision: 0.9000 - recall: 0.5625 - AUC: 0.9622 - val_loss: 0.1574 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9349\n",
      "148\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1562 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9538 - val_loss: 0.1048 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9983\n",
      "149\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2257 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8837 - val_loss: 0.1970 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9054\n",
      "150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1884 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9070 - val_loss: 0.2104 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8984\n",
      "151\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1860 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9145 - val_loss: 0.1329 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9661\n",
      "152\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1870 - accuracy: 0.9250 - precision: 0.6667 - recall: 0.5000 - AUC: 0.9280 - val_loss: 0.1632 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9245\n",
      "153\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1316 - accuracy: 0.9531 - precision: 0.8696 - recall: 0.6250 - AUC: 0.9657 - val_loss: 0.2495 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "154\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1932 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9060 - val_loss: 0.1832 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9158\n",
      "155\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1321 - accuracy: 0.9437 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9664 - val_loss: 0.1252 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9705\n",
      "156\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1859 - accuracy: 0.9281 - precision: 0.6800 - recall: 0.5312 - AUC: 0.9169 - val_loss: 0.2182 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8845\n",
      "157\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1700 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9397 - val_loss: 0.2053 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9045\n",
      "158\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2037 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.8989 - val_loss: 0.1281 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9661\n",
      "159\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2093 - accuracy: 0.9219 - precision: 0.6522 - recall: 0.4688 - AUC: 0.8886 - val_loss: 0.1986 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9201\n",
      "160\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2196 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8874 - val_loss: 0.2110 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8681\n",
      "161\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1917 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9034 - val_loss: 0.2320 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8663\n",
      "162\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1952 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9046 - val_loss: 0.1245 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "163\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1386 - accuracy: 0.9438 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9614 - val_loss: 0.1513 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9618\n",
      "164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1858 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9153 - val_loss: 0.1577 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9479\n",
      "165\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1361 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9712 - val_loss: 0.1653 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9497\n",
      "166\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1429 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9618 - val_loss: 0.2085 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.1250 - val_AUC: 0.9045\n",
      "167\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1483 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9525 - val_loss: 0.1223 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9635\n",
      "168\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1688 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9284 - val_loss: 0.1739 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9401\n",
      "169\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1986 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.8964 - val_loss: 0.1725 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9410\n",
      "170\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1856 - accuracy: 0.9250 - precision: 0.6667 - recall: 0.5000 - AUC: 0.9131 - val_loss: 0.1703 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9210\n",
      "171\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1733 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9339 - val_loss: 0.2859 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8116\n",
      "172\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1858 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9131 - val_loss: 0.2707 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8438\n",
      "173\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2203 - accuracy: 0.8969 - precision: 0.4706 - recall: 0.2500 - AUC: 0.8812 - val_loss: 0.1483 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9583\n",
      "174\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1829 - accuracy: 0.9438 - precision: 0.9375 - recall: 0.4688 - AUC: 0.9163 - val_loss: 0.2094 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9271\n",
      "175\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1782 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9313 - val_loss: 0.2681 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8542\n",
      "176\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1964 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.9130 - val_loss: 0.2020 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9201\n",
      "177\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1857 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9156 - val_loss: 0.1188 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9688\n",
      "178\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1642 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9434 - val_loss: 0.1964 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9132\n",
      "179\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1652 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9327 - val_loss: 0.1274 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9774\n",
      "180\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1738 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9335 - val_loss: 0.2692 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8655\n",
      "181\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1532 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9512 - val_loss: 0.1819 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9349\n",
      "182\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1809 - accuracy: 0.9438 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9199 - val_loss: 0.2273 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8976\n",
      "183\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1483 - accuracy: 0.9313 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9557 - val_loss: 0.2326 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8628\n",
      "184\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2040 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9007 - val_loss: 0.1508 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9583\n",
      "185\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1931 - accuracy: 0.9219 - precision: 0.6296 - recall: 0.5312 - AUC: 0.9225 - val_loss: 0.2772 - val_accuracy: 0.8625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8672\n",
      "186\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2000 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.8959 - val_loss: 0.0874 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9939\n",
      "187\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1505 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9565 - val_loss: 0.2419 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8542\n",
      "188\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1617 - accuracy: 0.9344 - precision: 0.7037 - recall: 0.5938 - AUC: 0.9438 - val_loss: 0.1565 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9392\n",
      "189\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1719 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9294 - val_loss: 0.1905 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8898\n",
      "190\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1750 - accuracy: 0.9375 - precision: 0.7308 - recall: 0.5938 - AUC: 0.9148 - val_loss: 0.1989 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9062\n",
      "191\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2367 - accuracy: 0.9000 - precision: 0.5000 - recall: 0.3125 - AUC: 0.8863 - val_loss: 0.2212 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9028\n",
      "192\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1771 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9251 - val_loss: 0.1853 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9158\n",
      "193\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1771 - accuracy: 0.9344 - precision: 0.7200 - recall: 0.5625 - AUC: 0.9418 - val_loss: 0.1826 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9340\n",
      "194\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - accuracy: 0.9062 - precision: 0.5556 - recall: 0.3125 - AUC: 0.9091 - val_loss: 0.0992 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9852\n",
      "195\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1759 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9292 - val_loss: 0.2402 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.9097\n",
      "196\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1864 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9300 - val_loss: 0.1547 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9592\n",
      "197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1098 - accuracy: 0.9625 - precision: 0.9545 - recall: 0.6562 - AUC: 0.9808 - val_loss: 0.1733 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9349\n",
      "198\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1881 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9200 - val_loss: 0.3255 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.7144\n",
      "199\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2148 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.8883 - val_loss: 0.1685 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9549\n",
      "200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1748 - accuracy: 0.9312 - precision: 0.8571 - recall: 0.3750 - AUC: 0.9357 - val_loss: 0.1118 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9905\n",
      "201\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1548 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9435 - val_loss: 0.2389 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8785\n",
      "202\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1740 - accuracy: 0.9438 - precision: 1.0000 - recall: 0.4375 - AUC: 0.9244 - val_loss: 0.1408 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9592\n",
      "203\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1849 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9283 - val_loss: 0.1495 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9661\n",
      "204\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2521 - accuracy: 0.8750 - precision: 0.2500 - recall: 0.1250 - AUC: 0.8706 - val_loss: 0.1282 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9627\n",
      "205\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1563 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.9563 - val_loss: 0.1758 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9418\n",
      "206\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1729 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9323 - val_loss: 0.3381 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.7873\n",
      "207\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2057 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.8916 - val_loss: 0.2114 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9062\n",
      "208\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1623 - accuracy: 0.9281 - precision: 0.6800 - recall: 0.5312 - AUC: 0.9506 - val_loss: 0.2218 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8837\n",
      "209\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1735 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9422 - val_loss: 0.2179 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8828\n",
      "210\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1946 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9092 - val_loss: 0.2440 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8507\n",
      "211\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1773 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9298 - val_loss: 0.0914 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 0.9931\n",
      "212\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1661 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9376 - val_loss: 0.2359 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8733\n",
      "213\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1575 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9321 - val_loss: 0.1570 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "214\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2228 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8833 - val_loss: 0.0729 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 0.9983\n",
      "215\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1850 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9287 - val_loss: 0.2581 - val_accuracy: 0.8875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8863\n",
      "216\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2135 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9072 - val_loss: 0.1656 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9462\n",
      "217\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2106 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.8818 - val_loss: 0.1887 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9132\n",
      "218\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2130 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.8963 - val_loss: 0.2464 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8446\n",
      "219\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1822 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9194 - val_loss: 0.2476 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8776\n",
      "220\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1660 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9357 - val_loss: 0.1782 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9358\n",
      "221\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1814 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9271 - val_loss: 0.1624 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9401\n",
      "222\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1582 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9444 - val_loss: 0.1058 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "223\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1400 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9666 - val_loss: 0.2311 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8976\n",
      "224\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1993 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9012 - val_loss: 0.1956 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9089\n",
      "225\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1417 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9427 - val_loss: 0.1170 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9809\n",
      "226\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2367 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.8585 - val_loss: 0.2068 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9115\n",
      "227\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1539 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9429 - val_loss: 0.2377 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8576\n",
      "228\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2009 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.9055 - val_loss: 0.1244 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9870\n",
      "229\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2013 - accuracy: 0.9125 - precision: 0.6250 - recall: 0.3125 - AUC: 0.9085 - val_loss: 0.2084 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8898\n",
      "230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1990 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9071 - val_loss: 0.1271 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9792\n",
      "231\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1755 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9147 - val_loss: 0.2392 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.1250 - val_AUC: 0.8455\n",
      "232\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2064 - accuracy: 0.9094 - precision: 0.5882 - recall: 0.3125 - AUC: 0.8898 - val_loss: 0.2046 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8950\n",
      "233\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1977 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9064 - val_loss: 0.1090 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "234\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1801 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9184 - val_loss: 0.1035 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9748\n",
      "235\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1740 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9376 - val_loss: 0.2930 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.8507\n",
      "236\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1655 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9369 - val_loss: 0.1662 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9462\n",
      "237\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1547 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.5312 - AUC: 0.9495 - val_loss: 0.1859 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9453\n",
      "238\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2165 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8815 - val_loss: 0.2139 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8984\n",
      "239\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1704 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9376 - val_loss: 0.2459 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8481\n",
      "240\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1768 - accuracy: 0.9187 - precision: 0.8000 - recall: 0.2500 - AUC: 0.9321 - val_loss: 0.2477 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8724\n",
      "241\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1544 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9588 - val_loss: 0.1546 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9332\n",
      "242\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1799 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9173 - val_loss: 0.1371 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9757\n",
      "243\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1660 - accuracy: 0.9438 - precision: 1.0000 - recall: 0.4375 - AUC: 0.9292 - val_loss: 0.1267 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9774\n",
      "244\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1859 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9245 - val_loss: 0.1610 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9601\n",
      "245\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1615 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9507 - val_loss: 0.1741 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9245\n",
      "246\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2213 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.8812 - val_loss: 0.1344 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9731\n",
      "247\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2155 - accuracy: 0.9219 - precision: 0.8182 - recall: 0.2812 - AUC: 0.8834 - val_loss: 0.1329 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9774\n",
      "248\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1896 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9197 - val_loss: 0.1478 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9592\n",
      "249\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1680 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9358 - val_loss: 0.1888 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8811\n",
      "250\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1775 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9314 - val_loss: 0.1054 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9913\n",
      "251\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1635 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9463 - val_loss: 0.1453 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9583\n",
      "252\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1836 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9334 - val_loss: 0.1690 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9314\n",
      "253\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2097 - accuracy: 0.9156 - precision: 0.6667 - recall: 0.3125 - AUC: 0.8904 - val_loss: 0.2557 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8403\n",
      "254\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2137 - accuracy: 0.9094 - precision: 0.5714 - recall: 0.3750 - AUC: 0.8889 - val_loss: 0.1830 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9314\n",
      "255\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1829 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9236 - val_loss: 0.1165 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9679\n",
      "256\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2066 - accuracy: 0.9156 - precision: 0.6087 - recall: 0.4375 - AUC: 0.9002 - val_loss: 0.1407 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9653\n",
      "257\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1637 - accuracy: 0.9344 - precision: 0.7200 - recall: 0.5625 - AUC: 0.9445 - val_loss: 0.1987 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8967\n",
      "258\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1841 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9289 - val_loss: 0.1253 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "259\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2309 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.8696 - val_loss: 0.1994 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "260\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1960 - accuracy: 0.9156 - precision: 0.6667 - recall: 0.3125 - AUC: 0.9198 - val_loss: 0.1954 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9141\n",
      "261\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2131 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.8849 - val_loss: 0.2890 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.7856\n",
      "262\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1342 - accuracy: 0.9500 - precision: 0.9000 - recall: 0.5625 - AUC: 0.9701 - val_loss: 0.1778 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9444\n",
      "263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1803 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9121 - val_loss: 0.2663 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8715\n",
      "264\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1928 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9138 - val_loss: 0.2215 - val_accuracy: 0.8875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.9045\n",
      "265\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1772 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9336 - val_loss: 0.2092 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.8646\n",
      "266\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1627 - accuracy: 0.9437 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9393 - val_loss: 0.1430 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "267\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1532 - accuracy: 0.9531 - precision: 0.9474 - recall: 0.5625 - AUC: 0.9398 - val_loss: 0.2332 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8863\n",
      "268\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1592 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9527 - val_loss: 0.1178 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9731\n",
      "269\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1882 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9164 - val_loss: 0.1877 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9071\n",
      "270\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1839 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9220 - val_loss: 0.1615 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9453\n",
      "271\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1782 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9342 - val_loss: 0.3152 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.7726\n",
      "272\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1978 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9058 - val_loss: 0.2297 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8620\n",
      "273\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1210 - accuracy: 0.9625 - precision: 0.9545 - recall: 0.6562 - AUC: 0.9681 - val_loss: 0.2212 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8724\n",
      "274\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2196 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8974 - val_loss: 0.1343 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9722\n",
      "275\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1421 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9626 - val_loss: 0.2091 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9028\n",
      "276\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1252 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9720 - val_loss: 0.1553 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9566\n",
      "277\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1775 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9167 - val_loss: 0.1725 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.8793\n",
      "278\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1759 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9368 - val_loss: 0.1661 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9505\n",
      "279\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1857 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9180 - val_loss: 0.2092 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8950\n",
      "280\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1786 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9317 - val_loss: 0.1916 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8854\n",
      "281\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1564 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9511 - val_loss: 0.2045 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "282\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2006 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.9140 - val_loss: 0.1466 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9679\n",
      "283\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2285 - accuracy: 0.9125 - precision: 0.6429 - recall: 0.2812 - AUC: 0.8729 - val_loss: 0.2921 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.7387\n",
      "284\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2008 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.9083 - val_loss: 0.1544 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9549\n",
      "285\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2078 - accuracy: 0.9219 - precision: 0.7692 - recall: 0.3125 - AUC: 0.8914 - val_loss: 0.1125 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9688\n",
      "286\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2065 - accuracy: 0.9094 - precision: 0.5882 - recall: 0.3125 - AUC: 0.9028 - val_loss: 0.1483 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9714\n",
      "287\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1470 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9530 - val_loss: 0.2520 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.7925\n",
      "288\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1916 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9013 - val_loss: 0.2525 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8377\n",
      "289\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2397 - accuracy: 0.9219 - precision: 0.7692 - recall: 0.3125 - AUC: 0.8574 - val_loss: 0.3122 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.7292\n",
      "290\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1963 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9115 - val_loss: 0.2295 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8446\n",
      "291\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.889 - 0s 71ms/step - loss: 0.2225 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8892 - val_loss: 0.1714 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9219\n",
      "292\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1657 - accuracy: 0.9438 - precision: 0.9375 - recall: 0.4688 - AUC: 0.9372 - val_loss: 0.1748 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9019\n",
      "293\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1740 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9296 - val_loss: 0.2078 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9245\n",
      "294\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1733 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9438 - val_loss: 0.2038 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9149\n",
      "295\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1645 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9243 - val_loss: 0.1589 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1461 - accuracy: 0.9437 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9608 - val_loss: 0.2722 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.7726\n",
      "297\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1960 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9189 - val_loss: 0.2471 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "298\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1651 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9248 - val_loss: 0.0988 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "299\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1723 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.5312 - AUC: 0.9222 - val_loss: 0.1094 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9835\n",
      "300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1714 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9353 - val_loss: 0.2029 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9089\n",
      "301\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1517 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9563 - val_loss: 0.1140 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9896\n",
      "302\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1754 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9181 - val_loss: 0.3416 - val_accuracy: 0.8625 - val_precision: 0.2000 - val_recall: 0.1250 - val_AUC: 0.7717\n",
      "303\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2091 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.8930 - val_loss: 0.2421 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8498\n",
      "304\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2183 - accuracy: 0.9125 - precision: 0.6250 - recall: 0.3125 - AUC: 0.8879 - val_loss: 0.2012 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9089\n",
      "305\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1760 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.4062 - AUC: 0.9224 - val_loss: 0.2070 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9392\n",
      "306\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2046 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9085 - val_loss: 0.2341 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8793\n",
      "307\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2020 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.9060 - val_loss: 0.1330 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9696\n",
      "308\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1447 - accuracy: 0.9531 - precision: 0.8400 - recall: 0.6562 - AUC: 0.9409 - val_loss: 0.2268 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8767\n",
      "309\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1780 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9213 - val_loss: 0.1534 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9497\n",
      "310\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1891 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.9063 - val_loss: 0.1733 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9505\n",
      "311\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2089 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.8977 - val_loss: 0.2235 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8802\n",
      "312\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1665 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9321 - val_loss: 0.1242 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9740\n",
      "313\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1579 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9520 - val_loss: 0.1896 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9340\n",
      "314\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2098 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9013 - val_loss: 0.1795 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9384\n",
      "315\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1413 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9604 - val_loss: 0.1574 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9523\n",
      "316\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2108 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.8915 - val_loss: 0.0630 - val_accuracy: 0.9750 - val_precision: 0.8750 - val_recall: 0.8750 - val_AUC: 0.9948\n",
      "317\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1891 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9313 - val_loss: 0.1635 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9488\n",
      "318\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1675 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9387 - val_loss: 0.1191 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9826\n",
      "319\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1714 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9243 - val_loss: 0.1570 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9635\n",
      "320\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1573 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9444 - val_loss: 0.1308 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9688\n",
      "321\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1428 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9588 - val_loss: 0.1364 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9740\n",
      "322\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1924 - accuracy: 0.9344 - precision: 0.7200 - recall: 0.5625 - AUC: 0.8955 - val_loss: 0.3133 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8108\n",
      "323\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1981 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9200 - val_loss: 0.3214 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.7483\n",
      "324\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1689 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9325 - val_loss: 0.2299 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8342\n",
      "325\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1992 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9202 - val_loss: 0.1558 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9479\n",
      "326\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2174 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.8926 - val_loss: 0.1917 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9201\n",
      "327\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2388 - accuracy: 0.9031 - precision: 0.5238 - recall: 0.3438 - AUC: 0.8855 - val_loss: 0.3078 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8038\n",
      "328\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2026 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9068 - val_loss: 0.1313 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9531\n",
      "329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1750 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9213 - val_loss: 0.1499 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9705\n",
      "330\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1977 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9061 - val_loss: 0.2548 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8142\n",
      "331\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1640 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9412 - val_loss: 0.2614 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8299\n",
      "332\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1889 - accuracy: 0.9250 - precision: 0.6667 - recall: 0.5000 - AUC: 0.9222 - val_loss: 0.2076 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9062\n",
      "333\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1964 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9025 - val_loss: 0.2758 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.8351\n",
      "334\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1904 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9236 - val_loss: 0.1156 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "335\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2068 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8902 - val_loss: 0.2010 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9158\n",
      "336\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1460 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9671 - val_loss: 0.1367 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9835\n",
      "337\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2429 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.8465 - val_loss: 0.1458 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9653\n",
      "338\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1989 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9049 - val_loss: 0.1063 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9731\n",
      "339\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1884 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9212 - val_loss: 0.2035 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "340\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2363 - accuracy: 0.9031 - precision: 0.5455 - recall: 0.1875 - AUC: 0.8625 - val_loss: 0.1658 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9505\n",
      "341\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2367 - accuracy: 0.9125 - precision: 0.6429 - recall: 0.2812 - AUC: 0.8644 - val_loss: 0.3202 - val_accuracy: 0.8750 - val_precision: 0.3750 - val_recall: 0.3750 - val_AUC: 0.7865\n",
      "342\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1376 - accuracy: 0.9531 - precision: 0.8148 - recall: 0.6875 - AUC: 0.9596 - val_loss: 0.2622 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8698\n",
      "343\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1918 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9092 - val_loss: 0.2937 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.7856\n",
      "344\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1517 - accuracy: 0.9500 - precision: 0.9000 - recall: 0.5625 - AUC: 0.9474 - val_loss: 0.1929 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9470\n",
      "345\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1718 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9524 - val_loss: 0.2642 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8481\n",
      "346\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1768 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9289 - val_loss: 0.3014 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8863\n",
      "347\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1863 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9175 - val_loss: 0.2098 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9054\n",
      "348\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1954 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.8893 - val_loss: 0.2280 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8420\n",
      "349\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1768 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9361 - val_loss: 0.2001 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9115\n",
      "350\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2361 - accuracy: 0.8906 - precision: 0.4118 - recall: 0.2188 - AUC: 0.8748 - val_loss: 0.2474 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8438\n",
      "351\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2273 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.8550 - val_loss: 0.1263 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9818\n",
      "352\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2383 - accuracy: 0.9125 - precision: 0.6111 - recall: 0.3438 - AUC: 0.8704 - val_loss: 0.1609 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9592\n",
      "353\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2107 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8870 - val_loss: 0.2066 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9028\n",
      "354\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2155 - accuracy: 0.9094 - precision: 0.6154 - recall: 0.2500 - AUC: 0.8846 - val_loss: 0.1591 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9601\n",
      "355\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2212 - accuracy: 0.9062 - precision: 0.5455 - recall: 0.3750 - AUC: 0.8969 - val_loss: 0.1997 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8733\n",
      "356\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1978 - accuracy: 0.8969 - precision: 0.4737 - recall: 0.2812 - AUC: 0.9227 - val_loss: 0.1420 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9583\n",
      "357\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1854 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9159 - val_loss: 0.2487 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8455\n",
      "358\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1927 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.8978 - val_loss: 0.2378 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8620\n",
      "359\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1705 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9369 - val_loss: 0.2158 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9080\n",
      "360\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1589 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9580 - val_loss: 0.2661 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.1250 - val_AUC: 0.7873\n",
      "361\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2274 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.8885 - val_loss: 0.1716 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9601\n",
      "362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2012 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9003 - val_loss: 0.2209 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8568\n",
      "363\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1351 - accuracy: 0.9469 - precision: 0.8000 - recall: 0.6250 - AUC: 0.9633 - val_loss: 0.1299 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9592\n",
      "364\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1521 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9495 - val_loss: 0.2022 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9062\n",
      "365\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2061 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8918 - val_loss: 0.1978 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9132\n",
      "366\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2047 - accuracy: 0.9312 - precision: 0.8571 - recall: 0.3750 - AUC: 0.8918 - val_loss: 0.1702 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9540\n",
      "367\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2056 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8966 - val_loss: 0.2045 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9071\n",
      "368\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2179 - accuracy: 0.9031 - precision: 0.5556 - recall: 0.1562 - AUC: 0.9013 - val_loss: 0.2004 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9089\n",
      "369\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1672 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9400 - val_loss: 0.1431 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9696\n",
      "370\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1630 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9456 - val_loss: 0.2749 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.7995\n",
      "371\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1920 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9151 - val_loss: 0.2138 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8681\n",
      "372\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2080 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8965 - val_loss: 0.1790 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9505\n",
      "373\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1827 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.9278 - val_loss: 0.1527 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9462\n",
      "374\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1373 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9618 - val_loss: 0.1359 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9687\n",
      "375\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1572 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9565 - val_loss: 0.1758 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9427\n",
      "376\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1904 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9191 - val_loss: 0.1195 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9705\n",
      "377\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1968 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9070 - val_loss: 0.1178 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9679\n",
      "378\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1752 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9229 - val_loss: 0.2182 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9227\n",
      "379\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1856 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9275 - val_loss: 0.1634 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9436\n",
      "380\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1810 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9300 - val_loss: 0.2249 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8594\n",
      "381\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1926 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9382 - val_loss: 0.2371 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8698\n",
      "382\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1765 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9281 - val_loss: 0.1438 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9618\n",
      "383\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1954 - accuracy: 0.9094 - precision: 0.5714 - recall: 0.3750 - AUC: 0.9166 - val_loss: 0.1889 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9253\n",
      "384\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1751 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9295 - val_loss: 0.1663 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9349\n",
      "385\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1248 - accuracy: 0.9531 - precision: 0.8400 - recall: 0.6562 - AUC: 0.9709 - val_loss: 0.2223 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8698\n",
      "386\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1807 - accuracy: 0.9312 - precision: 0.6786 - recall: 0.5938 - AUC: 0.9264 - val_loss: 0.1492 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9366\n",
      "387\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1878 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9215 - val_loss: 0.2116 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8715\n",
      "388\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1325 - accuracy: 0.9594 - precision: 0.9130 - recall: 0.6562 - AUC: 0.9635 - val_loss: 0.1652 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9306\n",
      "389\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1721 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9343 - val_loss: 0.1902 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9132\n",
      "390\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1920 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9190 - val_loss: 0.1618 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9375\n",
      "391\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1738 - accuracy: 0.9281 - precision: 0.6800 - recall: 0.5312 - AUC: 0.9280 - val_loss: 0.1152 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9844\n",
      "392\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1935 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9034 - val_loss: 0.1298 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9661\n",
      "393\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1993 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9136 - val_loss: 0.1292 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9688\n",
      "394\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1662 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9425 - val_loss: 0.4019 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.7144\n",
      "395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2059 - accuracy: 0.9125 - precision: 0.6250 - recall: 0.3125 - AUC: 0.9014 - val_loss: 0.1316 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9470\n",
      "396\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1436 - accuracy: 0.9500 - precision: 0.8333 - recall: 0.6250 - AUC: 0.9609 - val_loss: 0.2409 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8611\n",
      "397\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1706 - accuracy: 0.9406 - precision: 0.7407 - recall: 0.6250 - AUC: 0.9252 - val_loss: 0.2784 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.7830\n",
      "398\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2060 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.8932 - val_loss: 0.1546 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9384\n",
      "399\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1965 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9079 - val_loss: 0.2118 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8984\n",
      "400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1972 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9082 - val_loss: 0.1849 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8950\n",
      "401\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1875 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.4062 - AUC: 0.9058 - val_loss: 0.2036 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8993\n",
      "402\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1383 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9623 - val_loss: 0.1848 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9253\n",
      "403\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1744 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.4062 - AUC: 0.9259 - val_loss: 0.1145 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "404\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1649 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9479 - val_loss: 0.1778 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9115\n",
      "405\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1795 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9202 - val_loss: 0.1347 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9722\n",
      "406\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1298 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9692 - val_loss: 0.2352 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8602\n",
      "407\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1623 - accuracy: 0.9313 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9437 - val_loss: 0.1916 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9115\n",
      "408\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2472 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.8599 - val_loss: 0.1613 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9132\n",
      "409\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1560 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9450 - val_loss: 0.1452 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9618\n",
      "410\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1474 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9601 - val_loss: 0.1580 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9627\n",
      "411\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1453 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9590 - val_loss: 0.2061 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9262\n",
      "412\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1506 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9558 - val_loss: 0.2552 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8056\n",
      "413\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1698 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9391 - val_loss: 0.2503 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8186\n",
      "414\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1729 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9299 - val_loss: 0.2306 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8950\n",
      "415\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1584 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9283 - val_loss: 0.2902 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8524\n",
      "416\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2100 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9001 - val_loss: 0.1399 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9505\n",
      "417\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1519 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9460 - val_loss: 0.3161 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8073\n",
      "418\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2198 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8825 - val_loss: 0.1500 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9245\n",
      "419\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1884 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9062 - val_loss: 0.3893 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.7717\n",
      "420\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1730 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9277 - val_loss: 0.1201 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "421\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1857 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9238 - val_loss: 0.2884 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8151\n",
      "422\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1513 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9492 - val_loss: 0.2157 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8906\n",
      "423\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2235 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.8829 - val_loss: 0.3301 - val_accuracy: 0.8750 - val_precision: 0.3333 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "424\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2283 - accuracy: 0.9031 - precision: 0.5238 - recall: 0.3438 - AUC: 0.8966 - val_loss: 0.1565 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9583\n",
      "425\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1813 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9265 - val_loss: 0.2153 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9175\n",
      "426\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1909 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9177 - val_loss: 0.1883 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9358\n",
      "427\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1594 - accuracy: 0.9469 - precision: 0.8000 - recall: 0.6250 - AUC: 0.9465 - val_loss: 0.1448 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9601\n",
      "428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1911 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9168 - val_loss: 0.1188 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9852\n",
      "429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1833 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9348 - val_loss: 0.1847 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9227\n",
      "430\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1659 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9530 - val_loss: 0.1787 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9123\n",
      "431\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1706 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9293 - val_loss: 0.2059 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9193\n",
      "432\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2059 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8985 - val_loss: 0.2416 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8090\n",
      "433\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2087 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.8875 - val_loss: 0.2355 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8802\n",
      "434\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1705 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9383 - val_loss: 0.1134 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9896\n",
      "435\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1730 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9385 - val_loss: 0.1670 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9444\n",
      "436\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2562 - accuracy: 0.9031 - precision: 0.5333 - recall: 0.2500 - AUC: 0.8638 - val_loss: 0.2169 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8976\n",
      "437\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1841 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9190 - val_loss: 0.1912 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9418\n",
      "438\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1440 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9586 - val_loss: 0.2031 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8767\n",
      "439\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1646 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9488 - val_loss: 0.1486 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9687\n",
      "440\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1619 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9429 - val_loss: 0.2505 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8446\n",
      "441\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1985 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9080 - val_loss: 0.2018 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8915\n",
      "442\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1790 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9221 - val_loss: 0.2090 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8785\n",
      "443\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2199 - accuracy: 0.9062 - precision: 0.5714 - recall: 0.2500 - AUC: 0.8945 - val_loss: 0.1807 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9366\n",
      "444\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1987 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.8927 - val_loss: 0.1554 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9575\n",
      "445\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1488 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9531 - val_loss: 0.1888 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9201\n",
      "446\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1275 - accuracy: 0.9438 - precision: 0.9375 - recall: 0.4688 - AUC: 0.9740 - val_loss: 0.1413 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9661\n",
      "447\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1788 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9194 - val_loss: 0.1942 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "448\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1500 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9527 - val_loss: 0.2608 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8377\n",
      "449\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1635 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9397 - val_loss: 0.1604 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9575\n",
      "450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2188 - accuracy: 0.9125 - precision: 0.6000 - recall: 0.3750 - AUC: 0.8914 - val_loss: 0.1031 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9878\n",
      "451\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2314 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8543 - val_loss: 0.1328 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9635\n",
      "452\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1750 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9237 - val_loss: 0.1606 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9557\n",
      "453\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2247 - accuracy: 0.9125 - precision: 0.6111 - recall: 0.3438 - AUC: 0.8690 - val_loss: 0.2134 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8906\n",
      "454\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1455 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9546 - val_loss: 0.2031 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "455\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1820 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.9202 - val_loss: 0.1932 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9227\n",
      "456\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1665 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9426 - val_loss: 0.1561 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9488\n",
      "457\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2030 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9183 - val_loss: 0.1940 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9193\n",
      "458\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1737 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9306 - val_loss: 0.1898 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9340\n",
      "459\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1818 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9141 - val_loss: 0.1368 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9740\n",
      "460\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1497 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9634 - val_loss: 0.2151 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8733\n",
      "461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1677 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9419 - val_loss: 0.1573 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9427\n",
      "462\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2047 - accuracy: 0.9062 - precision: 0.5500 - recall: 0.3438 - AUC: 0.9051 - val_loss: 0.1852 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9427\n",
      "463\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2192 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8779 - val_loss: 0.2042 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.8733\n",
      "464\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2217 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.8815 - val_loss: 0.2702 - val_accuracy: 0.8625 - val_precision: 0.2857 - val_recall: 0.2500 - val_AUC: 0.8307\n",
      "465\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1755 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9252 - val_loss: 0.1417 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9731\n",
      "466\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1471 - accuracy: 0.9500 - precision: 0.8333 - recall: 0.6250 - AUC: 0.9473 - val_loss: 0.1187 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9809\n",
      "467\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1515 - accuracy: 0.9562 - precision: 0.9091 - recall: 0.6250 - AUC: 0.9431 - val_loss: 0.2874 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.7622\n",
      "468\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1826 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9186 - val_loss: 0.2364 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8073\n",
      "469\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1929 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9111 - val_loss: 0.1325 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9731\n",
      "470\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2109 - accuracy: 0.9062 - precision: 0.5714 - recall: 0.2500 - AUC: 0.9085 - val_loss: 0.2553 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.8707\n",
      "471\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2218 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8816 - val_loss: 0.1812 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8854\n",
      "472\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1506 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9529 - val_loss: 0.1476 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9653\n",
      "473\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1784 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9337 - val_loss: 0.0819 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9931\n",
      "474\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2083 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.8857 - val_loss: 0.2104 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9253\n",
      "475\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1981 - accuracy: 0.9187 - precision: 0.6250 - recall: 0.4688 - AUC: 0.9074 - val_loss: 0.0449 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 1.0000\n",
      "476\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1796 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9224 - val_loss: 0.1713 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9210\n",
      "477\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1698 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9266 - val_loss: 0.1391 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9740\n",
      "478\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1724 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9339 - val_loss: 0.1803 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9323\n",
      "479\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1990 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9015 - val_loss: 0.1765 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9262\n",
      "480\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1659 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9385 - val_loss: 0.2909 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.7847\n",
      "481\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1946 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.8965 - val_loss: 0.1860 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9271\n",
      "482\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1332 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9629 - val_loss: 0.1209 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9844\n",
      "483\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1588 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9444 - val_loss: 0.1261 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9661\n",
      "484\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1637 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9491 - val_loss: 0.1892 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.9401\n",
      "485\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2288 - accuracy: 0.9062 - precision: 0.5833 - recall: 0.2188 - AUC: 0.8872 - val_loss: 0.2494 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8594\n",
      "486\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1958 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9130 - val_loss: 0.0497 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 1.0000\n",
      "487\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2005 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9080 - val_loss: 0.2848 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "488\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1761 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9187 - val_loss: 0.1139 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9809\n",
      "489\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1681 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9428 - val_loss: 0.1623 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "490\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1782 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9384 - val_loss: 0.2635 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8099\n",
      "491\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1633 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9410 - val_loss: 0.1039 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9809\n",
      "492\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1185 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9756 - val_loss: 0.2732 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8438\n",
      "493\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1772 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9355 - val_loss: 0.1812 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9349\n",
      "494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1709 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9321 - val_loss: 0.1458 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9705\n",
      "495\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2731 - accuracy: 0.9062 - precision: 0.5500 - recall: 0.3438 - AUC: 0.8727 - val_loss: 0.1115 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9722\n",
      "496\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1756 - accuracy: 0.9219 - precision: 0.6522 - recall: 0.4688 - AUC: 0.9397 - val_loss: 0.2422 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9106\n",
      "497\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1644 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9429 - val_loss: 0.0748 - val_accuracy: 0.9875 - val_precision: 0.8889 - val_recall: 1.0000 - val_AUC: 0.9913\n",
      "498\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1840 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9075 - val_loss: 0.1581 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9514\n",
      "499\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1457 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9645 - val_loss: 0.1325 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9696\n",
      "500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2072 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9079 - val_loss: 0.2649 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8299\n",
      "501\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1958 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.8808 - val_loss: 0.2031 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9080\n",
      "502\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1518 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9529 - val_loss: 0.1438 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9644\n",
      "503\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1216 - accuracy: 0.9500 - precision: 0.8077 - recall: 0.6562 - AUC: 0.9714 - val_loss: 0.2188 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.8524\n",
      "504\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1521 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9430 - val_loss: 0.1537 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9722\n",
      "505\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1938 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9107 - val_loss: 0.1624 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9444\n",
      "506\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2059 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.8915 - val_loss: 0.1709 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9427\n",
      "507\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1882 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9203 - val_loss: 0.2253 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8759\n",
      "508\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1767 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9252 - val_loss: 0.2687 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8281\n",
      "509\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1719 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9338 - val_loss: 0.1978 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9210\n",
      "510\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2046 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.9118 - val_loss: 0.1456 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9601\n",
      "511\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1391 - accuracy: 0.9406 - precision: 0.7600 - recall: 0.5938 - AUC: 0.9644 - val_loss: 0.1734 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9531\n",
      "512\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1941 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9119 - val_loss: 0.2529 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8403\n",
      "513\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2088 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.8921 - val_loss: 0.2310 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8707\n",
      "514\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1755 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9376 - val_loss: 0.2027 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9149\n",
      "515\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2119 - accuracy: 0.9187 - precision: 0.6250 - recall: 0.4688 - AUC: 0.8947 - val_loss: 0.1542 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9366\n",
      "516\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2122 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9042 - val_loss: 0.1401 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9410\n",
      "517\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1740 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9401 - val_loss: 0.2060 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8941\n",
      "518\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1887 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9172 - val_loss: 0.2388 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8646\n",
      "519\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1979 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9185 - val_loss: 0.2444 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8620\n",
      "520\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1999 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9043 - val_loss: 0.0929 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9965\n",
      "521\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1804 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9110 - val_loss: 0.1903 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9193\n",
      "522\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1522 - accuracy: 0.9469 - precision: 0.9412 - recall: 0.5000 - AUC: 0.9511 - val_loss: 0.1171 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "523\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1733 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9260 - val_loss: 0.0923 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9913\n",
      "524\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1736 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9185 - val_loss: 0.2308 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8490\n",
      "525\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2009 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.8958 - val_loss: 0.2086 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8941\n",
      "526\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1536 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9547 - val_loss: 0.1756 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9358\n",
      "527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1713 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9355 - val_loss: 0.1844 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9149\n",
      "528\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1702 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9361 - val_loss: 0.2280 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8646\n",
      "529\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2055 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9011 - val_loss: 0.1743 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9314\n",
      "530\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1908 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9204 - val_loss: 0.2018 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8533\n",
      "531\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2021 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9013 - val_loss: 0.1767 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9306\n",
      "532\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1855 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.9169 - val_loss: 0.1640 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9627\n",
      "533\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2110 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8976 - val_loss: 0.1258 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9913\n",
      "534\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1773 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9301 - val_loss: 0.1091 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9878\n",
      "535\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1845 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9210 - val_loss: 0.1586 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9462\n",
      "536\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2098 - accuracy: 0.9156 - precision: 0.6923 - recall: 0.2812 - AUC: 0.9004 - val_loss: 0.2500 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8767\n",
      "537\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1427 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9501 - val_loss: 0.1589 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9470\n",
      "538\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1676 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9360 - val_loss: 0.2906 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.7943\n",
      "539\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1491 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9543 - val_loss: 0.1895 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9010\n",
      "540\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1538 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9515 - val_loss: 0.2289 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9297\n",
      "541\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1988 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8938 - val_loss: 0.2053 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8993\n",
      "542\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1432 - accuracy: 0.9531 - precision: 0.8400 - recall: 0.6562 - AUC: 0.9491 - val_loss: 0.1415 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9540\n",
      "543\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1581 - accuracy: 0.9531 - precision: 0.9474 - recall: 0.5625 - AUC: 0.9295 - val_loss: 0.1760 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9271\n",
      "544\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1535 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9485 - val_loss: 0.1198 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "545\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2012 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9009 - val_loss: 0.1893 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9201\n",
      "546\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2121 - accuracy: 0.9000 - precision: 0.5000 - recall: 0.2812 - AUC: 0.9120 - val_loss: 0.1952 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8984\n",
      "547\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1962 - accuracy: 0.9156 - precision: 0.6087 - recall: 0.4375 - AUC: 0.9201 - val_loss: 0.1911 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9236\n",
      "548\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1620 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9436 - val_loss: 0.1920 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9071\n",
      "549\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2118 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8836 - val_loss: 0.1589 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9366\n",
      "550\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1925 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9042 - val_loss: 0.1148 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9661\n",
      "551\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1407 - accuracy: 0.9375 - precision: 0.7308 - recall: 0.5938 - AUC: 0.9646 - val_loss: 0.1383 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9688\n",
      "552\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1772 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9355 - val_loss: 0.2330 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8281\n",
      "553\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1503 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9509 - val_loss: 0.1232 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9696\n",
      "554\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1987 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.8950 - val_loss: 0.1357 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9714\n",
      "555\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1528 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9478 - val_loss: 0.1555 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9557\n",
      "556\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1945 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9125 - val_loss: 0.1892 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9488\n",
      "557\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1960 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9049 - val_loss: 0.1117 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9722\n",
      "558\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1791 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9127 - val_loss: 0.1178 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9800\n",
      "559\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1529 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9534 - val_loss: 0.1148 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1745 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9376 - val_loss: 0.1141 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9913\n",
      "561\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1827 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9281 - val_loss: 0.1440 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9653\n",
      "562\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1725 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9255 - val_loss: 0.1751 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9210\n",
      "563\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1442 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9630 - val_loss: 0.1285 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9757\n",
      "564\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1745 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9215 - val_loss: 0.1395 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9505\n",
      "565\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2202 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.8784 - val_loss: 0.1735 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9297\n",
      "566\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1777 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9227 - val_loss: 0.1165 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9818\n",
      "567\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2259 - accuracy: 0.9094 - precision: 0.5652 - recall: 0.4062 - AUC: 0.8953 - val_loss: 0.1830 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9306\n",
      "568\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1759 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9313 - val_loss: 0.1401 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9609\n",
      "569\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1974 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9099 - val_loss: 0.1488 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9618\n",
      "570\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1758 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9307 - val_loss: 0.1598 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9618\n",
      "571\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1518 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.3750 - AUC: 0.9570 - val_loss: 0.2651 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8498\n",
      "572\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1841 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9248 - val_loss: 0.1220 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9575\n",
      "573\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2001 - accuracy: 0.9094 - precision: 0.5882 - recall: 0.3125 - AUC: 0.9082 - val_loss: 0.1879 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8889\n",
      "574\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1432 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9625 - val_loss: 0.1295 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9635\n",
      "575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-21625db61b83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         model2.fit(x_batch, y_batch,\n\u001b[0;32m     26\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                    verbose=1)\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "\n",
    "for e in range(epochs) :\n",
    "    print('Epochs : ',e)\n",
    "    batches = 0\n",
    "    for (x_batch, y_batch), (val_x, val_y) in zip(_datagen.flow(x_train, y_train, batch_size=32, subset='training'),\n",
    "                               _datagen.flow(x_train, y_train, batch_size=8, subset='validation')) :\n",
    "        print(batches)\n",
    "        model2.fit(x_batch, y_batch,\n",
    "                   validation_data=(val_x, val_y),\n",
    "                   verbose=1)\n",
    "        batches += 1\n",
    "        \n",
    "        if batches >= len(x_train) / 32:\n",
    "            break\n",
    "\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# _datagen.fit(x_train)\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "# model2.fit(_datagen.flow(x_train, y_train, batch_size=32,\n",
    "#          subset='training'),\n",
    "#          validation_data=_datagen.flow(x_train, y_train,\n",
    "#          batch_size=8, subset='validation'),\n",
    "#          steps_per_epoch=len(x_train) / 32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dedd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
