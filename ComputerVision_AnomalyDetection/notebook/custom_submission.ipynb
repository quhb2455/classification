{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6152307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa08b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_list, label_list=None, transforms=None, mode=\"train\") :\n",
    "        self.img_list = img_list\n",
    "        \n",
    "        if mode == \"train\" : \n",
    "            self.label_list = self.label_encoder(label_list)\n",
    "            \n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_list[idx]\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:            \n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.mode == \"train\" :\n",
    "            label = self.label_list[idx]\n",
    "            return img, torch.tensor(label)\n",
    "        \n",
    "        elif self.mode == \"test\" :\n",
    "            return img\n",
    "    \n",
    "    def label_encoder(self, label_list) :\n",
    "        label_enc = {k : i for i, k in enumerate(sorted(list(set(label_list))))}\n",
    "        return [label_enc[label] for label in label_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828aecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self, model_name, num_classes) :\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = timm.create_model(model_name=model_name, num_classes=num_classes, pretrained=True)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef5c8e",
   "metadata": {},
   "source": [
    "# Custom Swin Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96dba7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(nn.Module) :\n",
    "    def __init__(self, model_name, backbone_output) :\n",
    "        super(BackBone, self).__init__()\n",
    "        self.model = timm.create_model(model_name=model_name, num_classes=backbone_output, pretrained=True)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "# class MLP(nn.Module) :\n",
    "#     def __init__(self, in_features, dropout_rate, num_state) :\n",
    "#         super(MLP, self).__init__()\n",
    "#         #forward_features 시 LayerNorm까지 통과한 결과임\n",
    "#         # 따라서 LayerNorm 와 AdaptiveAvgPool1d는 필요없음    \n",
    "\n",
    "#         self.linear_1 = nn.Linear(in_features, in_features//2, bias=True)\n",
    "#         self.gelu = nn.GELU()\n",
    "#         self.dropout = nn.Dropout(p=dropout_rate, inplace=False)\n",
    "#         self.linear_2 = nn.Linear(in_features//2, num_state, bias=True)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.linear_1(x)\n",
    "#         x = self.gelu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.linear_2(x)\n",
    "#         return x\n",
    "class MLP(nn.Module) :\n",
    "    def __init__(self, in_features, dropout_rate, num_state) :\n",
    "        super(MLP, self).__init__()\n",
    "        #forward_features 시 LayerNorm까지 통과한 결과임\n",
    "        # 따라서 LayerNorm 와 AdaptiveAvgPool1d는 필요없음    \n",
    "\n",
    "        self.linear_1 = nn.Linear(in_features, in_features//2, bias=True)\n",
    "        self.gelu_1 = nn.GELU()\n",
    "        self.dropout_1 = nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        \n",
    "        self.linear_2 = nn.Linear(in_features//2, in_features//4, bias=True)\n",
    "        self.gelu_2 = nn.GELU()\n",
    "        self.dropout_2 = nn.Dropout(p=dropout_rate, inplace=False)\n",
    "        \n",
    "        self.linear_3 = nn.Linear(in_features//4, num_state, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        x = self.linear_2(x)\n",
    "        x = self.gelu_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        x = self.linear_3(x)\n",
    "        return x\n",
    "    \n",
    "class CustomSwinTransformer(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 model_path, \n",
    "                 model_name, \n",
    "                 backbone_output, \n",
    "                 num_class, \n",
    "                 num_state,\n",
    "#                  label_decoder,\n",
    "                 ensemble_backbone,\n",
    "                 ensemble_model_list,\n",
    "                 dropout_rate=0.5) :\n",
    "        super(CustomSwinTransformer, self).__init__()\n",
    "#         self.label_decoder = label_decoder\n",
    "        self.ensembel_backbone = ensemble_backbone\n",
    "        \n",
    "        if self.ensembel_backbone :\n",
    "            self.backbones = self.get_ensemble_backbone(ensemble_model_list,\n",
    "                                                       model_name,\n",
    "                                                       backbone_output)\n",
    "        else :\n",
    "            self.backbone = self.get_backbone(model_path,\n",
    "                                             model_name,\n",
    "                                             backbone_output)\n",
    "        \n",
    "        # num_state + 1을 해준 이유 = None Class를 추가할 예정이기 때문\n",
    "        self.mlps = nn.ModuleList([MLP(in_features=1024, \n",
    "                         dropout_rate=dropout_rate, \n",
    "#                        num_state = num_state[i]) for i in range(num_class)])\n",
    "                         num_state = num_state[i] + 1) for i in range(num_class)])\n",
    "        \n",
    "    def forward(self, x) :       \n",
    "#         prob = self.backbone(x)\n",
    "#         prob = F.softmax(prob.cpu())\n",
    "#         pred = torch.argmax(prob, dim=1)\n",
    "#         pred = list(map(lambda x : self.label_decoder[x.item()], pred))\n",
    "        \n",
    "        if self.ensembel_backbone :\n",
    "            feature_map = 0\n",
    "            for backbone in self.backbones :\n",
    "                feature_map += backbone.forward_features(x)\n",
    "            feature_map /= len(self.backbones)\n",
    "        else :\n",
    "            feature_map = self.backbone.forward_features(x)\n",
    "\n",
    "        preds = []    \n",
    "        for mlp in self.mlps :\n",
    "            preds.append(mlp(feature_map))\n",
    "        return preds\n",
    "    \n",
    "    def WeightFreeze(self, model) :\n",
    "        for i, child in enumerate(model.children()) :\n",
    "            for param in child.parameters() :\n",
    "                param.requires_grad = False\n",
    "        return model\n",
    "    \n",
    "    def get_backbone(self, model_path, model_name, backbone_output) :\n",
    "        checkpoint = torch.load(model_path)\n",
    "        backbone = BackBone(model_name, backbone_output)\n",
    "        backbone.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        backbone = self.WeightFreeze(backbone.model)\n",
    "#         return backbone.model\n",
    "        return backbone\n",
    "    \n",
    "    def get_ensemble_backbone(self, ensemble_model_list,  model_name, backbone_output) :\n",
    "        backbones = []\n",
    "        for model_path in ensemble_model_list:\n",
    "            backbones.append(self.get_backbone(model_path, model_name, backbone_output))\n",
    "        return nn.ModuleList(backbones)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625de6f8",
   "metadata": {},
   "source": [
    "# Weight Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808e89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightFreeze(model) :\n",
    "    for i, child in enumerate(model.backbone.children()) :\n",
    "        for param in child.parameters() :\n",
    "            param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dddec6",
   "metadata": {},
   "source": [
    "# MLP Label Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79125c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_label_split(num_state, labels) :\n",
    "    tmp = {i : torch.tensor([], dtype=torch.int32) for i in range(15)}\n",
    "\n",
    "    for label in labels :\n",
    "\n",
    "        if 0 <= label and label < num_state[0] :\n",
    "            tmp[0] = torch.cat((tmp[0], torch.tensor([label])), dim=0)\n",
    "        else :\n",
    "            tmp[0] = torch.cat((tmp[0], torch.tensor([num_state[0]])))\n",
    "            \n",
    "        for i in range(1, 15):\n",
    "            if sum(num_state[:i]) <= label and label < sum(num_state[:i+1]) :\n",
    "                tmp[i] = torch.cat((tmp[i], torch.tensor([int(label - sum(num_state[:i]))])), dim=0)\n",
    "            else :\n",
    "                tmp[i] = torch.cat((tmp[i], torch.tensor([num_state[i]])), dim=0)\n",
    "                \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b157a",
   "metadata": {},
   "source": [
    "# Label Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf19a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_decoder(labels) :\n",
    "#     print(\"==== each_dec ====\")\n",
    "#     print({k:i for i, k in enumerate(labels)})\n",
    "    return {k:i for i, k in enumerate(labels)}\n",
    "\n",
    "def label_encoder(labels) :\n",
    "#     print(\"==== each_dec ====\")\n",
    "#     print({k:i for i, k in enumerate(labels)})\n",
    "    return {i:k for i, k in enumerate(labels)}\n",
    "\n",
    "def each_label_decoder(labels, num_state) :\n",
    "    dec = label_decoder(labels)\n",
    "    each_dec = []\n",
    "    cnt = 0\n",
    "    for idx, (k, v) in enumerate(dec.items()) :\n",
    "        if sum(num_state[:cnt]) == idx :\n",
    "            cnt += 1\n",
    "            flag=True\n",
    "        \n",
    "        if flag :    \n",
    "            each_dec.append({cnt : list(dec.keys())[i] for cnt, i in enumerate(range(idx, sum(num_state[:cnt])))})\n",
    "            flag = False\n",
    "            \n",
    "#     print(\"==== each_dec ====\")\n",
    "#     print(each_dec)\n",
    "    return each_dec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398927da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sub\\.conda\\envs\\torch-1.11\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Model Len :  4\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    \"test_df_path\" : \"../data/test_df.csv\",\n",
    "    \"train_df_path\" : \"../data/train_df.csv\",\n",
    "    \"submission_df_path\" : \"../data/sample_submission.csv\",\n",
    "    \"img_path\" : \"../data/test\",\n",
    "    \"save_path\" : \"../data/submission/custom_ensemble_swin_aug_v4_last_dence_mixup_12e9e8e7e.csv\",\n",
    "    \"model_name\" : \"swin_base_patch4_window7_224_in22k\",\n",
    "    \"model_path\" : \"../model/custom_ensemble-kfold_swin_aug_v4-5_CEL-mixup/6E_0.0034_1fold_swin_base_patch4_window7_224_in22k.pt\",\n",
    "    \"num_classes\" : 88,\n",
    "    'num_state' : [4, 9, 6, 6, 6, 5, 6, 5, 8, 6, 6, 2, 5, 6, 8],\n",
    "    \"resize\" : 224,\n",
    "    \"device\" : \"cuda:0\",\n",
    "    \"batch_size\" : 64,\n",
    "    \"ensemble\" : True,\n",
    "    \"models_list\" : [\n",
    "        \"../model/ensemble_aug_v4-5_CEL-mixup/19E_0.0394_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/ensemble_aug_v4-5_CEL-mixup/22E_0.0269_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/ensemble_aug_v4-5_CEL-mixup/30E_0.0114_swin_base_patch4_window7_224_in22k.pt\"\n",
    "    ],\n",
    "    \"cus_models_list\" : [\n",
    "        \"../model/custom_ensemble_swin_aug_v4_last_dence/12E_0.0392_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/custom_ensemble_swin_aug_v4_last_dence/7E_0.0383_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/custom_ensemble_swin_aug_v4_last_dence/8E_0.0411_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/custom_ensemble_swin_aug_v4_last_dence/9E_0.0427_swin_base_patch4_window7_224_in22k.pt\",\n",
    "    ],\n",
    "    \"last_dence\" : None\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "opt = EasyDict(opt)\n",
    "\n",
    "\n",
    "model_opt = {    \n",
    "    'model_path' : '../model/swin_aug_v4_mixup/19E_0.0394_swin_base_patch4_window7_224_in22k.pt',\n",
    "    'model_name' : 'swin_base_patch4_window7_224_in22k',\n",
    "    'backbone_output' : 88,\n",
    "    'num_class' : 15,\n",
    "    'num_state' : [4, 9, 6, 6, 6, 5, 6, 5, 8, 6, 6, 2, 5, 6, 8],\n",
    "    \"ensemble_backbone\" : True,\n",
    "    \"ensemble_model_list\" : [\n",
    "        \"../model/ensemble_aug_v4-5_CEL-mixup/19E_0.0394_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/ensemble_aug_v4-5_CEL-mixup/22E_0.0269_swin_base_patch4_window7_224_in22k.pt\",\n",
    "        \"../model/ensemble_aug_v4-5_CEL-mixup/30E_0.0114_swin_base_patch4_window7_224_in22k.pt\"\n",
    "    ],\n",
    "    'dropout_rate' : 0.5,\n",
    "\n",
    "}\n",
    "model_opt = EasyDict(model_opt)\n",
    "\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(opt.resize, opt.resize),\n",
    "    A.Normalize(mean=[0.4178, 0.3926, 0.3861],\n",
    "                std=[0.2601, 0.2582, 0.2559]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_df = pd.read_csv(opt.train_df_path)\n",
    "label_list = list(sorted(train_df['label'].unique()))\n",
    "label_dec = label_decoder(label_list)\n",
    "label_enc = label_encoder(label_list)\n",
    "each_label_dec = each_label_decoder(label_list, opt.num_state)\n",
    "\n",
    "test_df = pd.read_csv(opt.test_df_path)\n",
    "file_names = list(map(lambda y :os.path.join(opt.img_path, y), test_df['file_name']))\n",
    "\n",
    "test_data = CustomDataset(file_names, transforms=test_transforms, mode=\"test\")\n",
    "test_loader = DataLoader(test_data, batch_size=opt.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "if opt.ensemble :\n",
    "    cus_models = []\n",
    "    models = []\n",
    "    for model_path in opt.cus_models_list :\n",
    "        model = CustomSwinTransformer(**model_opt).to(opt.device)\n",
    "#         model = WeightFreeze(custom_swin)\n",
    "        model_data = torch.load(model_path)\n",
    "        model.load_state_dict(model_data[\"model_state_dict\"])\n",
    "        cus_models.append(model.eval())\n",
    "        \n",
    "#     for model_path in opt.models_list :\n",
    "#         model = CNN(opt.model_name, opt.num_classes).to(opt.device)\n",
    "#         model_data = torch.load(model_path, map_location=\"cuda:0\")\n",
    "#         model.load_state_dict(model_data[\"model_state_dict\"])\n",
    "#         models.append(model.eval())\n",
    "        \n",
    "else :\n",
    "    model = CustomSwinTransformer(**model_opt).to(opt.device)\n",
    "#     model = WeightFreeze(custom_swin)\n",
    "    model_data = torch.load(opt.model_path)\n",
    "    model.load_state_dict(model_data[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "print(\"Custom Model Len : \", str(len(cus_models)))    \n",
    "# print(\"Model Len : \", str(len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f52292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_mlp_label(tmp_anws, num_state, batch_size) :\n",
    "    answer = []\n",
    "    total_score = []\n",
    "    for bn in range(batch_size) :\n",
    "        score, index, mlp_state = 0, 0, 0\n",
    "        \n",
    "        # mlp 개수만큼 반복 = 15번\n",
    "        for j, anws in enumerate(tmp_anws) :            \n",
    "            if score < anws[1][bn][anws[0][bn]] and anws[0][bn] != num_state[j] :\n",
    "                score = anws[1][bn][anws[0][bn]].item()\n",
    "                index = anws[0][bn].item()\n",
    "                mlp_state = j\n",
    "        total_score.append(score) \n",
    "        answer.append(each_label_dec[mlp_state][index])\n",
    "    return answer\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b29b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_merge_mlp_label(tmp_anws) :\n",
    "    merge = torch.zeros(64,1)\n",
    "    for idx, anws in enumerate(tmp_anws) :\n",
    "        try :\n",
    "            if idx == 0 :\n",
    "                merge = torch.cat([merge, anws[1][:, :-1]], dim=1)[:, 1:]\n",
    "            else :\n",
    "                merge = torch.cat([merge, anws[1][:, :-1]], dim=1)\n",
    "                \n",
    "        except :\n",
    "            merge = torch.zeros(42,1)\n",
    "            print(\"last - 42 batch\")\n",
    "            if idx == 0 :\n",
    "                merge = torch.cat([merge, anws[1][:, :-1]], dim=1)[:, 1:]\n",
    "            else :\n",
    "                merge = torch.cat([merge, anws[1][:, :-1]], dim=1)\n",
    "                \n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014a97ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/34 [00:00<?, ?it/s]C:\\Users\\sub\\AppData\\Local\\Temp\\ipykernel_5508\\1439460786.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predicts[idx] += F.softmax(output.cpu())\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [03:17<00:00,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad() :\n",
    "    answers = []\n",
    "    for img in tqdm(test_loader) :\n",
    "        img = img.to(opt.device)\n",
    "        if not opt.ensemble :\n",
    "            outputs = model(img)\n",
    "            tmp_anws = []\n",
    "            for idx, output in enumerate(outputs) :\n",
    "                prob = F.softmax(output.cpu())\n",
    "                preds = torch.argmax(prob, dim=1)\n",
    "                # [index, score]\n",
    "                tmp_anws.append([preds, prob])                \n",
    "                \n",
    "#                 score, indice = 0, 0\n",
    "#                 # batch size 만큼 반복\n",
    "#                 for j, pred in enumerate(preds) :\n",
    "#                     if score < output[j][preds]:\n",
    "#                         indice = pred\n",
    "#                         score = output[j][preds]\n",
    "\n",
    "            labels = merge_mlp_label(tmp_anws, opt.num_state, img.size(0))\n",
    "#             labels = list(map(lambda x : label_decoder[x.item()], preds))\n",
    "            answers.extend(labels)\n",
    "            \n",
    "        elif opt.ensemble and opt.last_dence is None:\n",
    "\n",
    "            predicts = [0] * 15\n",
    "            for model in cus_models :\n",
    "                outputs = model(img)\n",
    "                \n",
    "                # mlp 처리\n",
    "                for idx, output in enumerate(outputs) :\n",
    "                    predicts[idx] += F.softmax(output.cpu())\n",
    "            \n",
    "            predicts = list(map(lambda x : x / len(cus_models) , predicts))\n",
    "            tmp_anws = []\n",
    "            for prob in predicts :\n",
    "                preds = torch.argmax(prob, dim=1)\n",
    "                # [index, score]\n",
    "                tmp_anws.append([preds, prob])     \n",
    "            labels = merge_mlp_label(tmp_anws, opt.num_state, img.size(0))\n",
    "\n",
    "            answers.extend(labels)\n",
    "        \n",
    "        elif opt.last_dence :\n",
    "            \n",
    "            predicts = [0] * 15\n",
    "            for model in cus_models :\n",
    "                outputs = model(img)\n",
    "                \n",
    "                # mlp 처리\n",
    "                for idx, output in enumerate(outputs) :\n",
    "                    predicts[idx] += F.softmax(output.cpu())\n",
    "            \n",
    "#             predicts = list(map(lambda x : x / len(cus_models) , predicts))\n",
    "            tmp_anws = []\n",
    "            for prob in predicts :\n",
    "                preds = torch.argmax(prob, dim=1)\n",
    "                tmp_anws.append([preds, prob])     \n",
    "                \n",
    "            merged_pred = new_merge_mlp_label(tmp_anws)\n",
    "            \n",
    "            predicts = 0\n",
    "            for model in models :\n",
    "                output = model(img)        \n",
    "                output = F.softmax(output.cpu())\n",
    "                \n",
    "                predicts += output\n",
    "                \n",
    "            preds = torch.argmax(((predicts.detach().cpu() * 0.7) + (merged_pred * 0.3)) / (len(models) + len(cus_models)), dim=1)\n",
    "            labels = list(map(lambda x : label_enc[x.item()], preds))\n",
    "            answers.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0834c434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label\n",
       "index                  \n",
       "0       tile-glue_strip\n",
       "1             grid-good\n",
       "2       transistor-good\n",
       "3      tile-gray_stroke\n",
       "4             tile-good\n",
       "...                 ...\n",
       "2149   tile-gray_stroke\n",
       "2150         screw-good\n",
       "2151          grid-good\n",
       "2152         cable-good\n",
       "2153        zipper-good\n",
       "\n",
       "[2154 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(opt.submission_df_path).set_index('index')\n",
    "submission['label'] = answers\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f251e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(opt.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54984d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c3340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
